{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    24992.000000\nmean       419.802937\nstd        121.761374\nmin         11.000000\n25%        330.000000\n50%        512.000000\n75%        512.000000\nmax        513.000000\nName: content, dtype: float64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './proceed/train_data_all.csv'\n",
    "data=pd.read_csv(data_path,encoding='utf-8',sep='|')\n",
    "data['content'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sklearn.utils.shuffle(data) #随机打乱\n",
    "train_data = df.sample(frac=0.9, random_state=0, axis=0)\n",
    "dev_data = df.drop(train_data.index)\n",
    "train_data_path = './proceed/train_data.csv'\n",
    "dev_data_path = './proceed/dev_data.csv'\n",
    "# #将训练数据写入到文件中\n",
    "train_data.to_csv(train_data_path,  index=False,encoding='utf-8',sep ='|',header =['id','content','abstract'])\n",
    "# #将测试数据写入文件中\n",
    "dev_data.to_csv(dev_data_path,  index=False,encoding='utf-8',sep ='|',header =['id','content','abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================train===============\n",
      "count    22492.000000\n",
      "mean       419.649475\n",
      "std        121.892133\n",
      "min         11.000000\n",
      "25%        330.000000\n",
      "50%        512.000000\n",
      "75%        512.000000\n",
      "max        513.000000\n",
      "Name: content, dtype: float64\n",
      "=================dev=================\n",
      "count    2500.000000\n",
      "mean      421.183600\n",
      "std       120.593983\n",
      "min        18.000000\n",
      "25%       328.000000\n",
      "50%       512.000000\n",
      "75%       512.000000\n",
      "max       513.000000\n",
      "Name: content, dtype: float64\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "print(\"================train===============\")\n",
    "print(train_data['content'].str.len().describe())\n",
    "print(\"=================dev=================\")\n",
    "print(dev_data['content'].str.len().describe())\n",
    "print(\"====================================\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\paddle\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22501\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "# # q:上面的函数还能怎么写\n",
    "# # a:可以用pandas读取csv文件，然后用iterrows()方法遍历每一行，然后yield\n",
    "def read_from_csv(data_path):\n",
    "    data=pd.read_csv(data_path,encoding='utf-8',sep='|')\n",
    "    for index, row in data.iterrows():\n",
    "        content, abstract = row['content'],row['abstract']\n",
    "        yield {'content': content, 'abstract': abstract}\n",
    "\n",
    "# data_path为read()方法的参数\n",
    "train_dataset  = load_dataset(read_from_csv, data_path=train_data_path, lazy=False, split=\"train\")\n",
    "dev_dataset  = load_dataset(read_from_csv, data_path=dev_data_path, lazy=False, split=\"dev\")\n",
    "print(len(train_dataset))\n",
    "print(len(dev_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-04 23:54:15,523] [    INFO]\u001B[0m - Already cached /home/ubuntu/.paddlenlp/models/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/vocab.txt\u001B[0m\n",
      "\u001B[32m[2023-06-04 23:54:15,524] [    INFO]\u001B[0m - Already cached /home/ubuntu/.paddlenlp/models/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/added_tokens.json\u001B[0m\n",
      "\u001B[32m[2023-06-04 23:54:15,525] [    INFO]\u001B[0m - Already cached /home/ubuntu/.paddlenlp/models/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-04 23:54:15,526] [    INFO]\u001B[0m - Already cached /home/ubuntu/.paddlenlp/models/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-04 23:54:15,584] [    INFO]\u001B[0m - Already cached /home/ubuntu/.paddlenlp/models/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2023-06-04 23:54:15,585] [    INFO]\u001B[0m - Already cached /home/ubuntu/.paddlenlp/models/IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/model_config.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import PegasusForConditionalGeneration, PegasusChineseTokenizer\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from paddle.io import BatchSampler, DistributedBatchSampler, DataLoader\n",
    "from paddlenlp.data import DataCollatorForSeq2Seq\n",
    "\n",
    "#创建Tokenizer，用于分词，将token映射成id。\n",
    "1# 初始化分词器\n",
    "tokenizer = PegasusChineseTokenizer.from_pretrained('IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese')\n",
    "# 初始化模型，'IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/'IDEA-CCNL/Randeng-Pegasus-538M-Summary-Chinese\n",
    "model = PegasusForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese')\n",
    "\n",
    "# tokenizer = PegasusChineseTokenizer.from_pretrained('PaddlePaddle/Randeng-Pegasus-238M-Summary-Chinese-SSTIA')\n",
    "# # 初始化模型，'IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese/'IDEA-CCNL/Randeng-Pegasus-538M-Summary-Chinese\n",
    "# model = PegasusForConditionalGeneration.from_pretrained('PaddlePaddle/Randeng-Pegasus-238M-Summary-Chinese-SSTIA')\n",
    "# 组装 Batch 数据 & Padding\n",
    "batchify_fn = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装需要的相关库\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import paddle\n",
    "import paddlenlp\n",
    "import distutils.util\n",
    "from pprint import pprint\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "import contextlib\n",
    "from rouge import Rouge\n",
    "from visualdl import LogWriter\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from paddlenlp.datasets import MapDataset\n",
    "import paddle.nn as nn\n",
    "from paddlenlp.utils.log import logger\n",
    "from paddlenlp.metrics import BLEU\n",
    "from paddlenlp.data import Tuple, Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义convert_example，将content和title文本映射成int类型的id，同时构造labels。\n",
    "def convert_example(example, text_column, summary_column, tokenizer,\n",
    "                    max_source_length, max_target_length):\n",
    "    \"\"\"\n",
    "    构造模型的输入.\n",
    "    \"\"\"\n",
    "    inputs = example[text_column]\n",
    "    targets = example[summary_column]\n",
    "    # 分词\n",
    "    model_inputs = tokenizer(inputs,\n",
    "                             max_length=max_source_length,\n",
    "                             padding=False,\n",
    "                             truncation=True,\n",
    "                             return_attention_mask=True)\n",
    "    labels = tokenizer(targets,\n",
    "                       max_length=max_target_length,\n",
    "                       padding=False,\n",
    "                       truncation=True)\n",
    "    # 得到labels，后续通过DataCollatorForSeq2Seq进行移位\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于预训练模型限制，这里把文本最大长度设置为512\n",
    "# 文本的最大长度\n",
    "max_source_length = 512\n",
    "# 摘要的最大长度\n",
    "max_target_length = 160\n",
    "# 摘要的最小长度\n",
    "min_target_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1117, 131, 1266, 230, 21328, 4054, 13055, 1266, 13048, 1266, 221, 1909, 1857, 5226, 1608, 1909, 26198, 1909, 15944, 39771, 615, 6659, 36230, 791, 10961, 1266, 3399, 4813, 221, 12695, 27871, 1101, 6445, 12695, 1909, 2349, 2355, 791, 1266, 3399, 4659, 23162, 1266, 1608, 21933, 21018, 3399, 2274, 615, 197, 2334, 333, 6659, 36230, 791, 10961, 505, 1608, 1909, 26198, 1909, 10838, 2421, 230, 299, 4919, 2587, 2587, 275, 696, 1227, 13984, 30698, 4920, 2274, 18423, 1909, 25537, 38129, 23167, 1117, 131, 1477, 791, 14093, 1477, 1101, 709, 791, 14093, 5034, 7018, 200, 6800, 39223, 15203, 2274, 22617, 2334, 6683, 10753, 5034, 2274, 18817, 221, 44582, 1266, 3399, 1909, 1608, 21933, 3290, 15944, 1418, 131, 4656, 19164, 23548, 676, 8398, 1979, 435, 1454, 15214, 15214, 1909, 4919, 346, 18739, 23476, 696, 275, 791, 1266, 1909, 1608, 12268, 823, 4599, 1608, 21933, 3851, 1078, 3299, 1117, 131, 4503, 1909, 15944, 15203, 2274, 22617, 2334, 520, 696, 520, 2274, 823, 36566, 3399, 1909, 3441, 3399, 5034, 2274, 1266, 1826, 810, 18578, 19742, 32020, 5661, 5661, 12845, 1909, 9802, 257, 346, 19390, 8603, 28165, 5661, 38929, 25612, 8507, 3399, 8994, 18312, 5661, 5658, 132, 19040, 25175, 21234, 12312, 20869, 5663, 6402, 9165, 6963, 132, 736, 2274, 1963, 506, 3165, 32015, 2274, 823, 1454, 1117, 131, 1909, 30500, 17688, 1909, 30500, 17688, 4539, 15944, 39862, 3851, 33556, 221, 39922, 1909, 3851, 10008, 22048, 381, 1608, 1909, 3441, 2335, 4566, 4919, 13587, 2335, 39922, 4919, 13587, 2274, 823, 1454, 4503, 1909, 1958, 1958, 823, 1266, 667, 1117, 131, 1909, 36230, 791, 10961, 6302, 2274, 6659, 6277, 17676, 752, 645, 7702, 6609, 791, 36613, 791, 5034, 7702, 1076, 2334, 333, 541, 645, 1477, 2713, 1397, 1477, 28950, 4863, 1908, 676, 2334, 1076, 2334, 333, 346, 3851, 8241, 31185, 3399, 17376, 1477, 645, 21250, 7702, 1477, 4503, 20920, 20920, 20920, 1266, 667, 200, 1454, 197, 2334, 1643, 7702, 1909, 1963, 3165, 4919, 1909, 11137, 10465, 15944, 1768, 645, 1909, 23167, 1403, 27226, 1231, 7018, 3399, 36230, 791, 7018, 541, 752, 11192, 4503, 823, 4503, 1266, 30952, 200, 15828, 31185, 1909, 541, 1608, 12268, 1454, 1454, 1454, 1454, 381, 1608, 1909, 26198, 30698, 1266, 3399, 33335, 1608, 615, 1117, 131, 200, 15828, 3583, 25370, 18412, 10144, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [25416, 21704, 21933, 30698, 5661, 18587, 21933, 230, 25416, 22335, 5752, 119, 5805, 5661, 25416, 200, 30450, 5661, 3624, 28967, 11192, 3399, 676, 1625, 7155, 5661, 18587, 19443, 31080, 810, 25416, 22434, 30374, 25416, 308, 200, 30450, 5661, 25416, 30255, 18587, 22048, 12064, 5661, 4659, 14290, 30952, 179, 1]}\n",
      "{'input_ids': [1418, 131, 1909, 5226, 1909, 1934, 2355, 791, 3505, 718, 3399, 15132, 2274, 299, 5661, 3181, 718, 3399, 221, 299, 1909, 2421, 1909, 32808, 22617, 2334, 3399, 221, 2274, 5737, 13984, 3399, 221, 15132, 4749, 1909, 20905, 5687, 13984, 1117, 131, 1266, 34896, 3851, 3441, 4659, 1266, 1909, 3441, 12695, 3441, 2274, 2335, 5687, 13984, 3399, 14093, 15132, 31185, 11192, 5710, 13984, 5693, 221, 148, 3399, 31393, 8630, 7155, 5737, 13984, 1418, 131, 1909, 23165, 645, 5710, 13984, 5693, 221, 148, 3399, 7155, 1117, 131, 7155, 21002, 43168, 1625, 5680, 2334, 122, 791, 1477, 25361, 3399, 7005, 4656, 10833, 11192, 3399, 1418, 131, 1909, 26331, 1909, 2274, 4656, 1909, 23165, 4595, 7155, 1909, 30500, 2274, 4903, 21264, 3851, 1909, 483, 4913, 7155, 4656, 299, 200, 5279, 221, 23548, 299, 3399, 4656, 4599, 1909, 11624, 221, 1909, 4656, 1909, 200, 33894, 1909, 4656, 1909, 21500, 221, 5687, 13984, 3399, 221, 15132, 1477, 14542, 200, 33894, 221, 205, 1909, 15928, 4813, 17554, 5034, 2335, 28165, 4656, 1418, 131, 12256, 28967, 8430, 23165, 11192, 4913, 18974, 4955, 430, 4749, 5745, 501, 2469, 1729, 5758, 48561, 23548, 5659, 2588, 2334, 25361, 12785, 5680, 221, 2334, 5660, 5661, 3192, 1454, 22637, 5737, 501, 31185, 200, 30450, 5661, 30255, 1117, 131, 22048, 12064, 1626, 13595, 5661, 5661, 5658, 4903, 2274, 2335, 5693, 221, 148, 3399, 23548, 7018, 41212, 23548, 1397, 346, 1943, 4749, 3399, 1418, 131, 1909, 1645, 32808, 1909, 5034, 2335, 1909, 7389, 21264, 3851, 1909, 1939, 4913, 25537, 1909, 4656, 1909, 4656, 1909, 2335, 1909, 2335, 43602, 1909, 15928, 23165, 43602, 1909, 1101, 14435, 20869, 17819, 17819, 1909, 5034, 200, 33894, 15132, 1117, 131, 1266, 1909, 1608, 30499, 12268, 33335, 34896, 541, 28448, 3705, 17810, 131, 1909, 5034, 200, 20920, 381, 1909, 32036, 4903, 2335, 217, 17242, 200, 2602, 192, 2588, 2335, 7319, 3851, 1909, 1939, 4913, 25537, 1909, 4656, 1909, 200, 33894, 7222, 1909, 200, 20920, 1909, 4920, 4920, 25160, 20995, 11054, 1909, 3441, 1909, 1768, 346, 1943, 1909, 5737, 13984, 3299, 4637, 4749, 2334, 15132, 1117, 131, 1454, 4656, 1909, 25160, 1608, 30499, 12268, 7703, 346, 2335, 7117, 3399, 45233, 22048, 3851, 13595, 25537, 1266, 823, 1117, 131, 1266, 34896, 541, 28448, 27228, 30824, 33335, 1117, 131, 1266, 3583, 25370, 18412, 1266, 10144, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [25416, 21704, 1454, 4872, 12785, 3110, 31393, 8630, 5659, 5626, 5084, 3110, 5660, 2588, 2334, 25361, 7155, 200, 30450, 5661, 18587, 3845, 27517, 21933, 5661, 25416, 43168, 118, 5680, 118, 5667, 5666, 131, 5666, 131, 5666, 17406, 25361, 5661, 25416, 17628, 200, 30450, 5661, 30255, 18587, 27922, 4941, 4749, 5661, 4659, 14290, 5661, 30952, 1]}\n"
     ]
    }
   ],
   "source": [
    "#使用partial函数指定默认参数，使用map函数转换数据。map函数把原来的文本根据词汇表的编号转换成了相应的id，为了便于理解，这里把训练集合的部分样本展示出来。\n",
    "# 定义转换器\n",
    "trans_func = partial(convert_example,\n",
    "                     text_column='content',\n",
    "                     summary_column='abstract',\n",
    "                     tokenizer=tokenizer,\n",
    "                     max_source_length=max_source_length,\n",
    "                     max_target_length=max_target_length)\n",
    "                     \n",
    "# train_dataset和dev_dataset分别转换\n",
    "train_dataset = train_dataset.map(trans_func,\n",
    "                                  batched=False,\n",
    "                                  lazy =False)\n",
    "\n",
    "dev_dataset = dev_dataset.map(trans_func,\n",
    "                              batched=False,\n",
    "                            lazy =False)\n",
    "# 输出训练集的前 2 条样本\n",
    "for idx, example in enumerate(train_dataset):\n",
    "    if idx < 2:\n",
    "        print(example) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader  = paddle.io.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    return_list=True,\n",
    "    collate_fn=batchify_fn)\n",
    "dev_batch_sampler  = BatchSampler(\n",
    "    dataset=dev_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 构造测试Dataloader\n",
    "dev_data_loader = DataLoader(dataset=dev_dataset,\n",
    "                             batch_sampler=dev_batch_sampler,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=batchify_fn,\n",
    "                             return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率预热比例\n",
    "warmup = 0.02\n",
    "# 学习率\n",
    "learning_rate = 5e-5\n",
    "# 训练轮次\n",
    "num_epochs =50\n",
    "# 训练总步数\n",
    "num_training_steps = len(train_data_loader) * num_epochs\n",
    "# AdamW优化器参数epsilon\n",
    "adam_epsilon = 1e-6\n",
    "# AdamW优化器参数weight_decay\n",
    "weight_decay=0.01\n",
    "# 训练中，每100个log_steps打印一次日志\n",
    "log_steps = 100\n",
    "# 训练中，每隔eval_steps进行一次模型评估\n",
    "eval_steps = 10000\n",
    "# 使用SSTIA\n",
    "model.use_SSTIA = True\n",
    "model.mix_ratio = 0.3\n",
    "\n",
    "\n",
    "# 训练模型保存路径\n",
    "output_dir = 'checkpoints'\n",
    "# 解码beam size\n",
    "num_beams = 4\n",
    "\n",
    "log_writer = LogWriter('visualdl_log_dir')\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup)\n",
    "\n",
    "# LayerNorm参数不参与weight_decay\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 优化器AdamW\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    epsilon=adam_epsilon,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156300\n"
     ]
    }
   ],
   "source": [
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算训练评估参数Rouge-1，Rouge-2，Rouge-L\n",
    "def compute_metrics(preds, targets):\n",
    "    assert len(preds) == len(targets), (\n",
    "        'The length of pred_responses should be equal to the length of '\n",
    "        'target_responses. But received {} and {}.'.format(\n",
    "            len(preds), len(targets)))\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    scores = []\n",
    "    for pred, target in zip(preds, targets):\n",
    "        try:\n",
    "            score = rouge.get_scores(' '.join(pred), ' '.join(target))\n",
    "            scores.append([\n",
    "                score[0]['rouge-1']['f'], score[0]['rouge-2']['f'],\n",
    "                score[0]['rouge-l']['f']\n",
    "            ])\n",
    "        except ValueError:\n",
    "            scores.append([0, 0, 0])\n",
    "    rouge1 = np.mean([i[0] for i in scores])\n",
    "    rouge2 = np.mean([i[1] for i in scores])\n",
    "    rougel = np.mean([i[2] for i in scores])\n",
    "    \n",
    "    print('\\n' + '*' * 15)\n",
    "    print('The auto evaluation result is:')\n",
    "    print('rouge-1:', round(rouge1*100, 2))\n",
    "    print('rouge-2:', round(rouge2*100, 2))\n",
    "    print('rouge-L:', round(rougel*100, 2))\n",
    "   \n",
    "    return rouge1, rouge2, rougel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估函数\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, data_loader, tokenizer, min_target_length,\n",
    "             max_target_length):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    model = model._layers if isinstance(model, paddle.DataParallel) else model\n",
    "    for batch in tqdm(data_loader, total=len(data_loader), desc=\"Eval step\"):\n",
    "        labels = batch.pop('labels').numpy()\n",
    "        # 模型生成\n",
    "        preds = model.generate(input_ids=batch['input_ids'],\n",
    "                               attention_mask=batch['attention_mask'],\n",
    "                               min_length=min_target_length,\n",
    "                               max_length=max_target_length,\n",
    "                               decode_strategy='greedy_search',\n",
    "                               use_cache=True)[0]\n",
    "        # tokenizer将id转为string\n",
    "        all_preds.extend(\n",
    "            tokenizer.batch_decode(preds.numpy(),\n",
    "                                   skip_special_tokens=True,\n",
    "                                   clean_up_tokenization_spaces=False))\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        all_labels.extend(\n",
    "            tokenizer.batch_decode(labels,\n",
    "                                   skip_special_tokens=True,\n",
    "                                   clean_up_tokenization_spaces=False))\n",
    "    rouge1, rouge2, rougel= compute_metrics(all_preds, all_labels)\n",
    "    model.train()\n",
    "    return rouge1, rouge2, rougel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data_loader):\n",
    "    eval_steps = 20000\n",
    "    global_step = 0\n",
    "    best_rougel = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, batch in enumerate(train_data_loader):\n",
    "            global_step += 1\n",
    "            # 模型前向训练，计算loss\n",
    "            lm_logits, _, loss = model(**batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            if global_step % log_steps == 0:\n",
    "                logger.info(\n",
    "                    \"global step %d/%d, epoch: %d, batch: %d, rank_id: %s, loss: %f, lr: %.10f, speed: %.4f step/s\"\n",
    "                    % (global_step, num_training_steps, epoch, step,\n",
    "                        paddle.distributed.get_rank(), loss, optimizer.get_lr(),\n",
    "                        log_steps / (time.time() - tic_train)))\n",
    "                log_writer.add_scalar(\"train_loss\", loss.numpy(), global_step)\n",
    "                tic_train = time.time()\n",
    "#             if global_step % eval_steps == 0 or global_step == num_training_steps or global_step in [10,6000,10000]:\n",
    "#                 tic_eval = time.time()\n",
    "#                 rouge1, rouge2, rougel = evaluate(model, dev_data_loader, tokenizer,\n",
    "#                             min_target_length, max_target_length)\n",
    "#                 logger.info(\"eval done total : %s s\" % (time.time() - tic_eval))\n",
    "#                 log_writer.add_scalar(\"eval_rouge1\", rouge1, global_step)\n",
    "#                 log_writer.add_scalar(\"eval_rouge2\", rouge2, global_step)\n",
    "#                 log_writer.add_scalar(\"eval_rougel\", rougel, global_step)\n",
    "#                 if best_rougel < rougel:\n",
    "#                     best_rougel = rougel\n",
    "#                     if paddle.distributed.get_rank() == 0:\n",
    "#                         if not os.path.exists(output_dir):\n",
    "#                             os.makedirs(output_dir)\n",
    "#                         # Need better way to get inner model of DataParallel\n",
    "#                         model_to_save = model._layers if isinstance(\n",
    "#                             model, paddle.DataParallel) else model\n",
    "#                         model_to_save.save_pretrained(output_dir)\n",
    "#                         tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "            if global_step % eval_steps == 0 or global_step == num_training_steps or global_step in [0,1000,140000,150000]:\n",
    "                if paddle.distributed.get_rank() == 0:\n",
    "                        if not os.path.exists(output_dir):\n",
    "                            os.makedirs(output_dir)\n",
    "                        # Need better way to get inner model of DataParallel\n",
    "                        model_to_save = model._layers if isinstance(\n",
    "                            model, paddle.DataParallel) else model\n",
    "                        model_to_save.save_pretrained(output_dir)\n",
    "                        tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-05 22:28:40,360] [    INFO]\u001B[0m - global step 100/156300, epoch: 0, batch: 99, rank_id: 0, loss: 3.599521, lr: 0.0000018234, speed: 0.9260 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:30:33,192] [    INFO]\u001B[0m - global step 200/156300, epoch: 0, batch: 199, rank_id: 0, loss: 2.158661, lr: 0.0000034229, speed: 0.8864 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:32:26,325] [    INFO]\u001B[0m - global step 300/156300, epoch: 0, batch: 299, rank_id: 0, loss: 2.505717, lr: 0.0000050224, speed: 0.8840 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:34:18,029] [    INFO]\u001B[0m - global step 400/156300, epoch: 0, batch: 399, rank_id: 0, loss: 2.098660, lr: 0.0000066219, speed: 0.8954 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:36:04,628] [    INFO]\u001B[0m - global step 500/156300, epoch: 0, batch: 499, rank_id: 0, loss: 2.317709, lr: 0.0000082214, speed: 0.9382 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:37:55,498] [    INFO]\u001B[0m - global step 600/156300, epoch: 0, batch: 599, rank_id: 0, loss: 1.524417, lr: 0.0000098209, speed: 0.9021 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:39:45,066] [    INFO]\u001B[0m - global step 700/156300, epoch: 0, batch: 699, rank_id: 0, loss: 1.544491, lr: 0.0000114203, speed: 0.9128 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:41:35,538] [    INFO]\u001B[0m - global step 800/156300, epoch: 0, batch: 799, rank_id: 0, loss: 1.876875, lr: 0.0000130198, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:43:26,097] [    INFO]\u001B[0m - global step 900/156300, epoch: 0, batch: 899, rank_id: 0, loss: 1.633811, lr: 0.0000146193, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:45:17,963] [    INFO]\u001B[0m - global step 1000/156300, epoch: 0, batch: 999, rank_id: 0, loss: 1.647238, lr: 0.0000162188, speed: 0.8941 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:45:20,377] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:45:20,379] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:47:11,283] [    INFO]\u001B[0m - global step 1100/156300, epoch: 0, batch: 1099, rank_id: 0, loss: 1.118163, lr: 0.0000178183, speed: 0.8826 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:49:04,840] [    INFO]\u001B[0m - global step 1200/156300, epoch: 0, batch: 1199, rank_id: 0, loss: 0.564864, lr: 0.0000194178, speed: 0.8807 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:50:58,884] [    INFO]\u001B[0m - global step 1300/156300, epoch: 0, batch: 1299, rank_id: 0, loss: 1.523534, lr: 0.0000210173, speed: 0.8770 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:52:45,490] [    INFO]\u001B[0m - global step 1400/156300, epoch: 0, batch: 1399, rank_id: 0, loss: 1.928896, lr: 0.0000226168, speed: 0.9382 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:54:35,220] [    INFO]\u001B[0m - global step 1500/156300, epoch: 0, batch: 1499, rank_id: 0, loss: 1.404426, lr: 0.0000242163, speed: 0.9115 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:56:22,787] [    INFO]\u001B[0m - global step 1600/156300, epoch: 0, batch: 1599, rank_id: 0, loss: 1.797077, lr: 0.0000258157, speed: 0.9298 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 22:58:12,507] [    INFO]\u001B[0m - global step 1700/156300, epoch: 0, batch: 1699, rank_id: 0, loss: 1.867324, lr: 0.0000274152, speed: 0.9115 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:00:06,696] [    INFO]\u001B[0m - global step 1800/156300, epoch: 0, batch: 1799, rank_id: 0, loss: 1.284996, lr: 0.0000290147, speed: 0.8759 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:01:59,399] [    INFO]\u001B[0m - global step 1900/156300, epoch: 0, batch: 1899, rank_id: 0, loss: 1.014055, lr: 0.0000306142, speed: 0.8874 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:03:45,603] [    INFO]\u001B[0m - global step 2000/156300, epoch: 0, batch: 1999, rank_id: 0, loss: 0.925189, lr: 0.0000322137, speed: 0.9417 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:05:36,284] [    INFO]\u001B[0m - global step 2100/156300, epoch: 0, batch: 2099, rank_id: 0, loss: 0.904008, lr: 0.0000338132, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:07:22,636] [    INFO]\u001B[0m - global step 2200/156300, epoch: 0, batch: 2199, rank_id: 0, loss: 1.158919, lr: 0.0000354127, speed: 0.9404 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:09:12,586] [    INFO]\u001B[0m - global step 2300/156300, epoch: 0, batch: 2299, rank_id: 0, loss: 1.380511, lr: 0.0000370122, speed: 0.9096 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:11:02,944] [    INFO]\u001B[0m - global step 2400/156300, epoch: 0, batch: 2399, rank_id: 0, loss: 1.291505, lr: 0.0000386116, speed: 0.9063 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:12:56,655] [    INFO]\u001B[0m - global step 2500/156300, epoch: 0, batch: 2499, rank_id: 0, loss: 1.033425, lr: 0.0000402111, speed: 0.8795 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:14:51,949] [    INFO]\u001B[0m - global step 2600/156300, epoch: 0, batch: 2599, rank_id: 0, loss: 1.235872, lr: 0.0000418106, speed: 0.8675 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:16:43,393] [    INFO]\u001B[0m - global step 2700/156300, epoch: 0, batch: 2699, rank_id: 0, loss: 1.076244, lr: 0.0000434101, speed: 0.8974 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:18:34,474] [    INFO]\u001B[0m - global step 2800/156300, epoch: 0, batch: 2799, rank_id: 0, loss: 1.321153, lr: 0.0000450096, speed: 0.9004 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:20:26,402] [    INFO]\u001B[0m - global step 2900/156300, epoch: 0, batch: 2899, rank_id: 0, loss: 1.064094, lr: 0.0000466091, speed: 0.8936 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:22:17,037] [    INFO]\u001B[0m - global step 3000/156300, epoch: 0, batch: 2999, rank_id: 0, loss: 1.866177, lr: 0.0000482086, speed: 0.9040 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:24:06,263] [    INFO]\u001B[0m - global step 3100/156300, epoch: 0, batch: 3099, rank_id: 0, loss: 1.754222, lr: 0.0000498081, speed: 0.9157 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:25:54,702] [    INFO]\u001B[0m - global step 3200/156300, epoch: 1, batch: 73, rank_id: 0, loss: 1.277122, lr: 0.0000499713, speed: 0.9223 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:27:45,765] [    INFO]\u001B[0m - global step 3300/156300, epoch: 1, batch: 173, rank_id: 0, loss: 1.016581, lr: 0.0000499386, speed: 0.9005 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:29:39,410] [    INFO]\u001B[0m - global step 3400/156300, epoch: 1, batch: 273, rank_id: 0, loss: 0.955988, lr: 0.0000499060, speed: 0.8801 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:31:31,914] [    INFO]\u001B[0m - global step 3500/156300, epoch: 1, batch: 373, rank_id: 0, loss: 0.859930, lr: 0.0000498733, speed: 0.8890 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:33:20,801] [    INFO]\u001B[0m - global step 3600/156300, epoch: 1, batch: 473, rank_id: 0, loss: 0.521143, lr: 0.0000498407, speed: 0.9185 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:35:09,732] [    INFO]\u001B[0m - global step 3700/156300, epoch: 1, batch: 573, rank_id: 0, loss: 1.695827, lr: 0.0000498081, speed: 0.9181 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:36:58,774] [    INFO]\u001B[0m - global step 3800/156300, epoch: 1, batch: 673, rank_id: 0, loss: 1.516829, lr: 0.0000497754, speed: 0.9172 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:38:50,833] [    INFO]\u001B[0m - global step 3900/156300, epoch: 1, batch: 773, rank_id: 0, loss: 0.859546, lr: 0.0000497428, speed: 0.8925 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:40:43,016] [    INFO]\u001B[0m - global step 4000/156300, epoch: 1, batch: 873, rank_id: 0, loss: 0.730728, lr: 0.0000497101, speed: 0.8915 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:42:31,797] [    INFO]\u001B[0m - global step 4100/156300, epoch: 1, batch: 973, rank_id: 0, loss: 1.400193, lr: 0.0000496775, speed: 0.9194 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:44:22,814] [    INFO]\u001B[0m - global step 4200/156300, epoch: 1, batch: 1073, rank_id: 0, loss: 1.161428, lr: 0.0000496448, speed: 0.9009 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:46:16,657] [    INFO]\u001B[0m - global step 4300/156300, epoch: 1, batch: 1173, rank_id: 0, loss: 1.510290, lr: 0.0000496122, speed: 0.8785 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:48:09,567] [    INFO]\u001B[0m - global step 4400/156300, epoch: 1, batch: 1273, rank_id: 0, loss: 0.991033, lr: 0.0000495796, speed: 0.8858 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:49:58,526] [    INFO]\u001B[0m - global step 4500/156300, epoch: 1, batch: 1373, rank_id: 0, loss: 0.688121, lr: 0.0000495469, speed: 0.9179 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:51:47,139] [    INFO]\u001B[0m - global step 4600/156300, epoch: 1, batch: 1473, rank_id: 0, loss: 1.188174, lr: 0.0000495143, speed: 0.9208 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:53:36,469] [    INFO]\u001B[0m - global step 4700/156300, epoch: 1, batch: 1573, rank_id: 0, loss: 1.482985, lr: 0.0000494816, speed: 0.9148 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:55:25,814] [    INFO]\u001B[0m - global step 4800/156300, epoch: 1, batch: 1673, rank_id: 0, loss: 0.631064, lr: 0.0000494490, speed: 0.9147 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-05 23:57:17,868] [    INFO]\u001B[0m - global step 4900/156300, epoch: 1, batch: 1773, rank_id: 0, loss: 1.378705, lr: 0.0000494164, speed: 0.8926 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-05 23:59:07,226] [    INFO]\u001B[0m - global step 5000/156300, epoch: 1, batch: 1873, rank_id: 0, loss: 1.137408, lr: 0.0000493837, speed: 0.9146 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:00:59,741] [    INFO]\u001B[0m - global step 5100/156300, epoch: 1, batch: 1973, rank_id: 0, loss: 0.984272, lr: 0.0000493511, speed: 0.8889 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:02:48,769] [    INFO]\u001B[0m - global step 5200/156300, epoch: 1, batch: 2073, rank_id: 0, loss: 1.023719, lr: 0.0000493184, speed: 0.9173 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:04:34,926] [    INFO]\u001B[0m - global step 5300/156300, epoch: 1, batch: 2173, rank_id: 0, loss: 0.841073, lr: 0.0000492858, speed: 0.9421 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:06:26,500] [    INFO]\u001B[0m - global step 5400/156300, epoch: 1, batch: 2273, rank_id: 0, loss: 0.502050, lr: 0.0000492531, speed: 0.8964 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:08:17,217] [    INFO]\u001B[0m - global step 5500/156300, epoch: 1, batch: 2373, rank_id: 0, loss: 1.058246, lr: 0.0000492205, speed: 0.9033 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:10:07,801] [    INFO]\u001B[0m - global step 5600/156300, epoch: 1, batch: 2473, rank_id: 0, loss: 0.882702, lr: 0.0000491879, speed: 0.9044 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:12:01,349] [    INFO]\u001B[0m - global step 5700/156300, epoch: 1, batch: 2573, rank_id: 0, loss: 0.490458, lr: 0.0000491552, speed: 0.8808 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:13:58,643] [    INFO]\u001B[0m - global step 5800/156300, epoch: 1, batch: 2673, rank_id: 0, loss: 0.868047, lr: 0.0000491226, speed: 0.8527 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:15:46,312] [    INFO]\u001B[0m - global step 5900/156300, epoch: 1, batch: 2773, rank_id: 0, loss: 1.060168, lr: 0.0000490899, speed: 0.9289 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:17:37,526] [    INFO]\u001B[0m - global step 6000/156300, epoch: 1, batch: 2873, rank_id: 0, loss: 0.822660, lr: 0.0000490573, speed: 0.8993 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:19:27,827] [    INFO]\u001B[0m - global step 6100/156300, epoch: 1, batch: 2973, rank_id: 0, loss: 1.222843, lr: 0.0000490246, speed: 0.9067 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:21:18,942] [    INFO]\u001B[0m - global step 6200/156300, epoch: 1, batch: 3073, rank_id: 0, loss: 0.651783, lr: 0.0000489920, speed: 0.9001 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:23:07,343] [    INFO]\u001B[0m - global step 6300/156300, epoch: 2, batch: 47, rank_id: 0, loss: 0.893591, lr: 0.0000489594, speed: 0.9226 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:24:56,030] [    INFO]\u001B[0m - global step 6400/156300, epoch: 2, batch: 147, rank_id: 0, loss: 1.275176, lr: 0.0000489267, speed: 0.9202 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:26:51,363] [    INFO]\u001B[0m - global step 6500/156300, epoch: 2, batch: 247, rank_id: 0, loss: 0.998123, lr: 0.0000488941, speed: 0.8672 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:28:45,025] [    INFO]\u001B[0m - global step 6600/156300, epoch: 2, batch: 347, rank_id: 0, loss: 0.559967, lr: 0.0000488614, speed: 0.8799 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:30:33,827] [    INFO]\u001B[0m - global step 6700/156300, epoch: 2, batch: 447, rank_id: 0, loss: 0.941210, lr: 0.0000488288, speed: 0.9192 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:32:21,254] [    INFO]\u001B[0m - global step 6800/156300, epoch: 2, batch: 547, rank_id: 0, loss: 0.625627, lr: 0.0000487961, speed: 0.9310 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:34:12,622] [    INFO]\u001B[0m - global step 6900/156300, epoch: 2, batch: 647, rank_id: 0, loss: 0.882144, lr: 0.0000487635, speed: 0.8981 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:36:03,519] [    INFO]\u001B[0m - global step 7000/156300, epoch: 2, batch: 747, rank_id: 0, loss: 0.847017, lr: 0.0000487309, speed: 0.9019 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:37:55,061] [    INFO]\u001B[0m - global step 7100/156300, epoch: 2, batch: 847, rank_id: 0, loss: 0.843375, lr: 0.0000486982, speed: 0.8966 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:39:44,810] [    INFO]\u001B[0m - global step 7200/156300, epoch: 2, batch: 947, rank_id: 0, loss: 0.996048, lr: 0.0000486656, speed: 0.9113 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:41:36,868] [    INFO]\u001B[0m - global step 7300/156300, epoch: 2, batch: 1047, rank_id: 0, loss: 0.802740, lr: 0.0000486329, speed: 0.8925 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:43:27,895] [    INFO]\u001B[0m - global step 7400/156300, epoch: 2, batch: 1147, rank_id: 0, loss: 1.257986, lr: 0.0000486003, speed: 0.9008 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:45:21,703] [    INFO]\u001B[0m - global step 7500/156300, epoch: 2, batch: 1247, rank_id: 0, loss: 0.692841, lr: 0.0000485676, speed: 0.8788 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:47:13,010] [    INFO]\u001B[0m - global step 7600/156300, epoch: 2, batch: 1347, rank_id: 0, loss: 0.391922, lr: 0.0000485350, speed: 0.8985 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:49:01,559] [    INFO]\u001B[0m - global step 7700/156300, epoch: 2, batch: 1447, rank_id: 0, loss: 0.936011, lr: 0.0000485024, speed: 0.9214 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:50:50,153] [    INFO]\u001B[0m - global step 7800/156300, epoch: 2, batch: 1547, rank_id: 0, loss: 1.111442, lr: 0.0000484697, speed: 0.9210 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:52:40,725] [    INFO]\u001B[0m - global step 7900/156300, epoch: 2, batch: 1647, rank_id: 0, loss: 0.971864, lr: 0.0000484371, speed: 0.9045 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:54:33,869] [    INFO]\u001B[0m - global step 8000/156300, epoch: 2, batch: 1747, rank_id: 0, loss: 0.328538, lr: 0.0000484044, speed: 0.8839 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:56:21,931] [    INFO]\u001B[0m - global step 8100/156300, epoch: 2, batch: 1847, rank_id: 0, loss: 0.720831, lr: 0.0000483718, speed: 0.9255 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 00:58:12,955] [    INFO]\u001B[0m - global step 8200/156300, epoch: 2, batch: 1947, rank_id: 0, loss: 0.930662, lr: 0.0000483391, speed: 0.9008 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:00:01,750] [    INFO]\u001B[0m - global step 8300/156300, epoch: 2, batch: 2047, rank_id: 0, loss: 0.490528, lr: 0.0000483065, speed: 0.9193 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:01:49,183] [    INFO]\u001B[0m - global step 8400/156300, epoch: 2, batch: 2147, rank_id: 0, loss: 0.992221, lr: 0.0000482739, speed: 0.9309 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:03:42,244] [    INFO]\u001B[0m - global step 8500/156300, epoch: 2, batch: 2247, rank_id: 0, loss: 0.941359, lr: 0.0000482412, speed: 0.8846 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:05:30,540] [    INFO]\u001B[0m - global step 8600/156300, epoch: 2, batch: 2347, rank_id: 0, loss: 0.433099, lr: 0.0000482086, speed: 0.9235 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:07:21,438] [    INFO]\u001B[0m - global step 8700/156300, epoch: 2, batch: 2447, rank_id: 0, loss: 0.852351, lr: 0.0000481759, speed: 0.9019 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:09:17,208] [    INFO]\u001B[0m - global step 8800/156300, epoch: 2, batch: 2547, rank_id: 0, loss: 1.276772, lr: 0.0000481433, speed: 0.8639 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:11:13,223] [    INFO]\u001B[0m - global step 8900/156300, epoch: 2, batch: 2647, rank_id: 0, loss: 0.427984, lr: 0.0000481106, speed: 0.8621 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:13:01,523] [    INFO]\u001B[0m - global step 9000/156300, epoch: 2, batch: 2747, rank_id: 0, loss: 0.884517, lr: 0.0000480780, speed: 0.9235 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:14:54,252] [    INFO]\u001B[0m - global step 9100/156300, epoch: 2, batch: 2847, rank_id: 0, loss: 0.409440, lr: 0.0000480454, speed: 0.8872 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:16:42,970] [    INFO]\u001B[0m - global step 9200/156300, epoch: 2, batch: 2947, rank_id: 0, loss: 0.880620, lr: 0.0000480127, speed: 0.9199 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:18:33,591] [    INFO]\u001B[0m - global step 9300/156300, epoch: 2, batch: 3047, rank_id: 0, loss: 0.794880, lr: 0.0000479801, speed: 0.9041 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:20:22,811] [    INFO]\u001B[0m - global step 9400/156300, epoch: 3, batch: 21, rank_id: 0, loss: 0.559026, lr: 0.0000479474, speed: 0.9157 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:22:12,956] [    INFO]\u001B[0m - global step 9500/156300, epoch: 3, batch: 121, rank_id: 0, loss: 0.787029, lr: 0.0000479148, speed: 0.9080 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:24:04,132] [    INFO]\u001B[0m - global step 9600/156300, epoch: 3, batch: 221, rank_id: 0, loss: 0.638089, lr: 0.0000478821, speed: 0.8996 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:25:58,712] [    INFO]\u001B[0m - global step 9700/156300, epoch: 3, batch: 321, rank_id: 0, loss: 0.706392, lr: 0.0000478495, speed: 0.8729 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:27:48,504] [    INFO]\u001B[0m - global step 9800/156300, epoch: 3, batch: 421, rank_id: 0, loss: 1.003799, lr: 0.0000478169, speed: 0.9109 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 01:29:35,892] [    INFO]\u001B[0m - global step 9900/156300, epoch: 3, batch: 521, rank_id: 0, loss: 0.697300, lr: 0.0000477842, speed: 0.9313 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:31:28,004] [    INFO]\u001B[0m - global step 10000/156300, epoch: 3, batch: 621, rank_id: 0, loss: 0.603186, lr: 0.0000477516, speed: 0.8921 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:33:17,832] [    INFO]\u001B[0m - global step 10100/156300, epoch: 3, batch: 721, rank_id: 0, loss: 0.652068, lr: 0.0000477189, speed: 0.9106 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:35:08,032] [    INFO]\u001B[0m - global step 10200/156300, epoch: 3, batch: 821, rank_id: 0, loss: 0.954892, lr: 0.0000476863, speed: 0.9076 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:37:00,951] [    INFO]\u001B[0m - global step 10300/156300, epoch: 3, batch: 921, rank_id: 0, loss: 0.937043, lr: 0.0000476536, speed: 0.8857 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:38:51,690] [    INFO]\u001B[0m - global step 10400/156300, epoch: 3, batch: 1021, rank_id: 0, loss: 0.705247, lr: 0.0000476210, speed: 0.9032 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:40:41,634] [    INFO]\u001B[0m - global step 10500/156300, epoch: 3, batch: 1121, rank_id: 0, loss: 0.942596, lr: 0.0000475884, speed: 0.9097 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:42:34,922] [    INFO]\u001B[0m - global step 10600/156300, epoch: 3, batch: 1221, rank_id: 0, loss: 0.554342, lr: 0.0000475557, speed: 0.8828 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:44:29,990] [    INFO]\u001B[0m - global step 10700/156300, epoch: 3, batch: 1321, rank_id: 0, loss: 1.182860, lr: 0.0000475231, speed: 0.8692 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:46:16,084] [    INFO]\u001B[0m - global step 10800/156300, epoch: 3, batch: 1421, rank_id: 0, loss: 0.386076, lr: 0.0000474904, speed: 0.9427 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:48:07,315] [    INFO]\u001B[0m - global step 10900/156300, epoch: 3, batch: 1521, rank_id: 0, loss: 0.979573, lr: 0.0000474578, speed: 0.8992 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:49:55,103] [    INFO]\u001B[0m - global step 11000/156300, epoch: 3, batch: 1621, rank_id: 0, loss: 0.513845, lr: 0.0000474252, speed: 0.9279 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:51:47,401] [    INFO]\u001B[0m - global step 11100/156300, epoch: 3, batch: 1721, rank_id: 0, loss: 0.554423, lr: 0.0000473925, speed: 0.8906 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:53:39,031] [    INFO]\u001B[0m - global step 11200/156300, epoch: 3, batch: 1821, rank_id: 0, loss: 0.710987, lr: 0.0000473599, speed: 0.8959 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:55:29,539] [    INFO]\u001B[0m - global step 11300/156300, epoch: 3, batch: 1921, rank_id: 0, loss: 0.676623, lr: 0.0000473272, speed: 0.9050 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:57:17,563] [    INFO]\u001B[0m - global step 11400/156300, epoch: 3, batch: 2021, rank_id: 0, loss: 0.664370, lr: 0.0000472946, speed: 0.9259 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 01:59:07,717] [    INFO]\u001B[0m - global step 11500/156300, epoch: 3, batch: 2121, rank_id: 0, loss: 0.739017, lr: 0.0000472619, speed: 0.9080 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:00:56,586] [    INFO]\u001B[0m - global step 11600/156300, epoch: 3, batch: 2221, rank_id: 0, loss: 1.057622, lr: 0.0000472293, speed: 0.9187 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:02:45,265] [    INFO]\u001B[0m - global step 11700/156300, epoch: 3, batch: 2321, rank_id: 0, loss: 0.861281, lr: 0.0000471967, speed: 0.9203 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:04:36,161] [    INFO]\u001B[0m - global step 11800/156300, epoch: 3, batch: 2421, rank_id: 0, loss: 0.833124, lr: 0.0000471640, speed: 0.9019 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:06:29,659] [    INFO]\u001B[0m - global step 11900/156300, epoch: 3, batch: 2521, rank_id: 0, loss: 0.762725, lr: 0.0000471314, speed: 0.8812 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:08:27,718] [    INFO]\u001B[0m - global step 12000/156300, epoch: 3, batch: 2621, rank_id: 0, loss: 0.732281, lr: 0.0000470987, speed: 0.8472 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:10:16,131] [    INFO]\u001B[0m - global step 12100/156300, epoch: 3, batch: 2721, rank_id: 0, loss: 0.661477, lr: 0.0000470661, speed: 0.9225 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:12:09,641] [    INFO]\u001B[0m - global step 12200/156300, epoch: 3, batch: 2821, rank_id: 0, loss: 0.674170, lr: 0.0000470334, speed: 0.8811 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:13:59,021] [    INFO]\u001B[0m - global step 12300/156300, epoch: 3, batch: 2921, rank_id: 0, loss: 0.850405, lr: 0.0000470008, speed: 0.9144 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:15:50,547] [    INFO]\u001B[0m - global step 12400/156300, epoch: 3, batch: 3021, rank_id: 0, loss: 0.738883, lr: 0.0000469682, speed: 0.8968 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:17:40,419] [    INFO]\u001B[0m - global step 12500/156300, epoch: 3, batch: 3121, rank_id: 0, loss: 0.726486, lr: 0.0000469355, speed: 0.9103 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:19:28,310] [    INFO]\u001B[0m - global step 12600/156300, epoch: 4, batch: 95, rank_id: 0, loss: 0.638357, lr: 0.0000469029, speed: 0.9270 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:21:20,153] [    INFO]\u001B[0m - global step 12700/156300, epoch: 4, batch: 195, rank_id: 0, loss: 0.340133, lr: 0.0000468702, speed: 0.8942 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:23:15,027] [    INFO]\u001B[0m - global step 12800/156300, epoch: 4, batch: 295, rank_id: 0, loss: 0.469879, lr: 0.0000468376, speed: 0.8706 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:25:05,951] [    INFO]\u001B[0m - global step 12900/156300, epoch: 4, batch: 395, rank_id: 0, loss: 0.486861, lr: 0.0000468049, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:26:52,868] [    INFO]\u001B[0m - global step 13000/156300, epoch: 4, batch: 495, rank_id: 0, loss: 0.362641, lr: 0.0000467723, speed: 0.9354 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:28:43,907] [    INFO]\u001B[0m - global step 13100/156300, epoch: 4, batch: 595, rank_id: 0, loss: 0.585476, lr: 0.0000467397, speed: 0.9007 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:30:34,408] [    INFO]\u001B[0m - global step 13200/156300, epoch: 4, batch: 695, rank_id: 0, loss: 0.280563, lr: 0.0000467070, speed: 0.9051 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:32:24,137] [    INFO]\u001B[0m - global step 13300/156300, epoch: 4, batch: 795, rank_id: 0, loss: 0.964983, lr: 0.0000466744, speed: 0.9115 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:34:16,034] [    INFO]\u001B[0m - global step 13400/156300, epoch: 4, batch: 895, rank_id: 0, loss: 0.711524, lr: 0.0000466417, speed: 0.8938 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:36:06,760] [    INFO]\u001B[0m - global step 13500/156300, epoch: 4, batch: 995, rank_id: 0, loss: 0.429157, lr: 0.0000466091, speed: 0.9033 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:37:57,463] [    INFO]\u001B[0m - global step 13600/156300, epoch: 4, batch: 1095, rank_id: 0, loss: 0.642136, lr: 0.0000465764, speed: 0.9034 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:39:51,787] [    INFO]\u001B[0m - global step 13700/156300, epoch: 4, batch: 1195, rank_id: 0, loss: 0.493225, lr: 0.0000465438, speed: 0.8748 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:41:46,229] [    INFO]\u001B[0m - global step 13800/156300, epoch: 4, batch: 1295, rank_id: 0, loss: 0.610895, lr: 0.0000465112, speed: 0.8739 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:43:33,177] [    INFO]\u001B[0m - global step 13900/156300, epoch: 4, batch: 1395, rank_id: 0, loss: 1.062494, lr: 0.0000464785, speed: 0.9352 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:45:23,130] [    INFO]\u001B[0m - global step 14000/156300, epoch: 4, batch: 1495, rank_id: 0, loss: 0.425101, lr: 0.0000464459, speed: 0.9096 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:47:10,718] [    INFO]\u001B[0m - global step 14100/156300, epoch: 4, batch: 1595, rank_id: 0, loss: 0.796730, lr: 0.0000464132, speed: 0.9296 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:49:00,182] [    INFO]\u001B[0m - global step 14200/156300, epoch: 4, batch: 1695, rank_id: 0, loss: 0.474252, lr: 0.0000463806, speed: 0.9137 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:50:54,667] [    INFO]\u001B[0m - global step 14300/156300, epoch: 4, batch: 1795, rank_id: 0, loss: 0.599816, lr: 0.0000463479, speed: 0.8736 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:52:46,821] [    INFO]\u001B[0m - global step 14400/156300, epoch: 4, batch: 1895, rank_id: 0, loss: 0.502152, lr: 0.0000463153, speed: 0.8918 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:54:34,383] [    INFO]\u001B[0m - global step 14500/156300, epoch: 4, batch: 1995, rank_id: 0, loss: 0.611320, lr: 0.0000462827, speed: 0.9298 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:56:24,512] [    INFO]\u001B[0m - global step 14600/156300, epoch: 4, batch: 2095, rank_id: 0, loss: 0.720696, lr: 0.0000462500, speed: 0.9082 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 02:58:11,578] [    INFO]\u001B[0m - global step 14700/156300, epoch: 4, batch: 2195, rank_id: 0, loss: 0.477542, lr: 0.0000462174, speed: 0.9341 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 03:00:00,514] [    INFO]\u001B[0m - global step 14800/156300, epoch: 4, batch: 2295, rank_id: 0, loss: 0.744137, lr: 0.0000461847, speed: 0.9181 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:01:51,690] [    INFO]\u001B[0m - global step 14900/156300, epoch: 4, batch: 2395, rank_id: 0, loss: 0.836293, lr: 0.0000461521, speed: 0.8996 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:03:44,465] [    INFO]\u001B[0m - global step 15000/156300, epoch: 4, batch: 2495, rank_id: 0, loss: 0.738998, lr: 0.0000461194, speed: 0.8868 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:05:40,502] [    INFO]\u001B[0m - global step 15100/156300, epoch: 4, batch: 2595, rank_id: 0, loss: 0.621049, lr: 0.0000460868, speed: 0.8619 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:07:33,484] [    INFO]\u001B[0m - global step 15200/156300, epoch: 4, batch: 2695, rank_id: 0, loss: 0.637083, lr: 0.0000460542, speed: 0.8852 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:09:23,591] [    INFO]\u001B[0m - global step 15300/156300, epoch: 4, batch: 2795, rank_id: 0, loss: 0.609382, lr: 0.0000460215, speed: 0.9083 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:11:14,962] [    INFO]\u001B[0m - global step 15400/156300, epoch: 4, batch: 2895, rank_id: 0, loss: 0.757211, lr: 0.0000459889, speed: 0.8980 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:13:06,424] [    INFO]\u001B[0m - global step 15500/156300, epoch: 4, batch: 2995, rank_id: 0, loss: 0.776960, lr: 0.0000459562, speed: 0.8973 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:14:56,010] [    INFO]\u001B[0m - global step 15600/156300, epoch: 4, batch: 3095, rank_id: 0, loss: 0.847445, lr: 0.0000459236, speed: 0.9127 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:16:44,404] [    INFO]\u001B[0m - global step 15700/156300, epoch: 5, batch: 69, rank_id: 0, loss: 0.659151, lr: 0.0000458909, speed: 0.9227 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:18:35,579] [    INFO]\u001B[0m - global step 15800/156300, epoch: 5, batch: 169, rank_id: 0, loss: 0.530443, lr: 0.0000458583, speed: 0.8996 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:20:28,652] [    INFO]\u001B[0m - global step 15900/156300, epoch: 5, batch: 269, rank_id: 0, loss: 0.776238, lr: 0.0000458257, speed: 0.8845 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:22:22,434] [    INFO]\u001B[0m - global step 16000/156300, epoch: 5, batch: 369, rank_id: 0, loss: 0.521378, lr: 0.0000457930, speed: 0.8790 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:24:11,039] [    INFO]\u001B[0m - global step 16100/156300, epoch: 5, batch: 469, rank_id: 0, loss: 0.509082, lr: 0.0000457604, speed: 0.9209 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:26:00,056] [    INFO]\u001B[0m - global step 16200/156300, epoch: 5, batch: 569, rank_id: 0, loss: 0.801429, lr: 0.0000457277, speed: 0.9174 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:27:48,822] [    INFO]\u001B[0m - global step 16300/156300, epoch: 5, batch: 669, rank_id: 0, loss: 0.703124, lr: 0.0000456951, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:29:40,232] [    INFO]\u001B[0m - global step 16400/156300, epoch: 5, batch: 769, rank_id: 0, loss: 0.496766, lr: 0.0000456624, speed: 0.8977 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:31:33,557] [    INFO]\u001B[0m - global step 16500/156300, epoch: 5, batch: 869, rank_id: 0, loss: 0.796258, lr: 0.0000456298, speed: 0.8825 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:33:23,173] [    INFO]\u001B[0m - global step 16600/156300, epoch: 5, batch: 969, rank_id: 0, loss: 0.545780, lr: 0.0000455972, speed: 0.9124 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:35:12,958] [    INFO]\u001B[0m - global step 16700/156300, epoch: 5, batch: 1069, rank_id: 0, loss: 0.812625, lr: 0.0000455645, speed: 0.9110 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:37:07,342] [    INFO]\u001B[0m - global step 16800/156300, epoch: 5, batch: 1169, rank_id: 0, loss: 0.411883, lr: 0.0000455319, speed: 0.8744 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:39:00,237] [    INFO]\u001B[0m - global step 16900/156300, epoch: 5, batch: 1269, rank_id: 0, loss: 0.450404, lr: 0.0000454992, speed: 0.8859 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:40:49,810] [    INFO]\u001B[0m - global step 17000/156300, epoch: 5, batch: 1369, rank_id: 0, loss: 0.305378, lr: 0.0000454666, speed: 0.9128 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:42:38,746] [    INFO]\u001B[0m - global step 17100/156300, epoch: 5, batch: 1469, rank_id: 0, loss: 0.433818, lr: 0.0000454340, speed: 0.9181 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:44:27,990] [    INFO]\u001B[0m - global step 17200/156300, epoch: 5, batch: 1569, rank_id: 0, loss: 0.555760, lr: 0.0000454013, speed: 0.9155 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:46:17,229] [    INFO]\u001B[0m - global step 17300/156300, epoch: 5, batch: 1669, rank_id: 0, loss: 0.825727, lr: 0.0000453687, speed: 0.9156 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:48:10,328] [    INFO]\u001B[0m - global step 17400/156300, epoch: 5, batch: 1769, rank_id: 0, loss: 0.464166, lr: 0.0000453360, speed: 0.8843 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:49:59,985] [    INFO]\u001B[0m - global step 17500/156300, epoch: 5, batch: 1869, rank_id: 0, loss: 0.614998, lr: 0.0000453034, speed: 0.9121 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:51:51,512] [    INFO]\u001B[0m - global step 17600/156300, epoch: 5, batch: 1969, rank_id: 0, loss: 0.643925, lr: 0.0000452707, speed: 0.8968 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:53:40,611] [    INFO]\u001B[0m - global step 17700/156300, epoch: 5, batch: 2069, rank_id: 0, loss: 0.522648, lr: 0.0000452381, speed: 0.9167 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:55:27,489] [    INFO]\u001B[0m - global step 17800/156300, epoch: 5, batch: 2169, rank_id: 0, loss: 0.833960, lr: 0.0000452055, speed: 0.9358 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:57:19,061] [    INFO]\u001B[0m - global step 17900/156300, epoch: 5, batch: 2269, rank_id: 0, loss: 0.810762, lr: 0.0000451728, speed: 0.8964 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 03:59:09,639] [    INFO]\u001B[0m - global step 18000/156300, epoch: 5, batch: 2369, rank_id: 0, loss: 0.502430, lr: 0.0000451402, speed: 0.9045 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:01:00,690] [    INFO]\u001B[0m - global step 18100/156300, epoch: 5, batch: 2469, rank_id: 0, loss: 0.406748, lr: 0.0000451075, speed: 0.9006 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:02:54,143] [    INFO]\u001B[0m - global step 18200/156300, epoch: 5, batch: 2569, rank_id: 0, loss: 0.646793, lr: 0.0000450749, speed: 0.8815 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:04:51,956] [    INFO]\u001B[0m - global step 18300/156300, epoch: 5, batch: 2669, rank_id: 0, loss: 0.362474, lr: 0.0000450422, speed: 0.8489 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:06:39,269] [    INFO]\u001B[0m - global step 18400/156300, epoch: 5, batch: 2769, rank_id: 0, loss: 0.410043, lr: 0.0000450096, speed: 0.9320 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:08:31,099] [    INFO]\u001B[0m - global step 18500/156300, epoch: 5, batch: 2869, rank_id: 0, loss: 0.633847, lr: 0.0000449770, speed: 0.8943 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:10:21,825] [    INFO]\u001B[0m - global step 18600/156300, epoch: 5, batch: 2969, rank_id: 0, loss: 0.459028, lr: 0.0000449443, speed: 0.9033 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:12:12,398] [    INFO]\u001B[0m - global step 18700/156300, epoch: 5, batch: 3069, rank_id: 0, loss: 0.372603, lr: 0.0000449117, speed: 0.9045 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:14:00,562] [    INFO]\u001B[0m - global step 18800/156300, epoch: 6, batch: 43, rank_id: 0, loss: 0.435942, lr: 0.0000448790, speed: 0.9247 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:15:50,035] [    INFO]\u001B[0m - global step 18900/156300, epoch: 6, batch: 143, rank_id: 0, loss: 0.313379, lr: 0.0000448464, speed: 0.9136 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:17:44,964] [    INFO]\u001B[0m - global step 19000/156300, epoch: 6, batch: 243, rank_id: 0, loss: 0.553864, lr: 0.0000448137, speed: 0.8702 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:19:39,057] [    INFO]\u001B[0m - global step 19100/156300, epoch: 6, batch: 343, rank_id: 0, loss: 0.464873, lr: 0.0000447811, speed: 0.8766 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:21:27,042] [    INFO]\u001B[0m - global step 19200/156300, epoch: 6, batch: 443, rank_id: 0, loss: 0.375424, lr: 0.0000447485, speed: 0.9262 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:23:15,683] [    INFO]\u001B[0m - global step 19300/156300, epoch: 6, batch: 543, rank_id: 0, loss: 0.642761, lr: 0.0000447158, speed: 0.9206 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:25:07,217] [    INFO]\u001B[0m - global step 19400/156300, epoch: 6, batch: 643, rank_id: 0, loss: 0.605234, lr: 0.0000446832, speed: 0.8967 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:26:57,323] [    INFO]\u001B[0m - global step 19500/156300, epoch: 6, batch: 743, rank_id: 0, loss: 0.703171, lr: 0.0000446505, speed: 0.9083 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:28:48,591] [    INFO]\u001B[0m - global step 19600/156300, epoch: 6, batch: 843, rank_id: 0, loss: 0.499279, lr: 0.0000446179, speed: 0.8989 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 04:30:39,141] [    INFO]\u001B[0m - global step 19700/156300, epoch: 6, batch: 943, rank_id: 0, loss: 0.382402, lr: 0.0000445852, speed: 0.9047 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:32:30,394] [    INFO]\u001B[0m - global step 19800/156300, epoch: 6, batch: 1043, rank_id: 0, loss: 0.619550, lr: 0.0000445526, speed: 0.8990 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:34:21,416] [    INFO]\u001B[0m - global step 19900/156300, epoch: 6, batch: 1143, rank_id: 0, loss: 0.449046, lr: 0.0000445200, speed: 0.9008 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:36:15,945] [    INFO]\u001B[0m - global step 20000/156300, epoch: 6, batch: 1243, rank_id: 0, loss: 0.468883, lr: 0.0000444873, speed: 0.8733 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:36:26,892] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:36:26,894] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:38:18,608] [    INFO]\u001B[0m - global step 20100/156300, epoch: 6, batch: 1343, rank_id: 0, loss: 0.685623, lr: 0.0000444547, speed: 0.8153 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:40:06,727] [    INFO]\u001B[0m - global step 20200/156300, epoch: 6, batch: 1443, rank_id: 0, loss: 0.464793, lr: 0.0000444220, speed: 0.9250 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:41:55,524] [    INFO]\u001B[0m - global step 20300/156300, epoch: 6, batch: 1543, rank_id: 0, loss: 0.524883, lr: 0.0000443894, speed: 0.9193 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:43:46,672] [    INFO]\u001B[0m - global step 20400/156300, epoch: 6, batch: 1643, rank_id: 0, loss: 0.286018, lr: 0.0000443567, speed: 0.8998 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:45:39,053] [    INFO]\u001B[0m - global step 20500/156300, epoch: 6, batch: 1743, rank_id: 0, loss: 0.697987, lr: 0.0000443241, speed: 0.8900 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:47:27,555] [    INFO]\u001B[0m - global step 20600/156300, epoch: 6, batch: 1843, rank_id: 0, loss: 0.219462, lr: 0.0000442915, speed: 0.9218 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:49:18,192] [    INFO]\u001B[0m - global step 20700/156300, epoch: 6, batch: 1943, rank_id: 0, loss: 0.477739, lr: 0.0000442588, speed: 0.9040 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:51:06,544] [    INFO]\u001B[0m - global step 20800/156300, epoch: 6, batch: 2043, rank_id: 0, loss: 0.435433, lr: 0.0000442262, speed: 0.9231 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:52:55,110] [    INFO]\u001B[0m - global step 20900/156300, epoch: 6, batch: 2143, rank_id: 0, loss: 0.454192, lr: 0.0000441935, speed: 0.9212 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:54:47,751] [    INFO]\u001B[0m - global step 21000/156300, epoch: 6, batch: 2243, rank_id: 0, loss: 0.630369, lr: 0.0000441609, speed: 0.8879 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:56:35,131] [    INFO]\u001B[0m - global step 21100/156300, epoch: 6, batch: 2343, rank_id: 0, loss: 0.571325, lr: 0.0000441282, speed: 0.9314 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 04:58:26,474] [    INFO]\u001B[0m - global step 21200/156300, epoch: 6, batch: 2443, rank_id: 0, loss: 0.323790, lr: 0.0000440956, speed: 0.8983 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:00:22,452] [    INFO]\u001B[0m - global step 21300/156300, epoch: 6, batch: 2543, rank_id: 0, loss: 0.214219, lr: 0.0000440630, speed: 0.8623 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:02:17,994] [    INFO]\u001B[0m - global step 21400/156300, epoch: 6, batch: 2643, rank_id: 0, loss: 0.470155, lr: 0.0000440303, speed: 0.8656 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:04:06,576] [    INFO]\u001B[0m - global step 21500/156300, epoch: 6, batch: 2743, rank_id: 0, loss: 0.446596, lr: 0.0000439977, speed: 0.9211 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:05:59,265] [    INFO]\u001B[0m - global step 21600/156300, epoch: 6, batch: 2843, rank_id: 0, loss: 0.427272, lr: 0.0000439650, speed: 0.8875 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:07:48,425] [    INFO]\u001B[0m - global step 21700/156300, epoch: 6, batch: 2943, rank_id: 0, loss: 0.411731, lr: 0.0000439324, speed: 0.9162 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:09:38,552] [    INFO]\u001B[0m - global step 21800/156300, epoch: 6, batch: 3043, rank_id: 0, loss: 0.509376, lr: 0.0000438997, speed: 0.9082 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:11:28,296] [    INFO]\u001B[0m - global step 21900/156300, epoch: 7, batch: 17, rank_id: 0, loss: 0.462827, lr: 0.0000438671, speed: 0.9113 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:13:17,692] [    INFO]\u001B[0m - global step 22000/156300, epoch: 7, batch: 117, rank_id: 0, loss: 0.371199, lr: 0.0000438345, speed: 0.9142 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:15:09,131] [    INFO]\u001B[0m - global step 22100/156300, epoch: 7, batch: 217, rank_id: 0, loss: 0.744546, lr: 0.0000438018, speed: 0.8975 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:17:03,477] [    INFO]\u001B[0m - global step 22200/156300, epoch: 7, batch: 317, rank_id: 0, loss: 0.291919, lr: 0.0000437692, speed: 0.8747 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:18:52,919] [    INFO]\u001B[0m - global step 22300/156300, epoch: 7, batch: 417, rank_id: 0, loss: 0.525375, lr: 0.0000437365, speed: 0.9139 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:20:40,495] [    INFO]\u001B[0m - global step 22400/156300, epoch: 7, batch: 517, rank_id: 0, loss: 0.564388, lr: 0.0000437039, speed: 0.9297 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:22:32,020] [    INFO]\u001B[0m - global step 22500/156300, epoch: 7, batch: 617, rank_id: 0, loss: 0.517360, lr: 0.0000436712, speed: 0.8968 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:24:22,298] [    INFO]\u001B[0m - global step 22600/156300, epoch: 7, batch: 717, rank_id: 0, loss: 0.392898, lr: 0.0000436386, speed: 0.9069 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:26:13,207] [    INFO]\u001B[0m - global step 22700/156300, epoch: 7, batch: 817, rank_id: 0, loss: 0.654959, lr: 0.0000436060, speed: 0.9018 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:28:05,665] [    INFO]\u001B[0m - global step 22800/156300, epoch: 7, batch: 917, rank_id: 0, loss: 0.364456, lr: 0.0000435733, speed: 0.8893 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:29:55,784] [    INFO]\u001B[0m - global step 22900/156300, epoch: 7, batch: 1017, rank_id: 0, loss: 0.545211, lr: 0.0000435407, speed: 0.9082 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:31:47,045] [    INFO]\u001B[0m - global step 23000/156300, epoch: 7, batch: 1117, rank_id: 0, loss: 0.690130, lr: 0.0000435080, speed: 0.8989 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:33:39,568] [    INFO]\u001B[0m - global step 23100/156300, epoch: 7, batch: 1217, rank_id: 0, loss: 0.540286, lr: 0.0000434754, speed: 0.8888 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:35:33,992] [    INFO]\u001B[0m - global step 23200/156300, epoch: 7, batch: 1317, rank_id: 0, loss: 0.374927, lr: 0.0000434428, speed: 0.8741 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:37:19,618] [    INFO]\u001B[0m - global step 23300/156300, epoch: 7, batch: 1417, rank_id: 0, loss: 0.334969, lr: 0.0000434101, speed: 0.9469 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:39:11,673] [    INFO]\u001B[0m - global step 23400/156300, epoch: 7, batch: 1517, rank_id: 0, loss: 0.402601, lr: 0.0000433775, speed: 0.8925 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:40:58,418] [    INFO]\u001B[0m - global step 23500/156300, epoch: 7, batch: 1617, rank_id: 0, loss: 0.403040, lr: 0.0000433448, speed: 0.9370 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:42:51,521] [    INFO]\u001B[0m - global step 23600/156300, epoch: 7, batch: 1717, rank_id: 0, loss: 0.493617, lr: 0.0000433122, speed: 0.8843 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:44:42,388] [    INFO]\u001B[0m - global step 23700/156300, epoch: 7, batch: 1817, rank_id: 0, loss: 0.470964, lr: 0.0000432795, speed: 0.9021 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:46:33,775] [    INFO]\u001B[0m - global step 23800/156300, epoch: 7, batch: 1917, rank_id: 0, loss: 0.471822, lr: 0.0000432469, speed: 0.8979 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:48:20,985] [    INFO]\u001B[0m - global step 23900/156300, epoch: 7, batch: 2017, rank_id: 0, loss: 0.333512, lr: 0.0000432143, speed: 0.9329 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:50:11,456] [    INFO]\u001B[0m - global step 24000/156300, epoch: 7, batch: 2117, rank_id: 0, loss: 0.346096, lr: 0.0000431816, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:51:59,535] [    INFO]\u001B[0m - global step 24100/156300, epoch: 7, batch: 2217, rank_id: 0, loss: 0.451147, lr: 0.0000431490, speed: 0.9254 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:53:48,819] [    INFO]\u001B[0m - global step 24200/156300, epoch: 7, batch: 2317, rank_id: 0, loss: 0.461789, lr: 0.0000431163, speed: 0.9152 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:55:39,651] [    INFO]\u001B[0m - global step 24300/156300, epoch: 7, batch: 2417, rank_id: 0, loss: 0.152348, lr: 0.0000430837, speed: 0.9024 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 05:57:32,500] [    INFO]\u001B[0m - global step 24400/156300, epoch: 7, batch: 2517, rank_id: 0, loss: 0.282857, lr: 0.0000430510, speed: 0.8863 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 05:59:29,767] [    INFO]\u001B[0m - global step 24500/156300, epoch: 7, batch: 2617, rank_id: 0, loss: 0.206880, lr: 0.0000430184, speed: 0.8529 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:01:19,507] [    INFO]\u001B[0m - global step 24600/156300, epoch: 7, batch: 2717, rank_id: 0, loss: 0.165680, lr: 0.0000429858, speed: 0.9114 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:03:12,539] [    INFO]\u001B[0m - global step 24700/156300, epoch: 7, batch: 2817, rank_id: 0, loss: 0.403042, lr: 0.0000429531, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:05:01,895] [    INFO]\u001B[0m - global step 24800/156300, epoch: 7, batch: 2917, rank_id: 0, loss: 0.607273, lr: 0.0000429205, speed: 0.9146 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:06:53,113] [    INFO]\u001B[0m - global step 24900/156300, epoch: 7, batch: 3017, rank_id: 0, loss: 0.249556, lr: 0.0000428878, speed: 0.8993 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:08:41,567] [    INFO]\u001B[0m - global step 25000/156300, epoch: 7, batch: 3117, rank_id: 0, loss: 0.255432, lr: 0.0000428552, speed: 0.9222 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:10:31,431] [    INFO]\u001B[0m - global step 25100/156300, epoch: 8, batch: 91, rank_id: 0, loss: 0.399183, lr: 0.0000428225, speed: 0.9103 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:12:23,114] [    INFO]\u001B[0m - global step 25200/156300, epoch: 8, batch: 191, rank_id: 0, loss: 0.276669, lr: 0.0000427899, speed: 0.8955 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:14:17,488] [    INFO]\u001B[0m - global step 25300/156300, epoch: 8, batch: 291, rank_id: 0, loss: 0.511627, lr: 0.0000427573, speed: 0.8744 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:16:08,347] [    INFO]\u001B[0m - global step 25400/156300, epoch: 8, batch: 391, rank_id: 0, loss: 0.246391, lr: 0.0000427246, speed: 0.9022 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:17:55,672] [    INFO]\u001B[0m - global step 25500/156300, epoch: 8, batch: 491, rank_id: 0, loss: 0.236464, lr: 0.0000426920, speed: 0.9319 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:19:46,284] [    INFO]\u001B[0m - global step 25600/156300, epoch: 8, batch: 591, rank_id: 0, loss: 0.423807, lr: 0.0000426593, speed: 0.9042 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:21:36,118] [    INFO]\u001B[0m - global step 25700/156300, epoch: 8, batch: 691, rank_id: 0, loss: 0.080665, lr: 0.0000426267, speed: 0.9106 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:23:25,558] [    INFO]\u001B[0m - global step 25800/156300, epoch: 8, batch: 791, rank_id: 0, loss: 0.273835, lr: 0.0000425940, speed: 0.9139 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:25:18,324] [    INFO]\u001B[0m - global step 25900/156300, epoch: 8, batch: 891, rank_id: 0, loss: 0.380299, lr: 0.0000425614, speed: 0.8869 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:27:08,601] [    INFO]\u001B[0m - global step 26000/156300, epoch: 8, batch: 991, rank_id: 0, loss: 0.419734, lr: 0.0000425288, speed: 0.9069 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:28:59,572] [    INFO]\u001B[0m - global step 26100/156300, epoch: 8, batch: 1091, rank_id: 0, loss: 0.445870, lr: 0.0000424961, speed: 0.9013 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:30:53,082] [    INFO]\u001B[0m - global step 26200/156300, epoch: 8, batch: 1191, rank_id: 0, loss: 0.310179, lr: 0.0000424635, speed: 0.8811 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:32:46,992] [    INFO]\u001B[0m - global step 26300/156300, epoch: 8, batch: 1291, rank_id: 0, loss: 0.705757, lr: 0.0000424308, speed: 0.8780 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:34:35,442] [    INFO]\u001B[0m - global step 26400/156300, epoch: 8, batch: 1391, rank_id: 0, loss: 0.409711, lr: 0.0000423982, speed: 0.9222 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:36:24,216] [    INFO]\u001B[0m - global step 26500/156300, epoch: 8, batch: 1491, rank_id: 0, loss: 0.255623, lr: 0.0000423655, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:38:11,798] [    INFO]\u001B[0m - global step 26600/156300, epoch: 8, batch: 1591, rank_id: 0, loss: 0.331667, lr: 0.0000423329, speed: 0.9297 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:40:01,545] [    INFO]\u001B[0m - global step 26700/156300, epoch: 8, batch: 1691, rank_id: 0, loss: 0.304541, lr: 0.0000423003, speed: 0.9113 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:41:56,156] [    INFO]\u001B[0m - global step 26800/156300, epoch: 8, batch: 1791, rank_id: 0, loss: 0.459818, lr: 0.0000422676, speed: 0.8726 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:43:47,699] [    INFO]\u001B[0m - global step 26900/156300, epoch: 8, batch: 1891, rank_id: 0, loss: 0.302820, lr: 0.0000422350, speed: 0.8966 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:45:35,643] [    INFO]\u001B[0m - global step 27000/156300, epoch: 8, batch: 1991, rank_id: 0, loss: 0.225795, lr: 0.0000422023, speed: 0.9265 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:47:24,616] [    INFO]\u001B[0m - global step 27100/156300, epoch: 8, batch: 2091, rank_id: 0, loss: 0.166311, lr: 0.0000421697, speed: 0.9178 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:49:12,837] [    INFO]\u001B[0m - global step 27200/156300, epoch: 8, batch: 2191, rank_id: 0, loss: 0.104830, lr: 0.0000421370, speed: 0.9242 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:51:02,867] [    INFO]\u001B[0m - global step 27300/156300, epoch: 8, batch: 2291, rank_id: 0, loss: 0.307583, lr: 0.0000421044, speed: 0.9090 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:52:53,118] [    INFO]\u001B[0m - global step 27400/156300, epoch: 8, batch: 2391, rank_id: 0, loss: 0.143682, lr: 0.0000420718, speed: 0.9072 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:54:45,254] [    INFO]\u001B[0m - global step 27500/156300, epoch: 8, batch: 2491, rank_id: 0, loss: 0.150609, lr: 0.0000420391, speed: 0.8919 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:56:41,454] [    INFO]\u001B[0m - global step 27600/156300, epoch: 8, batch: 2591, rank_id: 0, loss: 0.407395, lr: 0.0000420065, speed: 0.8607 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 06:58:35,148] [    INFO]\u001B[0m - global step 27700/156300, epoch: 8, batch: 2691, rank_id: 0, loss: 0.150287, lr: 0.0000419738, speed: 0.8797 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:00:25,005] [    INFO]\u001B[0m - global step 27800/156300, epoch: 8, batch: 2791, rank_id: 0, loss: 0.097809, lr: 0.0000419412, speed: 0.9104 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:02:15,911] [    INFO]\u001B[0m - global step 27900/156300, epoch: 8, batch: 2891, rank_id: 0, loss: 0.300641, lr: 0.0000419085, speed: 0.9018 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:04:07,105] [    INFO]\u001B[0m - global step 28000/156300, epoch: 8, batch: 2991, rank_id: 0, loss: 0.291110, lr: 0.0000418759, speed: 0.8995 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:05:55,877] [    INFO]\u001B[0m - global step 28100/156300, epoch: 8, batch: 3091, rank_id: 0, loss: 0.317659, lr: 0.0000418433, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:07:44,532] [    INFO]\u001B[0m - global step 28200/156300, epoch: 9, batch: 65, rank_id: 0, loss: 0.285306, lr: 0.0000418106, speed: 0.9205 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:09:36,934] [    INFO]\u001B[0m - global step 28300/156300, epoch: 9, batch: 165, rank_id: 0, loss: 0.226149, lr: 0.0000417780, speed: 0.8898 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:11:29,204] [    INFO]\u001B[0m - global step 28400/156300, epoch: 9, batch: 265, rank_id: 0, loss: 0.554287, lr: 0.0000417453, speed: 0.8908 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:13:22,837] [    INFO]\u001B[0m - global step 28500/156300, epoch: 9, batch: 365, rank_id: 0, loss: 0.325173, lr: 0.0000417127, speed: 0.8801 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:15:12,050] [    INFO]\u001B[0m - global step 28600/156300, epoch: 9, batch: 465, rank_id: 0, loss: 0.188059, lr: 0.0000416801, speed: 0.9158 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:17:00,438] [    INFO]\u001B[0m - global step 28700/156300, epoch: 9, batch: 565, rank_id: 0, loss: 0.381047, lr: 0.0000416474, speed: 0.9228 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:18:48,413] [    INFO]\u001B[0m - global step 28800/156300, epoch: 9, batch: 665, rank_id: 0, loss: 0.185856, lr: 0.0000416148, speed: 0.9263 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:20:40,352] [    INFO]\u001B[0m - global step 28900/156300, epoch: 9, batch: 765, rank_id: 0, loss: 0.406336, lr: 0.0000415821, speed: 0.8935 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:22:33,081] [    INFO]\u001B[0m - global step 29000/156300, epoch: 9, batch: 865, rank_id: 0, loss: 0.243052, lr: 0.0000415495, speed: 0.8872 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:24:22,414] [    INFO]\u001B[0m - global step 29100/156300, epoch: 9, batch: 965, rank_id: 0, loss: 0.403964, lr: 0.0000415168, speed: 0.9148 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:26:12,945] [    INFO]\u001B[0m - global step 29200/156300, epoch: 9, batch: 1065, rank_id: 0, loss: 0.245859, lr: 0.0000414842, speed: 0.9049 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:28:06,199] [    INFO]\u001B[0m - global step 29300/156300, epoch: 9, batch: 1165, rank_id: 0, loss: 0.281154, lr: 0.0000414516, speed: 0.8831 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 07:29:59,535] [    INFO]\u001B[0m - global step 29400/156300, epoch: 9, batch: 1265, rank_id: 0, loss: 0.329019, lr: 0.0000414189, speed: 0.8825 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:31:49,022] [    INFO]\u001B[0m - global step 29500/156300, epoch: 9, batch: 1365, rank_id: 0, loss: 0.195588, lr: 0.0000413863, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:33:38,710] [    INFO]\u001B[0m - global step 29600/156300, epoch: 9, batch: 1465, rank_id: 0, loss: 0.258116, lr: 0.0000413536, speed: 0.9118 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:35:27,065] [    INFO]\u001B[0m - global step 29700/156300, epoch: 9, batch: 1565, rank_id: 0, loss: 0.306639, lr: 0.0000413210, speed: 0.9230 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:37:16,707] [    INFO]\u001B[0m - global step 29800/156300, epoch: 9, batch: 1665, rank_id: 0, loss: 0.120928, lr: 0.0000412883, speed: 0.9122 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:39:09,402] [    INFO]\u001B[0m - global step 29900/156300, epoch: 9, batch: 1765, rank_id: 0, loss: 0.235671, lr: 0.0000412557, speed: 0.8875 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:40:58,780] [    INFO]\u001B[0m - global step 30000/156300, epoch: 9, batch: 1865, rank_id: 0, loss: 0.461529, lr: 0.0000412231, speed: 0.9144 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:42:49,540] [    INFO]\u001B[0m - global step 30100/156300, epoch: 9, batch: 1965, rank_id: 0, loss: 0.157901, lr: 0.0000411904, speed: 0.9030 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:44:39,088] [    INFO]\u001B[0m - global step 30200/156300, epoch: 9, batch: 2065, rank_id: 0, loss: 0.183846, lr: 0.0000411578, speed: 0.9130 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:46:26,048] [    INFO]\u001B[0m - global step 30300/156300, epoch: 9, batch: 2165, rank_id: 0, loss: 0.184967, lr: 0.0000411251, speed: 0.9351 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:48:16,896] [    INFO]\u001B[0m - global step 30400/156300, epoch: 9, batch: 2265, rank_id: 0, loss: 0.320364, lr: 0.0000410925, speed: 0.9023 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:50:07,375] [    INFO]\u001B[0m - global step 30500/156300, epoch: 9, batch: 2365, rank_id: 0, loss: 0.264255, lr: 0.0000410598, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:51:58,830] [    INFO]\u001B[0m - global step 30600/156300, epoch: 9, batch: 2465, rank_id: 0, loss: 0.331757, lr: 0.0000410272, speed: 0.8973 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:53:51,832] [    INFO]\u001B[0m - global step 30700/156300, epoch: 9, batch: 2565, rank_id: 0, loss: 0.150516, lr: 0.0000409946, speed: 0.8851 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:55:50,046] [    INFO]\u001B[0m - global step 30800/156300, epoch: 9, batch: 2665, rank_id: 0, loss: 0.229641, lr: 0.0000409619, speed: 0.8460 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:57:36,873] [    INFO]\u001B[0m - global step 30900/156300, epoch: 9, batch: 2765, rank_id: 0, loss: 0.176944, lr: 0.0000409293, speed: 0.9362 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 07:59:28,776] [    INFO]\u001B[0m - global step 31000/156300, epoch: 9, batch: 2865, rank_id: 0, loss: 0.165936, lr: 0.0000408966, speed: 0.8938 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:01:20,281] [    INFO]\u001B[0m - global step 31100/156300, epoch: 9, batch: 2965, rank_id: 0, loss: 0.114983, lr: 0.0000408640, speed: 0.8970 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:03:09,277] [    INFO]\u001B[0m - global step 31200/156300, epoch: 9, batch: 3065, rank_id: 0, loss: 0.385904, lr: 0.0000408313, speed: 0.9176 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:04:58,630] [    INFO]\u001B[0m - global step 31300/156300, epoch: 10, batch: 39, rank_id: 0, loss: 0.230258, lr: 0.0000407987, speed: 0.9146 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:06:47,643] [    INFO]\u001B[0m - global step 31400/156300, epoch: 10, batch: 139, rank_id: 0, loss: 0.355692, lr: 0.0000407661, speed: 0.9174 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:08:41,863] [    INFO]\u001B[0m - global step 31500/156300, epoch: 10, batch: 239, rank_id: 0, loss: 0.199612, lr: 0.0000407334, speed: 0.8756 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:10:35,874] [    INFO]\u001B[0m - global step 31600/156300, epoch: 10, batch: 339, rank_id: 0, loss: 0.169707, lr: 0.0000407008, speed: 0.8772 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:12:24,117] [    INFO]\u001B[0m - global step 31700/156300, epoch: 10, batch: 439, rank_id: 0, loss: 0.197287, lr: 0.0000406681, speed: 0.9240 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:14:12,653] [    INFO]\u001B[0m - global step 31800/156300, epoch: 10, batch: 539, rank_id: 0, loss: 0.179605, lr: 0.0000406355, speed: 0.9215 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:16:03,341] [    INFO]\u001B[0m - global step 31900/156300, epoch: 10, batch: 639, rank_id: 0, loss: 0.186452, lr: 0.0000406028, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:17:54,147] [    INFO]\u001B[0m - global step 32000/156300, epoch: 10, batch: 739, rank_id: 0, loss: 0.226209, lr: 0.0000405702, speed: 0.9026 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:19:44,576] [    INFO]\u001B[0m - global step 32100/156300, epoch: 10, batch: 839, rank_id: 0, loss: 0.546216, lr: 0.0000405376, speed: 0.9057 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:21:36,293] [    INFO]\u001B[0m - global step 32200/156300, epoch: 10, batch: 939, rank_id: 0, loss: 0.231850, lr: 0.0000405049, speed: 0.8952 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:23:26,373] [    INFO]\u001B[0m - global step 32300/156300, epoch: 10, batch: 1039, rank_id: 0, loss: 0.248612, lr: 0.0000404723, speed: 0.9086 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:25:18,107] [    INFO]\u001B[0m - global step 32400/156300, epoch: 10, batch: 1139, rank_id: 0, loss: 0.324945, lr: 0.0000404396, speed: 0.8951 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:27:11,699] [    INFO]\u001B[0m - global step 32500/156300, epoch: 10, batch: 1239, rank_id: 0, loss: 0.240569, lr: 0.0000404070, speed: 0.8805 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:29:04,430] [    INFO]\u001B[0m - global step 32600/156300, epoch: 10, batch: 1339, rank_id: 0, loss: 0.235963, lr: 0.0000403743, speed: 0.8872 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:30:51,790] [    INFO]\u001B[0m - global step 32700/156300, epoch: 10, batch: 1439, rank_id: 0, loss: 0.355635, lr: 0.0000403417, speed: 0.9316 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:32:41,269] [    INFO]\u001B[0m - global step 32800/156300, epoch: 10, batch: 1539, rank_id: 0, loss: 0.152818, lr: 0.0000403091, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:34:32,580] [    INFO]\u001B[0m - global step 32900/156300, epoch: 10, batch: 1639, rank_id: 0, loss: 0.186851, lr: 0.0000402764, speed: 0.8985 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:36:23,240] [    INFO]\u001B[0m - global step 33000/156300, epoch: 10, batch: 1739, rank_id: 0, loss: 0.145446, lr: 0.0000402438, speed: 0.9038 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:38:12,857] [    INFO]\u001B[0m - global step 33100/156300, epoch: 10, batch: 1839, rank_id: 0, loss: 0.242936, lr: 0.0000402111, speed: 0.9124 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:40:03,475] [    INFO]\u001B[0m - global step 33200/156300, epoch: 10, batch: 1939, rank_id: 0, loss: 0.192186, lr: 0.0000401785, speed: 0.9041 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:41:51,957] [    INFO]\u001B[0m - global step 33300/156300, epoch: 10, batch: 2039, rank_id: 0, loss: 0.334267, lr: 0.0000401458, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:43:40,431] [    INFO]\u001B[0m - global step 33400/156300, epoch: 10, batch: 2139, rank_id: 0, loss: 0.068543, lr: 0.0000401132, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:45:31,895] [    INFO]\u001B[0m - global step 33500/156300, epoch: 10, batch: 2239, rank_id: 0, loss: 0.211413, lr: 0.0000400806, speed: 0.8973 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:47:20,174] [    INFO]\u001B[0m - global step 33600/156300, epoch: 10, batch: 2339, rank_id: 0, loss: 0.201318, lr: 0.0000400479, speed: 0.9237 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:49:09,897] [    INFO]\u001B[0m - global step 33700/156300, epoch: 10, batch: 2439, rank_id: 0, loss: 0.306001, lr: 0.0000400153, speed: 0.9115 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:51:06,629] [    INFO]\u001B[0m - global step 33800/156300, epoch: 10, batch: 2539, rank_id: 0, loss: 0.149601, lr: 0.0000399826, speed: 0.8568 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:53:02,636] [    INFO]\u001B[0m - global step 33900/156300, epoch: 10, batch: 2639, rank_id: 0, loss: 0.222734, lr: 0.0000399500, speed: 0.8621 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:54:51,273] [    INFO]\u001B[0m - global step 34000/156300, epoch: 10, batch: 2739, rank_id: 0, loss: 0.215598, lr: 0.0000399173, speed: 0.9206 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:56:43,907] [    INFO]\u001B[0m - global step 34100/156300, epoch: 10, batch: 2839, rank_id: 0, loss: 0.109731, lr: 0.0000398847, speed: 0.8880 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 08:58:32,747] [    INFO]\u001B[0m - global step 34200/156300, epoch: 10, batch: 2939, rank_id: 0, loss: 0.220114, lr: 0.0000398521, speed: 0.9189 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 09:00:22,386] [    INFO]\u001B[0m - global step 34300/156300, epoch: 10, batch: 3039, rank_id: 0, loss: 0.242871, lr: 0.0000398194, speed: 0.9122 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:02:12,727] [    INFO]\u001B[0m - global step 34400/156300, epoch: 11, batch: 13, rank_id: 0, loss: 0.333795, lr: 0.0000397868, speed: 0.9064 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:04:01,901] [    INFO]\u001B[0m - global step 34500/156300, epoch: 11, batch: 113, rank_id: 0, loss: 0.149994, lr: 0.0000397541, speed: 0.9161 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:05:53,476] [    INFO]\u001B[0m - global step 34600/156300, epoch: 11, batch: 213, rank_id: 0, loss: 0.125461, lr: 0.0000397215, speed: 0.8964 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:07:48,467] [    INFO]\u001B[0m - global step 34700/156300, epoch: 11, batch: 313, rank_id: 0, loss: 0.213298, lr: 0.0000396889, speed: 0.8697 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:09:37,687] [    INFO]\u001B[0m - global step 34800/156300, epoch: 11, batch: 413, rank_id: 0, loss: 0.206577, lr: 0.0000396562, speed: 0.9157 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:11:25,834] [    INFO]\u001B[0m - global step 34900/156300, epoch: 11, batch: 513, rank_id: 0, loss: 0.141180, lr: 0.0000396236, speed: 0.9248 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:13:17,147] [    INFO]\u001B[0m - global step 35000/156300, epoch: 11, batch: 613, rank_id: 0, loss: 0.287281, lr: 0.0000395909, speed: 0.8985 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:15:06,485] [    INFO]\u001B[0m - global step 35100/156300, epoch: 11, batch: 713, rank_id: 0, loss: 0.234088, lr: 0.0000395583, speed: 0.9147 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:16:57,480] [    INFO]\u001B[0m - global step 35200/156300, epoch: 11, batch: 813, rank_id: 0, loss: 0.200500, lr: 0.0000395256, speed: 0.9011 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:18:49,938] [    INFO]\u001B[0m - global step 35300/156300, epoch: 11, batch: 913, rank_id: 0, loss: 0.123335, lr: 0.0000394930, speed: 0.8893 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:20:41,069] [    INFO]\u001B[0m - global step 35400/156300, epoch: 11, batch: 1013, rank_id: 0, loss: 0.080180, lr: 0.0000394604, speed: 0.9000 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:22:31,636] [    INFO]\u001B[0m - global step 35500/156300, epoch: 11, batch: 1113, rank_id: 0, loss: 0.398946, lr: 0.0000394277, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:24:24,620] [    INFO]\u001B[0m - global step 35600/156300, epoch: 11, batch: 1213, rank_id: 0, loss: 0.200892, lr: 0.0000393951, speed: 0.8852 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:26:18,629] [    INFO]\u001B[0m - global step 35700/156300, epoch: 11, batch: 1313, rank_id: 0, loss: 0.111535, lr: 0.0000393624, speed: 0.8773 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:28:04,849] [    INFO]\u001B[0m - global step 35800/156300, epoch: 11, batch: 1413, rank_id: 0, loss: 0.211815, lr: 0.0000393298, speed: 0.9416 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:29:55,581] [    INFO]\u001B[0m - global step 35900/156300, epoch: 11, batch: 1513, rank_id: 0, loss: 0.145391, lr: 0.0000392971, speed: 0.9032 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:31:43,116] [    INFO]\u001B[0m - global step 36000/156300, epoch: 11, batch: 1613, rank_id: 0, loss: 0.334250, lr: 0.0000392645, speed: 0.9301 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:33:36,195] [    INFO]\u001B[0m - global step 36100/156300, epoch: 11, batch: 1713, rank_id: 0, loss: 0.201342, lr: 0.0000392319, speed: 0.8845 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:35:26,324] [    INFO]\u001B[0m - global step 36200/156300, epoch: 11, batch: 1813, rank_id: 0, loss: 0.244926, lr: 0.0000391992, speed: 0.9082 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:37:18,945] [    INFO]\u001B[0m - global step 36300/156300, epoch: 11, batch: 1913, rank_id: 0, loss: 0.098576, lr: 0.0000391666, speed: 0.8881 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:39:06,185] [    INFO]\u001B[0m - global step 36400/156300, epoch: 11, batch: 2013, rank_id: 0, loss: 0.154525, lr: 0.0000391339, speed: 0.9326 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:40:55,430] [    INFO]\u001B[0m - global step 36500/156300, epoch: 11, batch: 2113, rank_id: 0, loss: 0.219664, lr: 0.0000391013, speed: 0.9155 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:42:44,290] [    INFO]\u001B[0m - global step 36600/156300, epoch: 11, batch: 2213, rank_id: 0, loss: 0.076515, lr: 0.0000390686, speed: 0.9187 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:44:32,761] [    INFO]\u001B[0m - global step 36700/156300, epoch: 11, batch: 2313, rank_id: 0, loss: 0.209383, lr: 0.0000390360, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:46:24,144] [    INFO]\u001B[0m - global step 36800/156300, epoch: 11, batch: 2413, rank_id: 0, loss: 0.201023, lr: 0.0000390034, speed: 0.8979 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:48:16,951] [    INFO]\u001B[0m - global step 36900/156300, epoch: 11, batch: 2513, rank_id: 0, loss: 0.159563, lr: 0.0000389707, speed: 0.8866 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:50:14,840] [    INFO]\u001B[0m - global step 37000/156300, epoch: 11, batch: 2613, rank_id: 0, loss: 0.276233, lr: 0.0000389381, speed: 0.8484 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:52:03,609] [    INFO]\u001B[0m - global step 37100/156300, epoch: 11, batch: 2713, rank_id: 0, loss: 0.148753, lr: 0.0000389054, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:53:56,574] [    INFO]\u001B[0m - global step 37200/156300, epoch: 11, batch: 2813, rank_id: 0, loss: 0.151706, lr: 0.0000388728, speed: 0.8854 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:55:46,124] [    INFO]\u001B[0m - global step 37300/156300, epoch: 11, batch: 2913, rank_id: 0, loss: 0.181919, lr: 0.0000388401, speed: 0.9130 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:57:38,103] [    INFO]\u001B[0m - global step 37400/156300, epoch: 11, batch: 3013, rank_id: 0, loss: 0.407574, lr: 0.0000388075, speed: 0.8931 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 09:59:26,066] [    INFO]\u001B[0m - global step 37500/156300, epoch: 11, batch: 3113, rank_id: 0, loss: 0.064352, lr: 0.0000387749, speed: 0.9264 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:01:16,370] [    INFO]\u001B[0m - global step 37600/156300, epoch: 12, batch: 87, rank_id: 0, loss: 0.224757, lr: 0.0000387422, speed: 0.9067 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:03:07,824] [    INFO]\u001B[0m - global step 37700/156300, epoch: 12, batch: 187, rank_id: 0, loss: 0.253222, lr: 0.0000387096, speed: 0.8974 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:05:02,148] [    INFO]\u001B[0m - global step 37800/156300, epoch: 12, batch: 287, rank_id: 0, loss: 0.056487, lr: 0.0000386769, speed: 0.8748 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:06:53,007] [    INFO]\u001B[0m - global step 37900/156300, epoch: 12, batch: 387, rank_id: 0, loss: 0.143619, lr: 0.0000386443, speed: 0.9022 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:08:40,672] [    INFO]\u001B[0m - global step 38000/156300, epoch: 12, batch: 487, rank_id: 0, loss: 0.059004, lr: 0.0000386116, speed: 0.9289 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:10:31,515] [    INFO]\u001B[0m - global step 38100/156300, epoch: 12, batch: 587, rank_id: 0, loss: 0.151389, lr: 0.0000385790, speed: 0.9023 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:12:20,291] [    INFO]\u001B[0m - global step 38200/156300, epoch: 12, batch: 687, rank_id: 0, loss: 0.319456, lr: 0.0000385464, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:14:10,235] [    INFO]\u001B[0m - global step 38300/156300, epoch: 12, batch: 787, rank_id: 0, loss: 0.147631, lr: 0.0000385137, speed: 0.9097 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:16:03,220] [    INFO]\u001B[0m - global step 38400/156300, epoch: 12, batch: 887, rank_id: 0, loss: 0.234332, lr: 0.0000384811, speed: 0.8852 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:17:52,511] [    INFO]\u001B[0m - global step 38500/156300, epoch: 12, batch: 987, rank_id: 0, loss: 0.093448, lr: 0.0000384484, speed: 0.9151 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:19:42,840] [    INFO]\u001B[0m - global step 38600/156300, epoch: 12, batch: 1087, rank_id: 0, loss: 0.105065, lr: 0.0000384158, speed: 0.9065 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:21:36,625] [    INFO]\u001B[0m - global step 38700/156300, epoch: 12, batch: 1187, rank_id: 0, loss: 0.153894, lr: 0.0000383831, speed: 0.8790 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:23:31,322] [    INFO]\u001B[0m - global step 38800/156300, epoch: 12, batch: 1287, rank_id: 0, loss: 0.136864, lr: 0.0000383505, speed: 0.8720 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:25:19,221] [    INFO]\u001B[0m - global step 38900/156300, epoch: 12, batch: 1387, rank_id: 0, loss: 0.105321, lr: 0.0000383179, speed: 0.9269 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:27:08,313] [    INFO]\u001B[0m - global step 39000/156300, epoch: 12, batch: 1487, rank_id: 0, loss: 0.129494, lr: 0.0000382852, speed: 0.9168 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:28:56,523] [    INFO]\u001B[0m - global step 39100/156300, epoch: 12, batch: 1587, rank_id: 0, loss: 0.225312, lr: 0.0000382526, speed: 0.9243 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 10:30:45,625] [    INFO]\u001B[0m - global step 39200/156300, epoch: 12, batch: 1687, rank_id: 0, loss: 0.083772, lr: 0.0000382199, speed: 0.9167 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:32:39,696] [    INFO]\u001B[0m - global step 39300/156300, epoch: 12, batch: 1787, rank_id: 0, loss: 0.110543, lr: 0.0000381873, speed: 0.8768 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:34:31,085] [    INFO]\u001B[0m - global step 39400/156300, epoch: 12, batch: 1887, rank_id: 0, loss: 0.071897, lr: 0.0000381546, speed: 0.8979 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:36:20,479] [    INFO]\u001B[0m - global step 39500/156300, epoch: 12, batch: 1987, rank_id: 0, loss: 0.281830, lr: 0.0000381220, speed: 0.9143 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:38:09,471] [    INFO]\u001B[0m - global step 39600/156300, epoch: 12, batch: 2087, rank_id: 0, loss: 0.188748, lr: 0.0000380894, speed: 0.9176 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:39:57,667] [    INFO]\u001B[0m - global step 39700/156300, epoch: 12, batch: 2187, rank_id: 0, loss: 0.174213, lr: 0.0000380567, speed: 0.9244 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:41:48,158] [    INFO]\u001B[0m - global step 39800/156300, epoch: 12, batch: 2287, rank_id: 0, loss: 0.127307, lr: 0.0000380241, speed: 0.9052 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:43:37,644] [    INFO]\u001B[0m - global step 39900/156300, epoch: 12, batch: 2387, rank_id: 0, loss: 0.208221, lr: 0.0000379914, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:45:29,060] [    INFO]\u001B[0m - global step 40000/156300, epoch: 12, batch: 2487, rank_id: 0, loss: 0.156516, lr: 0.0000379588, speed: 0.8977 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:45:39,944] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:45:39,946] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:47:34,878] [    INFO]\u001B[0m - global step 40100/156300, epoch: 12, batch: 2587, rank_id: 0, loss: 0.320564, lr: 0.0000379261, speed: 0.7949 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:49:30,335] [    INFO]\u001B[0m - global step 40200/156300, epoch: 12, batch: 2687, rank_id: 0, loss: 0.050892, lr: 0.0000378935, speed: 0.8662 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:51:19,909] [    INFO]\u001B[0m - global step 40300/156300, epoch: 12, batch: 2787, rank_id: 0, loss: 0.118086, lr: 0.0000378609, speed: 0.9128 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:53:10,050] [    INFO]\u001B[0m - global step 40400/156300, epoch: 12, batch: 2887, rank_id: 0, loss: 0.158574, lr: 0.0000378282, speed: 0.9081 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:55:00,981] [    INFO]\u001B[0m - global step 40500/156300, epoch: 12, batch: 2987, rank_id: 0, loss: 0.156990, lr: 0.0000377956, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:56:50,429] [    INFO]\u001B[0m - global step 40600/156300, epoch: 12, batch: 3087, rank_id: 0, loss: 0.154923, lr: 0.0000377629, speed: 0.9138 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 10:58:38,630] [    INFO]\u001B[0m - global step 40700/156300, epoch: 13, batch: 61, rank_id: 0, loss: 0.061445, lr: 0.0000377303, speed: 0.9243 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:00:30,195] [    INFO]\u001B[0m - global step 40800/156300, epoch: 13, batch: 161, rank_id: 0, loss: 0.102815, lr: 0.0000376977, speed: 0.8965 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:02:22,772] [    INFO]\u001B[0m - global step 40900/156300, epoch: 13, batch: 261, rank_id: 0, loss: 0.139156, lr: 0.0000376650, speed: 0.8884 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:04:16,392] [    INFO]\u001B[0m - global step 41000/156300, epoch: 13, batch: 361, rank_id: 0, loss: 0.170254, lr: 0.0000376324, speed: 0.8803 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:06:06,061] [    INFO]\u001B[0m - global step 41100/156300, epoch: 13, batch: 461, rank_id: 0, loss: 0.159594, lr: 0.0000375997, speed: 0.9120 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:07:53,301] [    INFO]\u001B[0m - global step 41200/156300, epoch: 13, batch: 561, rank_id: 0, loss: 0.152894, lr: 0.0000375671, speed: 0.9326 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:09:42,873] [    INFO]\u001B[0m - global step 41300/156300, epoch: 13, batch: 661, rank_id: 0, loss: 0.134378, lr: 0.0000375344, speed: 0.9128 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:11:33,612] [    INFO]\u001B[0m - global step 41400/156300, epoch: 13, batch: 761, rank_id: 0, loss: 0.158446, lr: 0.0000375018, speed: 0.9031 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:13:26,040] [    INFO]\u001B[0m - global step 41500/156300, epoch: 13, batch: 861, rank_id: 0, loss: 0.085477, lr: 0.0000374692, speed: 0.8896 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:15:16,598] [    INFO]\u001B[0m - global step 41600/156300, epoch: 13, batch: 961, rank_id: 0, loss: 0.085187, lr: 0.0000374365, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:17:07,026] [    INFO]\u001B[0m - global step 41700/156300, epoch: 13, batch: 1061, rank_id: 0, loss: 0.069899, lr: 0.0000374039, speed: 0.9057 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:18:59,548] [    INFO]\u001B[0m - global step 41800/156300, epoch: 13, batch: 1161, rank_id: 0, loss: 0.221465, lr: 0.0000373712, speed: 0.8888 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:20:52,369] [    INFO]\u001B[0m - global step 41900/156300, epoch: 13, batch: 1261, rank_id: 0, loss: 0.058273, lr: 0.0000373386, speed: 0.8865 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:22:42,836] [    INFO]\u001B[0m - global step 42000/156300, epoch: 13, batch: 1361, rank_id: 0, loss: 0.142205, lr: 0.0000373059, speed: 0.9054 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:24:31,080] [    INFO]\u001B[0m - global step 42100/156300, epoch: 13, batch: 1461, rank_id: 0, loss: 0.195845, lr: 0.0000372733, speed: 0.9240 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:26:19,856] [    INFO]\u001B[0m - global step 42200/156300, epoch: 13, batch: 1561, rank_id: 0, loss: 0.124486, lr: 0.0000372407, speed: 0.9194 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:28:09,630] [    INFO]\u001B[0m - global step 42300/156300, epoch: 13, batch: 1661, rank_id: 0, loss: 0.108645, lr: 0.0000372080, speed: 0.9111 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:30:02,228] [    INFO]\u001B[0m - global step 42400/156300, epoch: 13, batch: 1761, rank_id: 0, loss: 0.069644, lr: 0.0000371754, speed: 0.8882 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:31:51,829] [    INFO]\u001B[0m - global step 42500/156300, epoch: 13, batch: 1861, rank_id: 0, loss: 0.097028, lr: 0.0000371427, speed: 0.9125 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:33:43,082] [    INFO]\u001B[0m - global step 42600/156300, epoch: 13, batch: 1961, rank_id: 0, loss: 0.174509, lr: 0.0000371101, speed: 0.8990 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:35:31,643] [    INFO]\u001B[0m - global step 42700/156300, epoch: 13, batch: 2061, rank_id: 0, loss: 0.069581, lr: 0.0000370774, speed: 0.9213 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:37:19,071] [    INFO]\u001B[0m - global step 42800/156300, epoch: 13, batch: 2161, rank_id: 0, loss: 0.178764, lr: 0.0000370448, speed: 0.9310 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:39:09,827] [    INFO]\u001B[0m - global step 42900/156300, epoch: 13, batch: 2261, rank_id: 0, loss: 0.106547, lr: 0.0000370122, speed: 0.9030 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:41:00,384] [    INFO]\u001B[0m - global step 43000/156300, epoch: 13, batch: 2361, rank_id: 0, loss: 0.092175, lr: 0.0000369795, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:42:51,909] [    INFO]\u001B[0m - global step 43100/156300, epoch: 13, batch: 2461, rank_id: 0, loss: 0.057502, lr: 0.0000369469, speed: 0.8968 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:44:45,415] [    INFO]\u001B[0m - global step 43200/156300, epoch: 13, batch: 2561, rank_id: 0, loss: 0.195019, lr: 0.0000369142, speed: 0.8811 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:46:43,229] [    INFO]\u001B[0m - global step 43300/156300, epoch: 13, batch: 2661, rank_id: 0, loss: 0.159960, lr: 0.0000368816, speed: 0.8489 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:48:30,510] [    INFO]\u001B[0m - global step 43400/156300, epoch: 13, batch: 2761, rank_id: 0, loss: 0.306693, lr: 0.0000368489, speed: 0.9323 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:50:22,151] [    INFO]\u001B[0m - global step 43500/156300, epoch: 13, batch: 2861, rank_id: 0, loss: 0.105730, lr: 0.0000368163, speed: 0.8959 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:52:13,132] [    INFO]\u001B[0m - global step 43600/156300, epoch: 13, batch: 2961, rank_id: 0, loss: 0.058883, lr: 0.0000367837, speed: 0.9012 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:54:01,037] [    INFO]\u001B[0m - global step 43700/156300, epoch: 13, batch: 3061, rank_id: 0, loss: 0.102421, lr: 0.0000367510, speed: 0.9269 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:55:51,686] [    INFO]\u001B[0m - global step 43800/156300, epoch: 14, batch: 35, rank_id: 0, loss: 0.306592, lr: 0.0000367184, speed: 0.9039 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 11:57:40,296] [    INFO]\u001B[0m - global step 43900/156300, epoch: 14, batch: 135, rank_id: 0, loss: 0.202275, lr: 0.0000366857, speed: 0.9209 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 11:59:33,328] [    INFO]\u001B[0m - global step 44000/156300, epoch: 14, batch: 235, rank_id: 0, loss: 0.092806, lr: 0.0000366531, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:01:27,895] [    INFO]\u001B[0m - global step 44100/156300, epoch: 14, batch: 335, rank_id: 0, loss: 0.100913, lr: 0.0000366204, speed: 0.8730 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:03:16,978] [    INFO]\u001B[0m - global step 44200/156300, epoch: 14, batch: 435, rank_id: 0, loss: 0.080963, lr: 0.0000365878, speed: 0.9169 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:05:05,489] [    INFO]\u001B[0m - global step 44300/156300, epoch: 14, batch: 535, rank_id: 0, loss: 0.078679, lr: 0.0000365552, speed: 0.9217 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:06:56,174] [    INFO]\u001B[0m - global step 44400/156300, epoch: 14, batch: 635, rank_id: 0, loss: 0.243676, lr: 0.0000365225, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:08:46,988] [    INFO]\u001B[0m - global step 44500/156300, epoch: 14, batch: 735, rank_id: 0, loss: 0.195702, lr: 0.0000364899, speed: 0.9025 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:10:36,995] [    INFO]\u001B[0m - global step 44600/156300, epoch: 14, batch: 835, rank_id: 0, loss: 0.152033, lr: 0.0000364572, speed: 0.9092 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:12:29,362] [    INFO]\u001B[0m - global step 44700/156300, epoch: 14, batch: 935, rank_id: 0, loss: 0.220936, lr: 0.0000364246, speed: 0.8901 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:14:19,451] [    INFO]\u001B[0m - global step 44800/156300, epoch: 14, batch: 1035, rank_id: 0, loss: 0.124699, lr: 0.0000363919, speed: 0.9085 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:16:10,140] [    INFO]\u001B[0m - global step 44900/156300, epoch: 14, batch: 1135, rank_id: 0, loss: 0.079559, lr: 0.0000363593, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:18:05,242] [    INFO]\u001B[0m - global step 45000/156300, epoch: 14, batch: 1235, rank_id: 0, loss: 0.115600, lr: 0.0000363267, speed: 0.8689 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:19:57,702] [    INFO]\u001B[0m - global step 45100/156300, epoch: 14, batch: 1335, rank_id: 0, loss: 0.113266, lr: 0.0000362940, speed: 0.8893 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:21:45,133] [    INFO]\u001B[0m - global step 45200/156300, epoch: 14, batch: 1435, rank_id: 0, loss: 0.050776, lr: 0.0000362614, speed: 0.9310 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:23:35,074] [    INFO]\u001B[0m - global step 45300/156300, epoch: 14, batch: 1535, rank_id: 0, loss: 0.092150, lr: 0.0000362287, speed: 0.9097 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:25:24,921] [    INFO]\u001B[0m - global step 45400/156300, epoch: 14, batch: 1635, rank_id: 0, loss: 0.159222, lr: 0.0000361961, speed: 0.9105 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:27:16,750] [    INFO]\u001B[0m - global step 45500/156300, epoch: 14, batch: 1735, rank_id: 0, loss: 0.070960, lr: 0.0000361634, speed: 0.8943 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:29:06,491] [    INFO]\u001B[0m - global step 45600/156300, epoch: 14, batch: 1835, rank_id: 0, loss: 0.066129, lr: 0.0000361308, speed: 0.9114 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:30:57,110] [    INFO]\u001B[0m - global step 45700/156300, epoch: 14, batch: 1935, rank_id: 0, loss: 0.106781, lr: 0.0000360982, speed: 0.9041 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:32:44,924] [    INFO]\u001B[0m - global step 45800/156300, epoch: 14, batch: 2035, rank_id: 0, loss: 0.050787, lr: 0.0000360655, speed: 0.9277 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:34:34,334] [    INFO]\u001B[0m - global step 45900/156300, epoch: 14, batch: 2135, rank_id: 0, loss: 0.054314, lr: 0.0000360329, speed: 0.9141 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:36:25,267] [    INFO]\u001B[0m - global step 46000/156300, epoch: 14, batch: 2235, rank_id: 0, loss: 0.124286, lr: 0.0000360002, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:38:13,242] [    INFO]\u001B[0m - global step 46100/156300, epoch: 14, batch: 2335, rank_id: 0, loss: 0.089732, lr: 0.0000359676, speed: 0.9263 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:40:03,700] [    INFO]\u001B[0m - global step 46200/156300, epoch: 14, batch: 2435, rank_id: 0, loss: 0.119780, lr: 0.0000359349, speed: 0.9054 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:42:00,191] [    INFO]\u001B[0m - global step 46300/156300, epoch: 14, batch: 2535, rank_id: 0, loss: 0.172687, lr: 0.0000359023, speed: 0.8586 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:43:56,447] [    INFO]\u001B[0m - global step 46400/156300, epoch: 14, batch: 2635, rank_id: 0, loss: 0.154700, lr: 0.0000358697, speed: 0.8603 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:45:44,281] [    INFO]\u001B[0m - global step 46500/156300, epoch: 14, batch: 2735, rank_id: 0, loss: 0.220366, lr: 0.0000358370, speed: 0.9275 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:47:37,780] [    INFO]\u001B[0m - global step 46600/156300, epoch: 14, batch: 2835, rank_id: 0, loss: 0.083650, lr: 0.0000358044, speed: 0.8812 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:49:26,407] [    INFO]\u001B[0m - global step 46700/156300, epoch: 14, batch: 2935, rank_id: 0, loss: 0.115215, lr: 0.0000357717, speed: 0.9207 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:51:16,727] [    INFO]\u001B[0m - global step 46800/156300, epoch: 14, batch: 3035, rank_id: 0, loss: 0.128894, lr: 0.0000357391, speed: 0.9066 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:53:06,798] [    INFO]\u001B[0m - global step 46900/156300, epoch: 15, batch: 9, rank_id: 0, loss: 0.108064, lr: 0.0000357065, speed: 0.9086 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:54:55,866] [    INFO]\u001B[0m - global step 47000/156300, epoch: 15, batch: 109, rank_id: 0, loss: 0.094045, lr: 0.0000356738, speed: 0.9170 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:56:47,483] [    INFO]\u001B[0m - global step 47100/156300, epoch: 15, batch: 209, rank_id: 0, loss: 0.117565, lr: 0.0000356412, speed: 0.8960 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 12:58:41,672] [    INFO]\u001B[0m - global step 47200/156300, epoch: 15, batch: 309, rank_id: 0, loss: 0.072075, lr: 0.0000356085, speed: 0.8759 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:00:32,436] [    INFO]\u001B[0m - global step 47300/156300, epoch: 15, batch: 409, rank_id: 0, loss: 0.035724, lr: 0.0000355759, speed: 0.9029 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:02:20,235] [    INFO]\u001B[0m - global step 47400/156300, epoch: 15, batch: 509, rank_id: 0, loss: 0.077343, lr: 0.0000355432, speed: 0.9278 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:04:10,817] [    INFO]\u001B[0m - global step 47500/156300, epoch: 15, batch: 609, rank_id: 0, loss: 0.074608, lr: 0.0000355106, speed: 0.9044 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:06:00,733] [    INFO]\u001B[0m - global step 47600/156300, epoch: 15, batch: 709, rank_id: 0, loss: 0.069982, lr: 0.0000354780, speed: 0.9099 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:07:50,981] [    INFO]\u001B[0m - global step 47700/156300, epoch: 15, batch: 809, rank_id: 0, loss: 0.117172, lr: 0.0000354453, speed: 0.9072 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:09:43,597] [    INFO]\u001B[0m - global step 47800/156300, epoch: 15, batch: 909, rank_id: 0, loss: 0.115137, lr: 0.0000354127, speed: 0.8881 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:11:34,474] [    INFO]\u001B[0m - global step 47900/156300, epoch: 15, batch: 1009, rank_id: 0, loss: 0.127950, lr: 0.0000353800, speed: 0.9020 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:13:25,474] [    INFO]\u001B[0m - global step 48000/156300, epoch: 15, batch: 1109, rank_id: 0, loss: 0.164164, lr: 0.0000353474, speed: 0.9010 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:15:18,217] [    INFO]\u001B[0m - global step 48100/156300, epoch: 15, batch: 1209, rank_id: 0, loss: 0.027735, lr: 0.0000353147, speed: 0.8871 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:17:12,448] [    INFO]\u001B[0m - global step 48200/156300, epoch: 15, batch: 1309, rank_id: 0, loss: 0.104468, lr: 0.0000352821, speed: 0.8755 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:18:58,659] [    INFO]\u001B[0m - global step 48300/156300, epoch: 15, batch: 1409, rank_id: 0, loss: 0.118718, lr: 0.0000352495, speed: 0.9417 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:20:49,655] [    INFO]\u001B[0m - global step 48400/156300, epoch: 15, batch: 1509, rank_id: 0, loss: 0.070022, lr: 0.0000352168, speed: 0.9011 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:22:37,330] [    INFO]\u001B[0m - global step 48500/156300, epoch: 15, batch: 1609, rank_id: 0, loss: 0.031253, lr: 0.0000351842, speed: 0.9288 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:24:29,332] [    INFO]\u001B[0m - global step 48600/156300, epoch: 15, batch: 1709, rank_id: 0, loss: 0.071572, lr: 0.0000351515, speed: 0.8930 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:26:20,816] [    INFO]\u001B[0m - global step 48700/156300, epoch: 15, batch: 1809, rank_id: 0, loss: 0.066643, lr: 0.0000351189, speed: 0.8971 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:28:13,445] [    INFO]\u001B[0m - global step 48800/156300, epoch: 15, batch: 1909, rank_id: 0, loss: 0.066504, lr: 0.0000350862, speed: 0.8880 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 13:29:59,637] [    INFO]\u001B[0m - global step 48900/156300, epoch: 15, batch: 2009, rank_id: 0, loss: 0.141307, lr: 0.0000350536, speed: 0.9418 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:31:50,040] [    INFO]\u001B[0m - global step 49000/156300, epoch: 15, batch: 2109, rank_id: 0, loss: 0.035481, lr: 0.0000350210, speed: 0.9059 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:33:38,465] [    INFO]\u001B[0m - global step 49100/156300, epoch: 15, batch: 2209, rank_id: 0, loss: 0.047824, lr: 0.0000349883, speed: 0.9224 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:35:26,793] [    INFO]\u001B[0m - global step 49200/156300, epoch: 15, batch: 2309, rank_id: 0, loss: 0.016877, lr: 0.0000349557, speed: 0.9233 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:37:17,923] [    INFO]\u001B[0m - global step 49300/156300, epoch: 15, batch: 2409, rank_id: 0, loss: 0.122218, lr: 0.0000349230, speed: 0.9000 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:39:10,530] [    INFO]\u001B[0m - global step 49400/156300, epoch: 15, batch: 2509, rank_id: 0, loss: 0.073347, lr: 0.0000348904, speed: 0.8882 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:41:08,559] [    INFO]\u001B[0m - global step 49500/156300, epoch: 15, batch: 2609, rank_id: 0, loss: 0.132462, lr: 0.0000348577, speed: 0.8474 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:42:58,209] [    INFO]\u001B[0m - global step 49600/156300, epoch: 15, batch: 2709, rank_id: 0, loss: 0.040836, lr: 0.0000348251, speed: 0.9121 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:44:49,925] [    INFO]\u001B[0m - global step 49700/156300, epoch: 15, batch: 2809, rank_id: 0, loss: 0.100670, lr: 0.0000347925, speed: 0.8953 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:46:39,950] [    INFO]\u001B[0m - global step 49800/156300, epoch: 15, batch: 2909, rank_id: 0, loss: 0.058497, lr: 0.0000347598, speed: 0.9090 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:48:32,150] [    INFO]\u001B[0m - global step 49900/156300, epoch: 15, batch: 3009, rank_id: 0, loss: 0.108768, lr: 0.0000347272, speed: 0.8914 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:50:21,014] [    INFO]\u001B[0m - global step 50000/156300, epoch: 15, batch: 3109, rank_id: 0, loss: 0.129174, lr: 0.0000346945, speed: 0.9187 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:52:11,005] [    INFO]\u001B[0m - global step 50100/156300, epoch: 16, batch: 83, rank_id: 0, loss: 0.071936, lr: 0.0000346619, speed: 0.9093 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:54:02,352] [    INFO]\u001B[0m - global step 50200/156300, epoch: 16, batch: 183, rank_id: 0, loss: 0.077541, lr: 0.0000346292, speed: 0.8982 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:55:56,607] [    INFO]\u001B[0m - global step 50300/156300, epoch: 16, batch: 283, rank_id: 0, loss: 0.100602, lr: 0.0000345966, speed: 0.8754 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:57:48,609] [    INFO]\u001B[0m - global step 50400/156300, epoch: 16, batch: 383, rank_id: 0, loss: 0.080136, lr: 0.0000345640, speed: 0.8930 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 13:59:35,388] [    INFO]\u001B[0m - global step 50500/156300, epoch: 16, batch: 483, rank_id: 0, loss: 0.090702, lr: 0.0000345313, speed: 0.9366 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:01:25,749] [    INFO]\u001B[0m - global step 50600/156300, epoch: 16, batch: 583, rank_id: 0, loss: 0.110508, lr: 0.0000344987, speed: 0.9063 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:03:15,406] [    INFO]\u001B[0m - global step 50700/156300, epoch: 16, batch: 683, rank_id: 0, loss: 0.127239, lr: 0.0000344660, speed: 0.9121 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:05:06,104] [    INFO]\u001B[0m - global step 50800/156300, epoch: 16, batch: 783, rank_id: 0, loss: 0.114405, lr: 0.0000344334, speed: 0.9035 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:06:58,440] [    INFO]\u001B[0m - global step 50900/156300, epoch: 16, batch: 883, rank_id: 0, loss: 0.025200, lr: 0.0000344007, speed: 0.8903 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:08:47,533] [    INFO]\u001B[0m - global step 51000/156300, epoch: 16, batch: 983, rank_id: 0, loss: 0.088549, lr: 0.0000343681, speed: 0.9168 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:10:38,466] [    INFO]\u001B[0m - global step 51100/156300, epoch: 16, batch: 1083, rank_id: 0, loss: 0.157610, lr: 0.0000343355, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:12:32,486] [    INFO]\u001B[0m - global step 51200/156300, epoch: 16, batch: 1183, rank_id: 0, loss: 0.094178, lr: 0.0000343028, speed: 0.8772 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:14:26,811] [    INFO]\u001B[0m - global step 51300/156300, epoch: 16, batch: 1283, rank_id: 0, loss: 0.078293, lr: 0.0000342702, speed: 0.8748 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:16:15,026] [    INFO]\u001B[0m - global step 51400/156300, epoch: 16, batch: 1383, rank_id: 0, loss: 0.133374, lr: 0.0000342375, speed: 0.9242 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:18:05,115] [    INFO]\u001B[0m - global step 51500/156300, epoch: 16, batch: 1483, rank_id: 0, loss: 0.100615, lr: 0.0000342049, speed: 0.9085 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:19:52,887] [    INFO]\u001B[0m - global step 51600/156300, epoch: 16, batch: 1583, rank_id: 0, loss: 0.052675, lr: 0.0000341722, speed: 0.9280 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:21:42,110] [    INFO]\u001B[0m - global step 51700/156300, epoch: 16, batch: 1683, rank_id: 0, loss: 0.063539, lr: 0.0000341396, speed: 0.9157 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:23:35,662] [    INFO]\u001B[0m - global step 51800/156300, epoch: 16, batch: 1783, rank_id: 0, loss: 0.066491, lr: 0.0000341070, speed: 0.8808 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:25:26,928] [    INFO]\u001B[0m - global step 51900/156300, epoch: 16, batch: 1883, rank_id: 0, loss: 0.057702, lr: 0.0000340743, speed: 0.8989 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:27:17,366] [    INFO]\u001B[0m - global step 52000/156300, epoch: 16, batch: 1983, rank_id: 0, loss: 0.052724, lr: 0.0000340417, speed: 0.9056 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:29:06,274] [    INFO]\u001B[0m - global step 52100/156300, epoch: 16, batch: 2083, rank_id: 0, loss: 0.082887, lr: 0.0000340090, speed: 0.9183 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:30:54,295] [    INFO]\u001B[0m - global step 52200/156300, epoch: 16, batch: 2183, rank_id: 0, loss: 0.104845, lr: 0.0000339764, speed: 0.9259 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:32:44,964] [    INFO]\u001B[0m - global step 52300/156300, epoch: 16, batch: 2283, rank_id: 0, loss: 0.045397, lr: 0.0000339438, speed: 0.9037 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:34:35,206] [    INFO]\u001B[0m - global step 52400/156300, epoch: 16, batch: 2383, rank_id: 0, loss: 0.048813, lr: 0.0000339111, speed: 0.9072 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:36:25,946] [    INFO]\u001B[0m - global step 52500/156300, epoch: 16, batch: 2483, rank_id: 0, loss: 0.065320, lr: 0.0000338785, speed: 0.9031 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:38:20,955] [    INFO]\u001B[0m - global step 52600/156300, epoch: 16, batch: 2583, rank_id: 0, loss: 0.034467, lr: 0.0000338458, speed: 0.8696 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:40:16,745] [    INFO]\u001B[0m - global step 52700/156300, epoch: 16, batch: 2683, rank_id: 0, loss: 0.119555, lr: 0.0000338132, speed: 0.8637 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:42:06,403] [    INFO]\u001B[0m - global step 52800/156300, epoch: 16, batch: 2783, rank_id: 0, loss: 0.091710, lr: 0.0000337805, speed: 0.9121 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:43:56,212] [    INFO]\u001B[0m - global step 52900/156300, epoch: 16, batch: 2883, rank_id: 0, loss: 0.069781, lr: 0.0000337479, speed: 0.9108 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:45:48,228] [    INFO]\u001B[0m - global step 53000/156300, epoch: 16, batch: 2983, rank_id: 0, loss: 0.077968, lr: 0.0000337153, speed: 0.8929 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:47:38,136] [    INFO]\u001B[0m - global step 53100/156300, epoch: 16, batch: 3083, rank_id: 0, loss: 0.109192, lr: 0.0000336826, speed: 0.9100 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:49:25,933] [    INFO]\u001B[0m - global step 53200/156300, epoch: 17, batch: 57, rank_id: 0, loss: 0.077715, lr: 0.0000336500, speed: 0.9278 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:51:16,603] [    INFO]\u001B[0m - global step 53300/156300, epoch: 17, batch: 157, rank_id: 0, loss: 0.073417, lr: 0.0000336173, speed: 0.9037 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:53:10,296] [    INFO]\u001B[0m - global step 53400/156300, epoch: 17, batch: 257, rank_id: 0, loss: 0.043622, lr: 0.0000335847, speed: 0.8797 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:55:04,272] [    INFO]\u001B[0m - global step 53500/156300, epoch: 17, batch: 357, rank_id: 0, loss: 0.065349, lr: 0.0000335520, speed: 0.8775 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:56:53,756] [    INFO]\u001B[0m - global step 53600/156300, epoch: 17, batch: 457, rank_id: 0, loss: 0.114129, lr: 0.0000335194, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 14:58:41,708] [    INFO]\u001B[0m - global step 53700/156300, epoch: 17, batch: 557, rank_id: 0, loss: 0.078447, lr: 0.0000334868, speed: 0.9265 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 15:00:31,331] [    INFO]\u001B[0m - global step 53800/156300, epoch: 17, batch: 657, rank_id: 0, loss: 0.063194, lr: 0.0000334541, speed: 0.9123 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:02:22,180] [    INFO]\u001B[0m - global step 53900/156300, epoch: 17, batch: 757, rank_id: 0, loss: 0.081131, lr: 0.0000334215, speed: 0.9023 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:04:14,322] [    INFO]\u001B[0m - global step 54000/156300, epoch: 17, batch: 857, rank_id: 0, loss: 0.079001, lr: 0.0000333888, speed: 0.8918 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:06:05,682] [    INFO]\u001B[0m - global step 54100/156300, epoch: 17, batch: 957, rank_id: 0, loss: 0.090772, lr: 0.0000333562, speed: 0.8981 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:07:56,844] [    INFO]\u001B[0m - global step 54200/156300, epoch: 17, batch: 1057, rank_id: 0, loss: 0.049205, lr: 0.0000333235, speed: 0.8997 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:09:48,523] [    INFO]\u001B[0m - global step 54300/156300, epoch: 17, batch: 1157, rank_id: 0, loss: 0.075157, lr: 0.0000332909, speed: 0.8955 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:11:42,179] [    INFO]\u001B[0m - global step 54400/156300, epoch: 17, batch: 1257, rank_id: 0, loss: 0.053425, lr: 0.0000332583, speed: 0.8800 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:13:32,744] [    INFO]\u001B[0m - global step 54500/156300, epoch: 17, batch: 1357, rank_id: 0, loss: 0.079766, lr: 0.0000332256, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:15:20,616] [    INFO]\u001B[0m - global step 54600/156300, epoch: 17, batch: 1457, rank_id: 0, loss: 0.062338, lr: 0.0000331930, speed: 0.9272 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:17:09,761] [    INFO]\u001B[0m - global step 54700/156300, epoch: 17, batch: 1557, rank_id: 0, loss: 0.037828, lr: 0.0000331603, speed: 0.9163 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:18:59,969] [    INFO]\u001B[0m - global step 54800/156300, epoch: 17, batch: 1657, rank_id: 0, loss: 0.056595, lr: 0.0000331277, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:20:52,732] [    INFO]\u001B[0m - global step 54900/156300, epoch: 17, batch: 1757, rank_id: 0, loss: 0.039615, lr: 0.0000330950, speed: 0.8869 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:22:41,866] [    INFO]\u001B[0m - global step 55000/156300, epoch: 17, batch: 1857, rank_id: 0, loss: 0.056296, lr: 0.0000330624, speed: 0.9164 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:24:33,103] [    INFO]\u001B[0m - global step 55100/156300, epoch: 17, batch: 1957, rank_id: 0, loss: 0.075908, lr: 0.0000330298, speed: 0.8991 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:26:21,553] [    INFO]\u001B[0m - global step 55200/156300, epoch: 17, batch: 2057, rank_id: 0, loss: 0.042916, lr: 0.0000329971, speed: 0.9222 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:28:09,233] [    INFO]\u001B[0m - global step 55300/156300, epoch: 17, batch: 2157, rank_id: 0, loss: 0.061539, lr: 0.0000329645, speed: 0.9288 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:30:00,540] [    INFO]\u001B[0m - global step 55400/156300, epoch: 17, batch: 2257, rank_id: 0, loss: 0.050026, lr: 0.0000329318, speed: 0.8985 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:31:50,525] [    INFO]\u001B[0m - global step 55500/156300, epoch: 17, batch: 2357, rank_id: 0, loss: 0.049927, lr: 0.0000328992, speed: 0.9093 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:33:42,364] [    INFO]\u001B[0m - global step 55600/156300, epoch: 17, batch: 2457, rank_id: 0, loss: 0.055310, lr: 0.0000328665, speed: 0.8943 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:35:36,423] [    INFO]\u001B[0m - global step 55700/156300, epoch: 17, batch: 2557, rank_id: 0, loss: 0.034282, lr: 0.0000328339, speed: 0.8769 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:37:33,882] [    INFO]\u001B[0m - global step 55800/156300, epoch: 17, batch: 2657, rank_id: 0, loss: 0.083122, lr: 0.0000328013, speed: 0.8515 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:39:20,730] [    INFO]\u001B[0m - global step 55900/156300, epoch: 17, batch: 2757, rank_id: 0, loss: 0.045224, lr: 0.0000327686, speed: 0.9360 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:41:12,735] [    INFO]\u001B[0m - global step 56000/156300, epoch: 17, batch: 2857, rank_id: 0, loss: 0.054205, lr: 0.0000327360, speed: 0.8929 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:43:03,608] [    INFO]\u001B[0m - global step 56100/156300, epoch: 17, batch: 2957, rank_id: 0, loss: 0.110948, lr: 0.0000327033, speed: 0.9021 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:44:52,374] [    INFO]\u001B[0m - global step 56200/156300, epoch: 17, batch: 3057, rank_id: 0, loss: 0.048398, lr: 0.0000326707, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:46:42,592] [    INFO]\u001B[0m - global step 56300/156300, epoch: 18, batch: 31, rank_id: 0, loss: 0.090126, lr: 0.0000326380, speed: 0.9074 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:48:32,142] [    INFO]\u001B[0m - global step 56400/156300, epoch: 18, batch: 131, rank_id: 0, loss: 0.022613, lr: 0.0000326054, speed: 0.9129 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:50:24,596] [    INFO]\u001B[0m - global step 56500/156300, epoch: 18, batch: 231, rank_id: 0, loss: 0.026541, lr: 0.0000325728, speed: 0.8894 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:52:19,131] [    INFO]\u001B[0m - global step 56600/156300, epoch: 18, batch: 331, rank_id: 0, loss: 0.029794, lr: 0.0000325401, speed: 0.8732 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:54:08,900] [    INFO]\u001B[0m - global step 56700/156300, epoch: 18, batch: 431, rank_id: 0, loss: 0.047610, lr: 0.0000325075, speed: 0.9111 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:55:56,936] [    INFO]\u001B[0m - global step 56800/156300, epoch: 18, batch: 531, rank_id: 0, loss: 0.112470, lr: 0.0000324748, speed: 0.9257 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:57:46,873] [    INFO]\u001B[0m - global step 56900/156300, epoch: 18, batch: 631, rank_id: 0, loss: 0.049635, lr: 0.0000324422, speed: 0.9097 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 15:59:37,457] [    INFO]\u001B[0m - global step 57000/156300, epoch: 18, batch: 731, rank_id: 0, loss: 0.040967, lr: 0.0000324095, speed: 0.9044 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:01:27,612] [    INFO]\u001B[0m - global step 57100/156300, epoch: 18, batch: 831, rank_id: 0, loss: 0.047747, lr: 0.0000323769, speed: 0.9079 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:03:20,773] [    INFO]\u001B[0m - global step 57200/156300, epoch: 18, batch: 931, rank_id: 0, loss: 0.083804, lr: 0.0000323443, speed: 0.8838 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:05:10,356] [    INFO]\u001B[0m - global step 57300/156300, epoch: 18, batch: 1031, rank_id: 0, loss: 0.035157, lr: 0.0000323116, speed: 0.9127 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:07:01,294] [    INFO]\u001B[0m - global step 57400/156300, epoch: 18, batch: 1131, rank_id: 0, loss: 0.119000, lr: 0.0000322790, speed: 0.9015 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:08:55,726] [    INFO]\u001B[0m - global step 57500/156300, epoch: 18, batch: 1231, rank_id: 0, loss: 0.056179, lr: 0.0000322463, speed: 0.8740 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:10:49,373] [    INFO]\u001B[0m - global step 57600/156300, epoch: 18, batch: 1331, rank_id: 0, loss: 0.075622, lr: 0.0000322137, speed: 0.8800 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:12:36,736] [    INFO]\u001B[0m - global step 57700/156300, epoch: 18, batch: 1431, rank_id: 0, loss: 0.133250, lr: 0.0000321810, speed: 0.9316 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:14:26,728] [    INFO]\u001B[0m - global step 57800/156300, epoch: 18, batch: 1531, rank_id: 0, loss: 0.074993, lr: 0.0000321484, speed: 0.9093 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:16:15,821] [    INFO]\u001B[0m - global step 57900/156300, epoch: 18, batch: 1631, rank_id: 0, loss: 0.101606, lr: 0.0000321158, speed: 0.9168 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:18:07,609] [    INFO]\u001B[0m - global step 58000/156300, epoch: 18, batch: 1731, rank_id: 0, loss: 0.041244, lr: 0.0000320831, speed: 0.8947 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:19:58,379] [    INFO]\u001B[0m - global step 58100/156300, epoch: 18, batch: 1831, rank_id: 0, loss: 0.032865, lr: 0.0000320505, speed: 0.9029 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:21:48,160] [    INFO]\u001B[0m - global step 58200/156300, epoch: 18, batch: 1931, rank_id: 0, loss: 0.040365, lr: 0.0000320178, speed: 0.9110 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:23:37,068] [    INFO]\u001B[0m - global step 58300/156300, epoch: 18, batch: 2031, rank_id: 0, loss: 0.084864, lr: 0.0000319852, speed: 0.9183 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:25:26,259] [    INFO]\u001B[0m - global step 58400/156300, epoch: 18, batch: 2131, rank_id: 0, loss: 0.090976, lr: 0.0000319526, speed: 0.9160 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:27:16,093] [    INFO]\u001B[0m - global step 58500/156300, epoch: 18, batch: 2231, rank_id: 0, loss: 0.056666, lr: 0.0000319199, speed: 0.9106 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:29:04,963] [    INFO]\u001B[0m - global step 58600/156300, epoch: 18, batch: 2331, rank_id: 0, loss: 0.077943, lr: 0.0000318873, speed: 0.9187 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 16:30:55,002] [    INFO]\u001B[0m - global step 58700/156300, epoch: 18, batch: 2431, rank_id: 0, loss: 0.041807, lr: 0.0000318546, speed: 0.9089 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:32:50,671] [    INFO]\u001B[0m - global step 58800/156300, epoch: 18, batch: 2531, rank_id: 0, loss: 0.040672, lr: 0.0000318220, speed: 0.8647 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:34:47,380] [    INFO]\u001B[0m - global step 58900/156300, epoch: 18, batch: 2631, rank_id: 0, loss: 0.079626, lr: 0.0000317893, speed: 0.8569 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:36:35,450] [    INFO]\u001B[0m - global step 59000/156300, epoch: 18, batch: 2731, rank_id: 0, loss: 0.044480, lr: 0.0000317567, speed: 0.9255 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:38:28,240] [    INFO]\u001B[0m - global step 59100/156300, epoch: 18, batch: 2831, rank_id: 0, loss: 0.036665, lr: 0.0000317241, speed: 0.8867 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:40:17,281] [    INFO]\u001B[0m - global step 59200/156300, epoch: 18, batch: 2931, rank_id: 0, loss: 0.034881, lr: 0.0000316914, speed: 0.9172 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:42:08,103] [    INFO]\u001B[0m - global step 59300/156300, epoch: 18, batch: 3031, rank_id: 0, loss: 0.070606, lr: 0.0000316588, speed: 0.9025 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:43:58,478] [    INFO]\u001B[0m - global step 59400/156300, epoch: 19, batch: 5, rank_id: 0, loss: 0.054651, lr: 0.0000316261, speed: 0.9061 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:45:46,644] [    INFO]\u001B[0m - global step 59500/156300, epoch: 19, batch: 105, rank_id: 0, loss: 0.084706, lr: 0.0000315935, speed: 0.9246 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:47:39,710] [    INFO]\u001B[0m - global step 59600/156300, epoch: 19, batch: 205, rank_id: 0, loss: 0.018132, lr: 0.0000315608, speed: 0.8846 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:49:33,194] [    INFO]\u001B[0m - global step 59700/156300, epoch: 19, batch: 305, rank_id: 0, loss: 0.137354, lr: 0.0000315282, speed: 0.8813 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:51:24,334] [    INFO]\u001B[0m - global step 59800/156300, epoch: 19, batch: 405, rank_id: 0, loss: 0.045865, lr: 0.0000314956, speed: 0.8999 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:53:11,625] [    INFO]\u001B[0m - global step 59900/156300, epoch: 19, batch: 505, rank_id: 0, loss: 0.027618, lr: 0.0000314629, speed: 0.9322 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:55:02,422] [    INFO]\u001B[0m - global step 60000/156300, epoch: 19, batch: 605, rank_id: 0, loss: 0.046930, lr: 0.0000314303, speed: 0.9027 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:55:13,017] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:55:13,019] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:57:02,874] [    INFO]\u001B[0m - global step 60100/156300, epoch: 19, batch: 705, rank_id: 0, loss: 0.067930, lr: 0.0000313976, speed: 0.8303 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 16:58:53,721] [    INFO]\u001B[0m - global step 60200/156300, epoch: 19, batch: 805, rank_id: 0, loss: 0.061755, lr: 0.0000313650, speed: 0.9023 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:00:45,852] [    INFO]\u001B[0m - global step 60300/156300, epoch: 19, batch: 905, rank_id: 0, loss: 0.075472, lr: 0.0000313323, speed: 0.8919 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:02:36,727] [    INFO]\u001B[0m - global step 60400/156300, epoch: 19, batch: 1005, rank_id: 0, loss: 0.088524, lr: 0.0000312997, speed: 0.9020 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:04:28,034] [    INFO]\u001B[0m - global step 60500/156300, epoch: 19, batch: 1105, rank_id: 0, loss: 0.040506, lr: 0.0000312671, speed: 0.8985 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:06:21,700] [    INFO]\u001B[0m - global step 60600/156300, epoch: 19, batch: 1205, rank_id: 0, loss: 0.038620, lr: 0.0000312344, speed: 0.8799 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:08:15,170] [    INFO]\u001B[0m - global step 60700/156300, epoch: 19, batch: 1305, rank_id: 0, loss: 0.033245, lr: 0.0000312018, speed: 0.8814 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:10:01,811] [    INFO]\u001B[0m - global step 60800/156300, epoch: 19, batch: 1405, rank_id: 0, loss: 0.033699, lr: 0.0000311691, speed: 0.9379 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:11:52,116] [    INFO]\u001B[0m - global step 60900/156300, epoch: 19, batch: 1505, rank_id: 0, loss: 0.035214, lr: 0.0000311365, speed: 0.9067 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:13:40,493] [    INFO]\u001B[0m - global step 61000/156300, epoch: 19, batch: 1605, rank_id: 0, loss: 0.044832, lr: 0.0000311038, speed: 0.9228 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:15:31,090] [    INFO]\u001B[0m - global step 61100/156300, epoch: 19, batch: 1705, rank_id: 0, loss: 0.049928, lr: 0.0000310712, speed: 0.9043 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:17:24,418] [    INFO]\u001B[0m - global step 61200/156300, epoch: 19, batch: 1805, rank_id: 0, loss: 0.037088, lr: 0.0000310386, speed: 0.8825 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:19:16,883] [    INFO]\u001B[0m - global step 61300/156300, epoch: 19, batch: 1905, rank_id: 0, loss: 0.038764, lr: 0.0000310059, speed: 0.8893 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:21:03,341] [    INFO]\u001B[0m - global step 61400/156300, epoch: 19, batch: 2005, rank_id: 0, loss: 0.049379, lr: 0.0000309733, speed: 0.9395 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:22:53,455] [    INFO]\u001B[0m - global step 61500/156300, epoch: 19, batch: 2105, rank_id: 0, loss: 0.022972, lr: 0.0000309406, speed: 0.9083 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:24:40,886] [    INFO]\u001B[0m - global step 61600/156300, epoch: 19, batch: 2205, rank_id: 0, loss: 0.055075, lr: 0.0000309080, speed: 0.9310 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:26:29,997] [    INFO]\u001B[0m - global step 61700/156300, epoch: 19, batch: 2305, rank_id: 0, loss: 0.077258, lr: 0.0000308753, speed: 0.9166 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:28:20,893] [    INFO]\u001B[0m - global step 61800/156300, epoch: 19, batch: 2405, rank_id: 0, loss: 0.037960, lr: 0.0000308427, speed: 0.9019 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:30:13,933] [    INFO]\u001B[0m - global step 61900/156300, epoch: 19, batch: 2505, rank_id: 0, loss: 0.041235, lr: 0.0000308101, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:32:10,532] [    INFO]\u001B[0m - global step 62000/156300, epoch: 19, batch: 2605, rank_id: 0, loss: 0.031444, lr: 0.0000307774, speed: 0.8578 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:34:01,812] [    INFO]\u001B[0m - global step 62100/156300, epoch: 19, batch: 2705, rank_id: 0, loss: 0.043491, lr: 0.0000307448, speed: 0.8988 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:35:53,191] [    INFO]\u001B[0m - global step 62200/156300, epoch: 19, batch: 2805, rank_id: 0, loss: 0.078263, lr: 0.0000307121, speed: 0.8980 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:37:44,115] [    INFO]\u001B[0m - global step 62300/156300, epoch: 19, batch: 2905, rank_id: 0, loss: 0.022561, lr: 0.0000306795, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:39:35,086] [    INFO]\u001B[0m - global step 62400/156300, epoch: 19, batch: 3005, rank_id: 0, loss: 0.054165, lr: 0.0000306468, speed: 0.9013 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:41:23,962] [    INFO]\u001B[0m - global step 62500/156300, epoch: 19, batch: 3105, rank_id: 0, loss: 0.053985, lr: 0.0000306142, speed: 0.9186 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:43:12,840] [    INFO]\u001B[0m - global step 62600/156300, epoch: 20, batch: 79, rank_id: 0, loss: 0.034790, lr: 0.0000305816, speed: 0.9186 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:45:04,974] [    INFO]\u001B[0m - global step 62700/156300, epoch: 20, batch: 179, rank_id: 0, loss: 0.044336, lr: 0.0000305489, speed: 0.8919 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:46:59,134] [    INFO]\u001B[0m - global step 62800/156300, epoch: 20, batch: 279, rank_id: 0, loss: 0.064025, lr: 0.0000305163, speed: 0.8761 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:48:51,336] [    INFO]\u001B[0m - global step 62900/156300, epoch: 20, batch: 379, rank_id: 0, loss: 0.068884, lr: 0.0000304836, speed: 0.8914 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:50:38,951] [    INFO]\u001B[0m - global step 63000/156300, epoch: 20, batch: 479, rank_id: 0, loss: 0.035200, lr: 0.0000304510, speed: 0.9294 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:52:28,736] [    INFO]\u001B[0m - global step 63100/156300, epoch: 20, batch: 579, rank_id: 0, loss: 0.023211, lr: 0.0000304183, speed: 0.9110 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:54:18,008] [    INFO]\u001B[0m - global step 63200/156300, epoch: 20, batch: 679, rank_id: 0, loss: 0.041198, lr: 0.0000303857, speed: 0.9153 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:56:09,116] [    INFO]\u001B[0m - global step 63300/156300, epoch: 20, batch: 779, rank_id: 0, loss: 0.044770, lr: 0.0000303531, speed: 0.9001 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 17:58:02,071] [    INFO]\u001B[0m - global step 63400/156300, epoch: 20, batch: 879, rank_id: 0, loss: 0.062701, lr: 0.0000303204, speed: 0.8854 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 17:59:50,327] [    INFO]\u001B[0m - global step 63500/156300, epoch: 20, batch: 979, rank_id: 0, loss: 0.029052, lr: 0.0000302878, speed: 0.9239 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:01:41,221] [    INFO]\u001B[0m - global step 63600/156300, epoch: 20, batch: 1079, rank_id: 0, loss: 0.047503, lr: 0.0000302551, speed: 0.9019 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:03:34,927] [    INFO]\u001B[0m - global step 63700/156300, epoch: 20, batch: 1179, rank_id: 0, loss: 0.039161, lr: 0.0000302225, speed: 0.8796 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:05:29,235] [    INFO]\u001B[0m - global step 63800/156300, epoch: 20, batch: 1279, rank_id: 0, loss: 0.041827, lr: 0.0000301898, speed: 0.8749 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:07:16,965] [    INFO]\u001B[0m - global step 63900/156300, epoch: 20, batch: 1379, rank_id: 0, loss: 0.062847, lr: 0.0000301572, speed: 0.9284 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:09:06,778] [    INFO]\u001B[0m - global step 64000/156300, epoch: 20, batch: 1479, rank_id: 0, loss: 0.066469, lr: 0.0000301246, speed: 0.9108 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:10:55,110] [    INFO]\u001B[0m - global step 64100/156300, epoch: 20, batch: 1579, rank_id: 0, loss: 0.029219, lr: 0.0000300919, speed: 0.9232 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:12:43,997] [    INFO]\u001B[0m - global step 64200/156300, epoch: 20, batch: 1679, rank_id: 0, loss: 0.031345, lr: 0.0000300593, speed: 0.9185 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:14:37,260] [    INFO]\u001B[0m - global step 64300/156300, epoch: 20, batch: 1779, rank_id: 0, loss: 0.043532, lr: 0.0000300266, speed: 0.8830 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:16:27,600] [    INFO]\u001B[0m - global step 64400/156300, epoch: 20, batch: 1879, rank_id: 0, loss: 0.051427, lr: 0.0000299940, speed: 0.9064 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:18:18,772] [    INFO]\u001B[0m - global step 64500/156300, epoch: 20, batch: 1979, rank_id: 0, loss: 0.028073, lr: 0.0000299614, speed: 0.8996 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:20:08,142] [    INFO]\u001B[0m - global step 64600/156300, epoch: 20, batch: 2079, rank_id: 0, loss: 0.022060, lr: 0.0000299287, speed: 0.9145 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:21:55,387] [    INFO]\u001B[0m - global step 64700/156300, epoch: 20, batch: 2179, rank_id: 0, loss: 0.041034, lr: 0.0000298961, speed: 0.9326 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:23:45,756] [    INFO]\u001B[0m - global step 64800/156300, epoch: 20, batch: 2279, rank_id: 0, loss: 0.039422, lr: 0.0000298634, speed: 0.9062 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:25:36,149] [    INFO]\u001B[0m - global step 64900/156300, epoch: 20, batch: 2379, rank_id: 0, loss: 0.060348, lr: 0.0000298308, speed: 0.9060 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:27:26,828] [    INFO]\u001B[0m - global step 65000/156300, epoch: 20, batch: 2479, rank_id: 0, loss: 0.032941, lr: 0.0000297981, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:29:21,461] [    INFO]\u001B[0m - global step 65100/156300, epoch: 20, batch: 2579, rank_id: 0, loss: 0.040118, lr: 0.0000297655, speed: 0.8725 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:31:17,880] [    INFO]\u001B[0m - global step 65200/156300, epoch: 20, batch: 2679, rank_id: 0, loss: 0.037178, lr: 0.0000297329, speed: 0.8591 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:33:06,927] [    INFO]\u001B[0m - global step 65300/156300, epoch: 20, batch: 2779, rank_id: 0, loss: 0.071765, lr: 0.0000297002, speed: 0.9172 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:34:57,503] [    INFO]\u001B[0m - global step 65400/156300, epoch: 20, batch: 2879, rank_id: 0, loss: 0.077560, lr: 0.0000296676, speed: 0.9045 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:36:47,983] [    INFO]\u001B[0m - global step 65500/156300, epoch: 20, batch: 2979, rank_id: 0, loss: 0.034702, lr: 0.0000296349, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:38:38,156] [    INFO]\u001B[0m - global step 65600/156300, epoch: 20, batch: 3079, rank_id: 0, loss: 0.061412, lr: 0.0000296023, speed: 0.9078 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:40:26,614] [    INFO]\u001B[0m - global step 65700/156300, epoch: 21, batch: 53, rank_id: 0, loss: 0.039501, lr: 0.0000295696, speed: 0.9221 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:42:16,281] [    INFO]\u001B[0m - global step 65800/156300, epoch: 21, batch: 153, rank_id: 0, loss: 0.031939, lr: 0.0000295370, speed: 0.9120 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:44:10,467] [    INFO]\u001B[0m - global step 65900/156300, epoch: 21, batch: 253, rank_id: 0, loss: 0.045900, lr: 0.0000295044, speed: 0.8759 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:46:04,214] [    INFO]\u001B[0m - global step 66000/156300, epoch: 21, batch: 353, rank_id: 0, loss: 0.039938, lr: 0.0000294717, speed: 0.8793 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:47:53,546] [    INFO]\u001B[0m - global step 66100/156300, epoch: 21, batch: 453, rank_id: 0, loss: 0.035920, lr: 0.0000294391, speed: 0.9148 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:49:41,724] [    INFO]\u001B[0m - global step 66200/156300, epoch: 21, batch: 553, rank_id: 0, loss: 0.022543, lr: 0.0000294064, speed: 0.9245 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:51:31,822] [    INFO]\u001B[0m - global step 66300/156300, epoch: 21, batch: 653, rank_id: 0, loss: 0.038034, lr: 0.0000293738, speed: 0.9084 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:53:22,152] [    INFO]\u001B[0m - global step 66400/156300, epoch: 21, batch: 753, rank_id: 0, loss: 0.052429, lr: 0.0000293411, speed: 0.9065 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:55:14,391] [    INFO]\u001B[0m - global step 66500/156300, epoch: 21, batch: 853, rank_id: 0, loss: 0.033110, lr: 0.0000293085, speed: 0.8911 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:57:04,939] [    INFO]\u001B[0m - global step 66600/156300, epoch: 21, batch: 953, rank_id: 0, loss: 0.055004, lr: 0.0000292759, speed: 0.9047 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 18:58:56,680] [    INFO]\u001B[0m - global step 66700/156300, epoch: 21, batch: 1053, rank_id: 0, loss: 0.050860, lr: 0.0000292432, speed: 0.8950 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:00:47,621] [    INFO]\u001B[0m - global step 66800/156300, epoch: 21, batch: 1153, rank_id: 0, loss: 0.038714, lr: 0.0000292106, speed: 0.9015 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:02:42,137] [    INFO]\u001B[0m - global step 66900/156300, epoch: 21, batch: 1253, rank_id: 0, loss: 0.060871, lr: 0.0000291779, speed: 0.8734 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:04:31,919] [    INFO]\u001B[0m - global step 67000/156300, epoch: 21, batch: 1353, rank_id: 0, loss: 0.029107, lr: 0.0000291453, speed: 0.9110 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:06:20,052] [    INFO]\u001B[0m - global step 67100/156300, epoch: 21, batch: 1453, rank_id: 0, loss: 0.036907, lr: 0.0000291126, speed: 0.9249 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:08:09,629] [    INFO]\u001B[0m - global step 67200/156300, epoch: 21, batch: 1553, rank_id: 0, loss: 0.041453, lr: 0.0000290800, speed: 0.9127 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:09:59,539] [    INFO]\u001B[0m - global step 67300/156300, epoch: 21, batch: 1653, rank_id: 0, loss: 0.052207, lr: 0.0000290474, speed: 0.9100 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:11:52,542] [    INFO]\u001B[0m - global step 67400/156300, epoch: 21, batch: 1753, rank_id: 0, loss: 0.037581, lr: 0.0000290147, speed: 0.8851 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:13:41,912] [    INFO]\u001B[0m - global step 67500/156300, epoch: 21, batch: 1853, rank_id: 0, loss: 0.027477, lr: 0.0000289821, speed: 0.9145 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:15:32,579] [    INFO]\u001B[0m - global step 67600/156300, epoch: 21, batch: 1953, rank_id: 0, loss: 0.016138, lr: 0.0000289494, speed: 0.9037 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:17:20,675] [    INFO]\u001B[0m - global step 67700/156300, epoch: 21, batch: 2053, rank_id: 0, loss: 0.027853, lr: 0.0000289168, speed: 0.9252 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:19:08,631] [    INFO]\u001B[0m - global step 67800/156300, epoch: 21, batch: 2153, rank_id: 0, loss: 0.038077, lr: 0.0000288841, speed: 0.9264 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:21:00,192] [    INFO]\u001B[0m - global step 67900/156300, epoch: 21, batch: 2253, rank_id: 0, loss: 0.059479, lr: 0.0000288515, speed: 0.8965 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:22:49,204] [    INFO]\u001B[0m - global step 68000/156300, epoch: 21, batch: 2353, rank_id: 0, loss: 0.027404, lr: 0.0000288189, speed: 0.9175 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:24:41,111] [    INFO]\u001B[0m - global step 68100/156300, epoch: 21, batch: 2453, rank_id: 0, loss: 0.027987, lr: 0.0000287862, speed: 0.8937 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:26:36,218] [    INFO]\u001B[0m - global step 68200/156300, epoch: 21, batch: 2553, rank_id: 0, loss: 0.018975, lr: 0.0000287536, speed: 0.8689 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:28:33,085] [    INFO]\u001B[0m - global step 68300/156300, epoch: 21, batch: 2653, rank_id: 0, loss: 0.062196, lr: 0.0000287209, speed: 0.8558 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 19:30:19,941] [    INFO]\u001B[0m - global step 68400/156300, epoch: 21, batch: 2753, rank_id: 0, loss: 0.015345, lr: 0.0000286883, speed: 0.9360 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:32:12,533] [    INFO]\u001B[0m - global step 68500/156300, epoch: 21, batch: 2853, rank_id: 0, loss: 0.038895, lr: 0.0000286556, speed: 0.8883 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:34:02,363] [    INFO]\u001B[0m - global step 68600/156300, epoch: 21, batch: 2953, rank_id: 0, loss: 0.046174, lr: 0.0000286230, speed: 0.9107 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:35:51,557] [    INFO]\u001B[0m - global step 68700/156300, epoch: 21, batch: 3053, rank_id: 0, loss: 0.032151, lr: 0.0000285904, speed: 0.9160 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:37:41,682] [    INFO]\u001B[0m - global step 68800/156300, epoch: 22, batch: 27, rank_id: 0, loss: 0.064449, lr: 0.0000285577, speed: 0.9082 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:39:31,286] [    INFO]\u001B[0m - global step 68900/156300, epoch: 22, batch: 127, rank_id: 0, loss: 0.023632, lr: 0.0000285251, speed: 0.9125 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:41:23,101] [    INFO]\u001B[0m - global step 69000/156300, epoch: 22, batch: 227, rank_id: 0, loss: 0.032605, lr: 0.0000284924, speed: 0.8945 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:43:17,913] [    INFO]\u001B[0m - global step 69100/156300, epoch: 22, batch: 327, rank_id: 0, loss: 0.034839, lr: 0.0000284598, speed: 0.8711 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:45:07,813] [    INFO]\u001B[0m - global step 69200/156300, epoch: 22, batch: 427, rank_id: 0, loss: 0.031070, lr: 0.0000284271, speed: 0.9101 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:46:55,197] [    INFO]\u001B[0m - global step 69300/156300, epoch: 22, batch: 527, rank_id: 0, loss: 0.076713, lr: 0.0000283945, speed: 0.9314 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:48:46,176] [    INFO]\u001B[0m - global step 69400/156300, epoch: 22, batch: 627, rank_id: 0, loss: 0.029022, lr: 0.0000283619, speed: 0.9012 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:50:36,185] [    INFO]\u001B[0m - global step 69500/156300, epoch: 22, batch: 727, rank_id: 0, loss: 0.017649, lr: 0.0000283292, speed: 0.9091 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:52:26,441] [    INFO]\u001B[0m - global step 69600/156300, epoch: 22, batch: 827, rank_id: 0, loss: 0.031545, lr: 0.0000282966, speed: 0.9071 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:54:18,670] [    INFO]\u001B[0m - global step 69700/156300, epoch: 22, batch: 927, rank_id: 0, loss: 0.025567, lr: 0.0000282639, speed: 0.8912 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:56:09,494] [    INFO]\u001B[0m - global step 69800/156300, epoch: 22, batch: 1027, rank_id: 0, loss: 0.026103, lr: 0.0000282313, speed: 0.9025 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:57:59,785] [    INFO]\u001B[0m - global step 69900/156300, epoch: 22, batch: 1127, rank_id: 0, loss: 0.042039, lr: 0.0000281986, speed: 0.9068 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 19:59:54,185] [    INFO]\u001B[0m - global step 70000/156300, epoch: 22, batch: 1227, rank_id: 0, loss: 0.033714, lr: 0.0000281660, speed: 0.8742 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:01:48,002] [    INFO]\u001B[0m - global step 70100/156300, epoch: 22, batch: 1327, rank_id: 0, loss: 0.042254, lr: 0.0000281334, speed: 0.8787 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:03:34,379] [    INFO]\u001B[0m - global step 70200/156300, epoch: 22, batch: 1427, rank_id: 0, loss: 0.044103, lr: 0.0000281007, speed: 0.9402 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:05:25,226] [    INFO]\u001B[0m - global step 70300/156300, epoch: 22, batch: 1527, rank_id: 0, loss: 0.026957, lr: 0.0000280681, speed: 0.9023 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:07:13,991] [    INFO]\u001B[0m - global step 70400/156300, epoch: 22, batch: 1627, rank_id: 0, loss: 0.078447, lr: 0.0000280354, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:09:06,386] [    INFO]\u001B[0m - global step 70500/156300, epoch: 22, batch: 1727, rank_id: 0, loss: 0.023703, lr: 0.0000280028, speed: 0.8898 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:10:56,478] [    INFO]\u001B[0m - global step 70600/156300, epoch: 22, batch: 1827, rank_id: 0, loss: 0.025400, lr: 0.0000279702, speed: 0.9085 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:12:46,563] [    INFO]\u001B[0m - global step 70700/156300, epoch: 22, batch: 1927, rank_id: 0, loss: 0.044905, lr: 0.0000279375, speed: 0.9085 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:14:35,747] [    INFO]\u001B[0m - global step 70800/156300, epoch: 22, batch: 2027, rank_id: 0, loss: 0.028665, lr: 0.0000279049, speed: 0.9160 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:16:24,680] [    INFO]\u001B[0m - global step 70900/156300, epoch: 22, batch: 2127, rank_id: 0, loss: 0.032725, lr: 0.0000278722, speed: 0.9181 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:18:13,833] [    INFO]\u001B[0m - global step 71000/156300, epoch: 22, batch: 2227, rank_id: 0, loss: 0.022459, lr: 0.0000278396, speed: 0.9163 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:20:03,153] [    INFO]\u001B[0m - global step 71100/156300, epoch: 22, batch: 2327, rank_id: 0, loss: 0.036693, lr: 0.0000278069, speed: 0.9149 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:21:53,345] [    INFO]\u001B[0m - global step 71200/156300, epoch: 22, batch: 2427, rank_id: 0, loss: 0.027282, lr: 0.0000277743, speed: 0.9076 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:23:48,548] [    INFO]\u001B[0m - global step 71300/156300, epoch: 22, batch: 2527, rank_id: 0, loss: 0.036068, lr: 0.0000277417, speed: 0.8682 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:25:45,701] [    INFO]\u001B[0m - global step 71400/156300, epoch: 22, batch: 2627, rank_id: 0, loss: 0.033199, lr: 0.0000277090, speed: 0.8537 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:27:34,249] [    INFO]\u001B[0m - global step 71500/156300, epoch: 22, batch: 2727, rank_id: 0, loss: 0.045674, lr: 0.0000276764, speed: 0.9214 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:29:27,014] [    INFO]\u001B[0m - global step 71600/156300, epoch: 22, batch: 2827, rank_id: 0, loss: 0.021373, lr: 0.0000276437, speed: 0.8869 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:31:15,098] [    INFO]\u001B[0m - global step 71700/156300, epoch: 22, batch: 2927, rank_id: 0, loss: 0.052178, lr: 0.0000276111, speed: 0.9253 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:33:06,568] [    INFO]\u001B[0m - global step 71800/156300, epoch: 22, batch: 3027, rank_id: 0, loss: 0.014868, lr: 0.0000275784, speed: 0.8972 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:34:55,799] [    INFO]\u001B[0m - global step 71900/156300, epoch: 23, batch: 1, rank_id: 0, loss: 0.035961, lr: 0.0000275458, speed: 0.9156 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:36:43,912] [    INFO]\u001B[0m - global step 72000/156300, epoch: 23, batch: 101, rank_id: 0, loss: 0.041253, lr: 0.0000275132, speed: 0.9251 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:38:37,390] [    INFO]\u001B[0m - global step 72100/156300, epoch: 23, batch: 201, rank_id: 0, loss: 0.013312, lr: 0.0000274805, speed: 0.8813 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:40:30,299] [    INFO]\u001B[0m - global step 72200/156300, epoch: 23, batch: 301, rank_id: 0, loss: 0.039498, lr: 0.0000274479, speed: 0.8858 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:42:21,859] [    INFO]\u001B[0m - global step 72300/156300, epoch: 23, batch: 401, rank_id: 0, loss: 0.030287, lr: 0.0000274152, speed: 0.8965 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:44:08,873] [    INFO]\u001B[0m - global step 72400/156300, epoch: 23, batch: 501, rank_id: 0, loss: 0.021661, lr: 0.0000273826, speed: 0.9346 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:45:59,929] [    INFO]\u001B[0m - global step 72500/156300, epoch: 23, batch: 601, rank_id: 0, loss: 0.060228, lr: 0.0000273499, speed: 0.9006 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:47:49,704] [    INFO]\u001B[0m - global step 72600/156300, epoch: 23, batch: 701, rank_id: 0, loss: 0.044483, lr: 0.0000273173, speed: 0.9111 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:49:39,766] [    INFO]\u001B[0m - global step 72700/156300, epoch: 23, batch: 801, rank_id: 0, loss: 0.017974, lr: 0.0000272847, speed: 0.9087 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:51:31,509] [    INFO]\u001B[0m - global step 72800/156300, epoch: 23, batch: 901, rank_id: 0, loss: 0.047044, lr: 0.0000272520, speed: 0.8950 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:53:22,772] [    INFO]\u001B[0m - global step 72900/156300, epoch: 23, batch: 1001, rank_id: 0, loss: 0.040674, lr: 0.0000272194, speed: 0.8989 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:55:13,708] [    INFO]\u001B[0m - global step 73000/156300, epoch: 23, batch: 1101, rank_id: 0, loss: 0.047245, lr: 0.0000271867, speed: 0.9015 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:57:07,450] [    INFO]\u001B[0m - global step 73100/156300, epoch: 23, batch: 1201, rank_id: 0, loss: 0.009233, lr: 0.0000271541, speed: 0.8793 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 20:59:01,692] [    INFO]\u001B[0m - global step 73200/156300, epoch: 23, batch: 1301, rank_id: 0, loss: 0.033607, lr: 0.0000271214, speed: 0.8755 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 21:00:47,535] [    INFO]\u001B[0m - global step 73300/156300, epoch: 23, batch: 1401, rank_id: 0, loss: 0.023214, lr: 0.0000270888, speed: 0.9449 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:02:37,990] [    INFO]\u001B[0m - global step 73400/156300, epoch: 23, batch: 1501, rank_id: 0, loss: 0.038140, lr: 0.0000270562, speed: 0.9055 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:04:25,766] [    INFO]\u001B[0m - global step 73500/156300, epoch: 23, batch: 1601, rank_id: 0, loss: 0.012752, lr: 0.0000270235, speed: 0.9280 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:06:15,854] [    INFO]\u001B[0m - global step 73600/156300, epoch: 23, batch: 1701, rank_id: 0, loss: 0.048165, lr: 0.0000269909, speed: 0.9085 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:08:09,938] [    INFO]\u001B[0m - global step 73700/156300, epoch: 23, batch: 1801, rank_id: 0, loss: 0.024627, lr: 0.0000269582, speed: 0.8767 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:10:02,697] [    INFO]\u001B[0m - global step 73800/156300, epoch: 23, batch: 1901, rank_id: 0, loss: 0.018604, lr: 0.0000269256, speed: 0.8870 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:11:48,527] [    INFO]\u001B[0m - global step 73900/156300, epoch: 23, batch: 2001, rank_id: 0, loss: 0.036008, lr: 0.0000268929, speed: 0.9451 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:13:39,385] [    INFO]\u001B[0m - global step 74000/156300, epoch: 23, batch: 2101, rank_id: 0, loss: 0.037018, lr: 0.0000268603, speed: 0.9022 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:15:26,347] [    INFO]\u001B[0m - global step 74100/156300, epoch: 23, batch: 2201, rank_id: 0, loss: 0.034559, lr: 0.0000268277, speed: 0.9351 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:17:15,656] [    INFO]\u001B[0m - global step 74200/156300, epoch: 23, batch: 2301, rank_id: 0, loss: 0.037006, lr: 0.0000267950, speed: 0.9150 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:19:05,533] [    INFO]\u001B[0m - global step 74300/156300, epoch: 23, batch: 2401, rank_id: 0, loss: 0.046472, lr: 0.0000267624, speed: 0.9102 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:20:59,704] [    INFO]\u001B[0m - global step 74400/156300, epoch: 23, batch: 2501, rank_id: 0, loss: 0.050460, lr: 0.0000267297, speed: 0.8760 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:22:55,541] [    INFO]\u001B[0m - global step 74500/156300, epoch: 23, batch: 2601, rank_id: 0, loss: 0.035787, lr: 0.0000266971, speed: 0.8634 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:24:46,490] [    INFO]\u001B[0m - global step 74600/156300, epoch: 23, batch: 2701, rank_id: 0, loss: 0.034921, lr: 0.0000266644, speed: 0.9014 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:26:37,878] [    INFO]\u001B[0m - global step 74700/156300, epoch: 23, batch: 2801, rank_id: 0, loss: 0.033414, lr: 0.0000266318, speed: 0.8979 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:28:29,380] [    INFO]\u001B[0m - global step 74800/156300, epoch: 23, batch: 2901, rank_id: 0, loss: 0.027753, lr: 0.0000265992, speed: 0.8970 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:30:19,905] [    INFO]\u001B[0m - global step 74900/156300, epoch: 23, batch: 3001, rank_id: 0, loss: 0.023200, lr: 0.0000265665, speed: 0.9049 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:32:09,757] [    INFO]\u001B[0m - global step 75000/156300, epoch: 23, batch: 3101, rank_id: 0, loss: 0.013721, lr: 0.0000265339, speed: 0.9104 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:33:57,829] [    INFO]\u001B[0m - global step 75100/156300, epoch: 24, batch: 75, rank_id: 0, loss: 0.022590, lr: 0.0000265012, speed: 0.9254 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:35:48,969] [    INFO]\u001B[0m - global step 75200/156300, epoch: 24, batch: 175, rank_id: 0, loss: 0.019331, lr: 0.0000264686, speed: 0.8999 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:37:42,646] [    INFO]\u001B[0m - global step 75300/156300, epoch: 24, batch: 275, rank_id: 0, loss: 0.021586, lr: 0.0000264359, speed: 0.8798 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:39:35,472] [    INFO]\u001B[0m - global step 75400/156300, epoch: 24, batch: 375, rank_id: 0, loss: 0.059274, lr: 0.0000264033, speed: 0.8864 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:41:23,622] [    INFO]\u001B[0m - global step 75500/156300, epoch: 24, batch: 475, rank_id: 0, loss: 0.017998, lr: 0.0000263707, speed: 0.9248 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:43:12,279] [    INFO]\u001B[0m - global step 75600/156300, epoch: 24, batch: 575, rank_id: 0, loss: 0.033373, lr: 0.0000263380, speed: 0.9205 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:45:02,267] [    INFO]\u001B[0m - global step 75700/156300, epoch: 24, batch: 675, rank_id: 0, loss: 0.016735, lr: 0.0000263054, speed: 0.9093 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:46:53,995] [    INFO]\u001B[0m - global step 75800/156300, epoch: 24, batch: 775, rank_id: 0, loss: 0.051303, lr: 0.0000262727, speed: 0.8952 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:48:46,873] [    INFO]\u001B[0m - global step 75900/156300, epoch: 24, batch: 875, rank_id: 0, loss: 0.033420, lr: 0.0000262401, speed: 0.8860 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:50:35,308] [    INFO]\u001B[0m - global step 76000/156300, epoch: 24, batch: 975, rank_id: 0, loss: 0.054808, lr: 0.0000262075, speed: 0.9223 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:52:26,063] [    INFO]\u001B[0m - global step 76100/156300, epoch: 24, batch: 1075, rank_id: 0, loss: 0.021101, lr: 0.0000261748, speed: 0.9030 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:54:19,855] [    INFO]\u001B[0m - global step 76200/156300, epoch: 24, batch: 1175, rank_id: 0, loss: 0.009180, lr: 0.0000261422, speed: 0.8789 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:56:13,106] [    INFO]\u001B[0m - global step 76300/156300, epoch: 24, batch: 1275, rank_id: 0, loss: 0.018471, lr: 0.0000261095, speed: 0.8831 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:58:01,576] [    INFO]\u001B[0m - global step 76400/156300, epoch: 24, batch: 1375, rank_id: 0, loss: 0.019472, lr: 0.0000260769, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 21:59:50,623] [    INFO]\u001B[0m - global step 76500/156300, epoch: 24, batch: 1475, rank_id: 0, loss: 0.033669, lr: 0.0000260442, speed: 0.9172 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:01:40,009] [    INFO]\u001B[0m - global step 76600/156300, epoch: 24, batch: 1575, rank_id: 0, loss: 0.027722, lr: 0.0000260116, speed: 0.9143 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:03:29,033] [    INFO]\u001B[0m - global step 76700/156300, epoch: 24, batch: 1675, rank_id: 0, loss: 0.026787, lr: 0.0000259790, speed: 0.9174 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:05:21,515] [    INFO]\u001B[0m - global step 76800/156300, epoch: 24, batch: 1775, rank_id: 0, loss: 0.035037, lr: 0.0000259463, speed: 0.8892 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:07:11,496] [    INFO]\u001B[0m - global step 76900/156300, epoch: 24, batch: 1875, rank_id: 0, loss: 0.045179, lr: 0.0000259137, speed: 0.9094 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:09:03,727] [    INFO]\u001B[0m - global step 77000/156300, epoch: 24, batch: 1975, rank_id: 0, loss: 0.034253, lr: 0.0000258810, speed: 0.8911 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:10:52,554] [    INFO]\u001B[0m - global step 77100/156300, epoch: 24, batch: 2075, rank_id: 0, loss: 0.018817, lr: 0.0000258484, speed: 0.9190 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:12:39,364] [    INFO]\u001B[0m - global step 77200/156300, epoch: 24, batch: 2175, rank_id: 0, loss: 0.027229, lr: 0.0000258157, speed: 0.9364 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:14:30,142] [    INFO]\u001B[0m - global step 77300/156300, epoch: 24, batch: 2275, rank_id: 0, loss: 0.021397, lr: 0.0000257831, speed: 0.9028 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:16:21,245] [    INFO]\u001B[0m - global step 77400/156300, epoch: 24, batch: 2375, rank_id: 0, loss: 0.024265, lr: 0.0000257505, speed: 0.9002 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:18:11,470] [    INFO]\u001B[0m - global step 77500/156300, epoch: 24, batch: 2475, rank_id: 0, loss: 0.018374, lr: 0.0000257178, speed: 0.9074 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:20:05,912] [    INFO]\u001B[0m - global step 77600/156300, epoch: 24, batch: 2575, rank_id: 0, loss: 0.039784, lr: 0.0000256852, speed: 0.8739 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:22:02,337] [    INFO]\u001B[0m - global step 77700/156300, epoch: 24, batch: 2675, rank_id: 0, loss: 0.018339, lr: 0.0000256525, speed: 0.8590 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:23:51,118] [    INFO]\u001B[0m - global step 77800/156300, epoch: 24, batch: 2775, rank_id: 0, loss: 0.022276, lr: 0.0000256199, speed: 0.9194 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:25:42,227] [    INFO]\u001B[0m - global step 77900/156300, epoch: 24, batch: 2875, rank_id: 0, loss: 0.017175, lr: 0.0000255872, speed: 0.9001 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:27:32,528] [    INFO]\u001B[0m - global step 78000/156300, epoch: 24, batch: 2975, rank_id: 0, loss: 0.026974, lr: 0.0000255546, speed: 0.9067 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:29:23,354] [    INFO]\u001B[0m - global step 78100/156300, epoch: 24, batch: 3075, rank_id: 0, loss: 0.046074, lr: 0.0000255220, speed: 0.9024 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-06 22:31:12,024] [    INFO]\u001B[0m - global step 78200/156300, epoch: 25, batch: 49, rank_id: 0, loss: 0.045322, lr: 0.0000254893, speed: 0.9204 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:33:01,413] [    INFO]\u001B[0m - global step 78300/156300, epoch: 25, batch: 149, rank_id: 0, loss: 0.036429, lr: 0.0000254567, speed: 0.9143 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:34:55,949] [    INFO]\u001B[0m - global step 78400/156300, epoch: 25, batch: 249, rank_id: 0, loss: 0.038559, lr: 0.0000254240, speed: 0.8732 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:36:49,588] [    INFO]\u001B[0m - global step 78500/156300, epoch: 25, batch: 349, rank_id: 0, loss: 0.037625, lr: 0.0000253914, speed: 0.8801 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:38:38,595] [    INFO]\u001B[0m - global step 78600/156300, epoch: 25, batch: 449, rank_id: 0, loss: 0.022630, lr: 0.0000253587, speed: 0.9175 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:40:26,541] [    INFO]\u001B[0m - global step 78700/156300, epoch: 25, batch: 549, rank_id: 0, loss: 0.046021, lr: 0.0000253261, speed: 0.9265 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:42:16,952] [    INFO]\u001B[0m - global step 78800/156300, epoch: 25, batch: 649, rank_id: 0, loss: 0.019011, lr: 0.0000252935, speed: 0.9058 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:44:08,452] [    INFO]\u001B[0m - global step 78900/156300, epoch: 25, batch: 749, rank_id: 0, loss: 0.036018, lr: 0.0000252608, speed: 0.8970 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:46:00,295] [    INFO]\u001B[0m - global step 79000/156300, epoch: 25, batch: 849, rank_id: 0, loss: 0.041971, lr: 0.0000252282, speed: 0.8942 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:47:49,784] [    INFO]\u001B[0m - global step 79100/156300, epoch: 25, batch: 949, rank_id: 0, loss: 0.018707, lr: 0.0000251955, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:49:42,211] [    INFO]\u001B[0m - global step 79200/156300, epoch: 25, batch: 1049, rank_id: 0, loss: 0.021037, lr: 0.0000251629, speed: 0.8896 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:51:33,435] [    INFO]\u001B[0m - global step 79300/156300, epoch: 25, batch: 1149, rank_id: 0, loss: 0.021249, lr: 0.0000251302, speed: 0.8992 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:53:27,217] [    INFO]\u001B[0m - global step 79400/156300, epoch: 25, batch: 1249, rank_id: 0, loss: 0.042972, lr: 0.0000250976, speed: 0.8790 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:55:18,333] [    INFO]\u001B[0m - global step 79500/156300, epoch: 25, batch: 1349, rank_id: 0, loss: 0.038391, lr: 0.0000250650, speed: 0.9001 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:57:06,382] [    INFO]\u001B[0m - global step 79600/156300, epoch: 25, batch: 1449, rank_id: 0, loss: 0.028774, lr: 0.0000250323, speed: 0.9256 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 22:58:55,305] [    INFO]\u001B[0m - global step 79700/156300, epoch: 25, batch: 1549, rank_id: 0, loss: 0.029297, lr: 0.0000249997, speed: 0.9182 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:00:45,769] [    INFO]\u001B[0m - global step 79800/156300, epoch: 25, batch: 1649, rank_id: 0, loss: 0.026118, lr: 0.0000249670, speed: 0.9054 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:02:39,031] [    INFO]\u001B[0m - global step 79900/156300, epoch: 25, batch: 1749, rank_id: 0, loss: 0.022063, lr: 0.0000249344, speed: 0.8830 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:04:26,898] [    INFO]\u001B[0m - global step 80000/156300, epoch: 25, batch: 1849, rank_id: 0, loss: 0.011244, lr: 0.0000249017, speed: 0.9272 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:04:37,567] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:04:37,569] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:06:29,649] [    INFO]\u001B[0m - global step 80100/156300, epoch: 25, batch: 1949, rank_id: 0, loss: 0.011096, lr: 0.0000248691, speed: 0.8148 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:08:17,910] [    INFO]\u001B[0m - global step 80200/156300, epoch: 25, batch: 2049, rank_id: 0, loss: 0.015557, lr: 0.0000248365, speed: 0.9238 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:10:05,420] [    INFO]\u001B[0m - global step 80300/156300, epoch: 25, batch: 2149, rank_id: 0, loss: 0.016943, lr: 0.0000248038, speed: 0.9303 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:11:57,776] [    INFO]\u001B[0m - global step 80400/156300, epoch: 25, batch: 2249, rank_id: 0, loss: 0.028562, lr: 0.0000247712, speed: 0.8901 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:13:46,611] [    INFO]\u001B[0m - global step 80500/156300, epoch: 25, batch: 2349, rank_id: 0, loss: 0.056553, lr: 0.0000247385, speed: 0.9190 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:15:37,635] [    INFO]\u001B[0m - global step 80600/156300, epoch: 25, batch: 2449, rank_id: 0, loss: 0.011550, lr: 0.0000247059, speed: 0.9008 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:17:33,196] [    INFO]\u001B[0m - global step 80700/156300, epoch: 25, batch: 2549, rank_id: 0, loss: 0.017863, lr: 0.0000246732, speed: 0.8655 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:19:29,433] [    INFO]\u001B[0m - global step 80800/156300, epoch: 25, batch: 2649, rank_id: 0, loss: 0.028037, lr: 0.0000246406, speed: 0.8604 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:21:17,316] [    INFO]\u001B[0m - global step 80900/156300, epoch: 25, batch: 2749, rank_id: 0, loss: 0.028608, lr: 0.0000246080, speed: 0.9271 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:23:10,353] [    INFO]\u001B[0m - global step 81000/156300, epoch: 25, batch: 2849, rank_id: 0, loss: 0.027169, lr: 0.0000245753, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:24:59,475] [    INFO]\u001B[0m - global step 81100/156300, epoch: 25, batch: 2949, rank_id: 0, loss: 0.039576, lr: 0.0000245427, speed: 0.9165 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:26:49,554] [    INFO]\u001B[0m - global step 81200/156300, epoch: 25, batch: 3049, rank_id: 0, loss: 0.015932, lr: 0.0000245100, speed: 0.9086 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:28:39,035] [    INFO]\u001B[0m - global step 81300/156300, epoch: 26, batch: 23, rank_id: 0, loss: 0.025654, lr: 0.0000244774, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:30:28,768] [    INFO]\u001B[0m - global step 81400/156300, epoch: 26, batch: 123, rank_id: 0, loss: 0.045479, lr: 0.0000244447, speed: 0.9114 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:32:20,685] [    INFO]\u001B[0m - global step 81500/156300, epoch: 26, batch: 223, rank_id: 0, loss: 0.041797, lr: 0.0000244121, speed: 0.8936 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:34:14,905] [    INFO]\u001B[0m - global step 81600/156300, epoch: 26, batch: 323, rank_id: 0, loss: 0.027309, lr: 0.0000243795, speed: 0.8756 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:36:05,059] [    INFO]\u001B[0m - global step 81700/156300, epoch: 26, batch: 423, rank_id: 0, loss: 0.013726, lr: 0.0000243468, speed: 0.9080 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:37:52,908] [    INFO]\u001B[0m - global step 81800/156300, epoch: 26, batch: 523, rank_id: 0, loss: 0.029603, lr: 0.0000243142, speed: 0.9274 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:39:44,306] [    INFO]\u001B[0m - global step 81900/156300, epoch: 26, batch: 623, rank_id: 0, loss: 0.004236, lr: 0.0000242815, speed: 0.8978 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:41:34,625] [    INFO]\u001B[0m - global step 82000/156300, epoch: 26, batch: 723, rank_id: 0, loss: 0.048295, lr: 0.0000242489, speed: 0.9066 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:43:24,901] [    INFO]\u001B[0m - global step 82100/156300, epoch: 26, batch: 823, rank_id: 0, loss: 0.020349, lr: 0.0000242163, speed: 0.9070 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:45:17,939] [    INFO]\u001B[0m - global step 82200/156300, epoch: 26, batch: 923, rank_id: 0, loss: 0.054794, lr: 0.0000241836, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:47:08,207] [    INFO]\u001B[0m - global step 82300/156300, epoch: 26, batch: 1023, rank_id: 0, loss: 0.033366, lr: 0.0000241510, speed: 0.9070 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:48:58,443] [    INFO]\u001B[0m - global step 82400/156300, epoch: 26, batch: 1123, rank_id: 0, loss: 0.021232, lr: 0.0000241183, speed: 0.9073 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:50:51,329] [    INFO]\u001B[0m - global step 82500/156300, epoch: 26, batch: 1223, rank_id: 0, loss: 0.017983, lr: 0.0000240857, speed: 0.8860 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:52:46,603] [    INFO]\u001B[0m - global step 82600/156300, epoch: 26, batch: 1323, rank_id: 0, loss: 0.016177, lr: 0.0000240530, speed: 0.8676 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:54:32,764] [    INFO]\u001B[0m - global step 82700/156300, epoch: 26, batch: 1423, rank_id: 0, loss: 0.009082, lr: 0.0000240204, speed: 0.9421 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:56:23,801] [    INFO]\u001B[0m - global step 82800/156300, epoch: 26, batch: 1523, rank_id: 0, loss: 0.021386, lr: 0.0000239878, speed: 0.9007 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-06 23:58:12,731] [    INFO]\u001B[0m - global step 82900/156300, epoch: 26, batch: 1623, rank_id: 0, loss: 0.036305, lr: 0.0000239551, speed: 0.9182 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 00:00:05,036] [    INFO]\u001B[0m - global step 83000/156300, epoch: 26, batch: 1723, rank_id: 0, loss: 0.034305, lr: 0.0000239225, speed: 0.8906 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:01:55,531] [    INFO]\u001B[0m - global step 83100/156300, epoch: 26, batch: 1823, rank_id: 0, loss: 0.029194, lr: 0.0000238898, speed: 0.9052 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:03:46,071] [    INFO]\u001B[0m - global step 83200/156300, epoch: 26, batch: 1923, rank_id: 0, loss: 0.010506, lr: 0.0000238572, speed: 0.9048 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:05:34,391] [    INFO]\u001B[0m - global step 83300/156300, epoch: 26, batch: 2023, rank_id: 0, loss: 0.012967, lr: 0.0000238245, speed: 0.9233 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:07:24,400] [    INFO]\u001B[0m - global step 83400/156300, epoch: 26, batch: 2123, rank_id: 0, loss: 0.017138, lr: 0.0000237919, speed: 0.9092 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:09:13,580] [    INFO]\u001B[0m - global step 83500/156300, epoch: 26, batch: 2223, rank_id: 0, loss: 0.016297, lr: 0.0000237593, speed: 0.9161 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:11:01,755] [    INFO]\u001B[0m - global step 83600/156300, epoch: 26, batch: 2323, rank_id: 0, loss: 0.026232, lr: 0.0000237266, speed: 0.9246 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:12:53,264] [    INFO]\u001B[0m - global step 83700/156300, epoch: 26, batch: 2423, rank_id: 0, loss: 0.040585, lr: 0.0000236940, speed: 0.8969 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:14:46,773] [    INFO]\u001B[0m - global step 83800/156300, epoch: 26, batch: 2523, rank_id: 0, loss: 0.022733, lr: 0.0000236613, speed: 0.8811 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:16:44,807] [    INFO]\u001B[0m - global step 83900/156300, epoch: 26, batch: 2623, rank_id: 0, loss: 0.023434, lr: 0.0000236287, speed: 0.8473 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:18:33,290] [    INFO]\u001B[0m - global step 84000/156300, epoch: 26, batch: 2723, rank_id: 0, loss: 0.020830, lr: 0.0000235960, speed: 0.9219 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:20:26,832] [    INFO]\u001B[0m - global step 84100/156300, epoch: 26, batch: 2823, rank_id: 0, loss: 0.014376, lr: 0.0000235634, speed: 0.8809 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:22:15,349] [    INFO]\u001B[0m - global step 84200/156300, epoch: 26, batch: 2923, rank_id: 0, loss: 0.019821, lr: 0.0000235308, speed: 0.9216 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:24:07,152] [    INFO]\u001B[0m - global step 84300/156300, epoch: 26, batch: 3023, rank_id: 0, loss: 0.028341, lr: 0.0000234981, speed: 0.8946 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:25:56,459] [    INFO]\u001B[0m - global step 84400/156300, epoch: 26, batch: 3123, rank_id: 0, loss: 0.021571, lr: 0.0000234655, speed: 0.9150 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:27:44,187] [    INFO]\u001B[0m - global step 84500/156300, epoch: 27, batch: 97, rank_id: 0, loss: 0.013823, lr: 0.0000234328, speed: 0.9284 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:29:36,715] [    INFO]\u001B[0m - global step 84600/156300, epoch: 27, batch: 197, rank_id: 0, loss: 0.011191, lr: 0.0000234002, speed: 0.8888 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:31:30,778] [    INFO]\u001B[0m - global step 84700/156300, epoch: 27, batch: 297, rank_id: 0, loss: 0.036765, lr: 0.0000233675, speed: 0.8768 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:33:22,632] [    INFO]\u001B[0m - global step 84800/156300, epoch: 27, batch: 397, rank_id: 0, loss: 0.021654, lr: 0.0000233349, speed: 0.8941 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:35:09,107] [    INFO]\u001B[0m - global step 84900/156300, epoch: 27, batch: 497, rank_id: 0, loss: 0.014471, lr: 0.0000233023, speed: 0.9393 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:36:59,962] [    INFO]\u001B[0m - global step 85000/156300, epoch: 27, batch: 597, rank_id: 0, loss: 0.042484, lr: 0.0000232696, speed: 0.9022 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:38:50,595] [    INFO]\u001B[0m - global step 85100/156300, epoch: 27, batch: 697, rank_id: 0, loss: 0.022171, lr: 0.0000232370, speed: 0.9040 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:40:40,655] [    INFO]\u001B[0m - global step 85200/156300, epoch: 27, batch: 797, rank_id: 0, loss: 0.015817, lr: 0.0000232043, speed: 0.9087 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:42:31,804] [    INFO]\u001B[0m - global step 85300/156300, epoch: 27, batch: 897, rank_id: 0, loss: 0.012912, lr: 0.0000231717, speed: 0.8998 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:44:23,669] [    INFO]\u001B[0m - global step 85400/156300, epoch: 27, batch: 997, rank_id: 0, loss: 0.034895, lr: 0.0000231390, speed: 0.8941 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:46:14,430] [    INFO]\u001B[0m - global step 85500/156300, epoch: 27, batch: 1097, rank_id: 0, loss: 0.016027, lr: 0.0000231064, speed: 0.9030 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:48:08,434] [    INFO]\u001B[0m - global step 85600/156300, epoch: 27, batch: 1197, rank_id: 0, loss: 0.014363, lr: 0.0000230738, speed: 0.8773 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:50:02,554] [    INFO]\u001B[0m - global step 85700/156300, epoch: 27, batch: 1297, rank_id: 0, loss: 0.015289, lr: 0.0000230411, speed: 0.8764 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:51:49,811] [    INFO]\u001B[0m - global step 85800/156300, epoch: 27, batch: 1397, rank_id: 0, loss: 0.017600, lr: 0.0000230085, speed: 0.9325 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:53:39,515] [    INFO]\u001B[0m - global step 85900/156300, epoch: 27, batch: 1497, rank_id: 0, loss: 0.012009, lr: 0.0000229758, speed: 0.9117 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:55:27,000] [    INFO]\u001B[0m - global step 86000/156300, epoch: 27, batch: 1597, rank_id: 0, loss: 0.011715, lr: 0.0000229432, speed: 0.9305 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:57:17,007] [    INFO]\u001B[0m - global step 86100/156300, epoch: 27, batch: 1697, rank_id: 0, loss: 0.017206, lr: 0.0000229105, speed: 0.9092 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 00:59:10,983] [    INFO]\u001B[0m - global step 86200/156300, epoch: 27, batch: 1797, rank_id: 0, loss: 0.030725, lr: 0.0000228779, speed: 0.8775 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:01:03,493] [    INFO]\u001B[0m - global step 86300/156300, epoch: 27, batch: 1897, rank_id: 0, loss: 0.040111, lr: 0.0000228453, speed: 0.8889 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:02:50,167] [    INFO]\u001B[0m - global step 86400/156300, epoch: 27, batch: 1997, rank_id: 0, loss: 0.024763, lr: 0.0000228126, speed: 0.9376 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:04:40,254] [    INFO]\u001B[0m - global step 86500/156300, epoch: 27, batch: 2097, rank_id: 0, loss: 0.033580, lr: 0.0000227800, speed: 0.9085 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:06:27,071] [    INFO]\u001B[0m - global step 86600/156300, epoch: 27, batch: 2197, rank_id: 0, loss: 0.018081, lr: 0.0000227473, speed: 0.9363 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:08:16,471] [    INFO]\u001B[0m - global step 86700/156300, epoch: 27, batch: 2297, rank_id: 0, loss: 0.027861, lr: 0.0000227147, speed: 0.9142 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:10:07,857] [    INFO]\u001B[0m - global step 86800/156300, epoch: 27, batch: 2397, rank_id: 0, loss: 0.008590, lr: 0.0000226820, speed: 0.8979 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:12:01,126] [    INFO]\u001B[0m - global step 86900/156300, epoch: 27, batch: 2497, rank_id: 0, loss: 0.030865, lr: 0.0000226494, speed: 0.8830 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:13:56,740] [    INFO]\u001B[0m - global step 87000/156300, epoch: 27, batch: 2597, rank_id: 0, loss: 0.023668, lr: 0.0000226168, speed: 0.8651 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:15:48,971] [    INFO]\u001B[0m - global step 87100/156300, epoch: 27, batch: 2697, rank_id: 0, loss: 0.012058, lr: 0.0000225841, speed: 0.8912 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:17:39,560] [    INFO]\u001B[0m - global step 87200/156300, epoch: 27, batch: 2797, rank_id: 0, loss: 0.013269, lr: 0.0000225515, speed: 0.9044 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:19:30,985] [    INFO]\u001B[0m - global step 87300/156300, epoch: 27, batch: 2897, rank_id: 0, loss: 0.018212, lr: 0.0000225188, speed: 0.8976 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:21:22,414] [    INFO]\u001B[0m - global step 87400/156300, epoch: 27, batch: 2997, rank_id: 0, loss: 0.026078, lr: 0.0000224862, speed: 0.8976 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:23:11,978] [    INFO]\u001B[0m - global step 87500/156300, epoch: 27, batch: 3097, rank_id: 0, loss: 0.014920, lr: 0.0000224535, speed: 0.9129 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:24:59,691] [    INFO]\u001B[0m - global step 87600/156300, epoch: 28, batch: 71, rank_id: 0, loss: 0.022713, lr: 0.0000224209, speed: 0.9286 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:26:51,637] [    INFO]\u001B[0m - global step 87700/156300, epoch: 28, batch: 171, rank_id: 0, loss: 0.008029, lr: 0.0000223883, speed: 0.8934 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:28:44,537] [    INFO]\u001B[0m - global step 87800/156300, epoch: 28, batch: 271, rank_id: 0, loss: 0.011671, lr: 0.0000223556, speed: 0.8859 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 01:30:37,829] [    INFO]\u001B[0m - global step 87900/156300, epoch: 28, batch: 371, rank_id: 0, loss: 0.027701, lr: 0.0000223230, speed: 0.8828 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:32:26,608] [    INFO]\u001B[0m - global step 88000/156300, epoch: 28, batch: 471, rank_id: 0, loss: 0.020204, lr: 0.0000222903, speed: 0.9194 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:34:15,419] [    INFO]\u001B[0m - global step 88100/156300, epoch: 28, batch: 571, rank_id: 0, loss: 0.010418, lr: 0.0000222577, speed: 0.9192 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:36:04,718] [    INFO]\u001B[0m - global step 88200/156300, epoch: 28, batch: 671, rank_id: 0, loss: 0.005346, lr: 0.0000222251, speed: 0.9151 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:37:56,785] [    INFO]\u001B[0m - global step 88300/156300, epoch: 28, batch: 771, rank_id: 0, loss: 0.032871, lr: 0.0000221924, speed: 0.8925 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:39:48,776] [    INFO]\u001B[0m - global step 88400/156300, epoch: 28, batch: 871, rank_id: 0, loss: 0.010985, lr: 0.0000221598, speed: 0.8931 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:41:38,536] [    INFO]\u001B[0m - global step 88500/156300, epoch: 28, batch: 971, rank_id: 0, loss: 0.015588, lr: 0.0000221271, speed: 0.9112 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:43:28,935] [    INFO]\u001B[0m - global step 88600/156300, epoch: 28, batch: 1071, rank_id: 0, loss: 0.012989, lr: 0.0000220945, speed: 0.9059 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:45:23,093] [    INFO]\u001B[0m - global step 88700/156300, epoch: 28, batch: 1171, rank_id: 0, loss: 0.018747, lr: 0.0000220618, speed: 0.8761 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:47:15,817] [    INFO]\u001B[0m - global step 88800/156300, epoch: 28, batch: 1271, rank_id: 0, loss: 0.012960, lr: 0.0000220292, speed: 0.8872 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:49:04,778] [    INFO]\u001B[0m - global step 88900/156300, epoch: 28, batch: 1371, rank_id: 0, loss: 0.037955, lr: 0.0000219966, speed: 0.9179 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:50:54,195] [    INFO]\u001B[0m - global step 89000/156300, epoch: 28, batch: 1471, rank_id: 0, loss: 0.020398, lr: 0.0000219639, speed: 0.9141 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:52:43,726] [    INFO]\u001B[0m - global step 89100/156300, epoch: 28, batch: 1571, rank_id: 0, loss: 0.008233, lr: 0.0000219313, speed: 0.9131 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:54:32,275] [    INFO]\u001B[0m - global step 89200/156300, epoch: 28, batch: 1671, rank_id: 0, loss: 0.009911, lr: 0.0000218986, speed: 0.9214 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:56:25,564] [    INFO]\u001B[0m - global step 89300/156300, epoch: 28, batch: 1771, rank_id: 0, loss: 0.018431, lr: 0.0000218660, speed: 0.8828 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 01:58:14,897] [    INFO]\u001B[0m - global step 89400/156300, epoch: 28, batch: 1871, rank_id: 0, loss: 0.029610, lr: 0.0000218333, speed: 0.9148 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:00:06,967] [    INFO]\u001B[0m - global step 89500/156300, epoch: 28, batch: 1971, rank_id: 0, loss: 0.024388, lr: 0.0000218007, speed: 0.8924 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:01:55,970] [    INFO]\u001B[0m - global step 89600/156300, epoch: 28, batch: 2071, rank_id: 0, loss: 0.018590, lr: 0.0000217681, speed: 0.9175 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:03:42,266] [    INFO]\u001B[0m - global step 89700/156300, epoch: 28, batch: 2171, rank_id: 0, loss: 0.014224, lr: 0.0000217354, speed: 0.9409 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:05:33,335] [    INFO]\u001B[0m - global step 89800/156300, epoch: 28, batch: 2271, rank_id: 0, loss: 0.010777, lr: 0.0000217028, speed: 0.9005 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:07:24,602] [    INFO]\u001B[0m - global step 89900/156300, epoch: 28, batch: 2371, rank_id: 0, loss: 0.031194, lr: 0.0000216701, speed: 0.8989 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:09:15,253] [    INFO]\u001B[0m - global step 90000/156300, epoch: 28, batch: 2471, rank_id: 0, loss: 0.010579, lr: 0.0000216375, speed: 0.9039 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:11:08,481] [    INFO]\u001B[0m - global step 90100/156300, epoch: 28, batch: 2571, rank_id: 0, loss: 0.012774, lr: 0.0000216048, speed: 0.8833 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:13:06,106] [    INFO]\u001B[0m - global step 90200/156300, epoch: 28, batch: 2671, rank_id: 0, loss: 0.035113, lr: 0.0000215722, speed: 0.8503 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:14:53,650] [    INFO]\u001B[0m - global step 90300/156300, epoch: 28, batch: 2771, rank_id: 0, loss: 0.026167, lr: 0.0000215396, speed: 0.9300 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:16:45,324] [    INFO]\u001B[0m - global step 90400/156300, epoch: 28, batch: 2871, rank_id: 0, loss: 0.006543, lr: 0.0000215069, speed: 0.8956 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:18:36,172] [    INFO]\u001B[0m - global step 90500/156300, epoch: 28, batch: 2971, rank_id: 0, loss: 0.014490, lr: 0.0000214743, speed: 0.9023 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:20:26,572] [    INFO]\u001B[0m - global step 90600/156300, epoch: 28, batch: 3071, rank_id: 0, loss: 0.011647, lr: 0.0000214416, speed: 0.9059 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:22:15,364] [    INFO]\u001B[0m - global step 90700/156300, epoch: 29, batch: 45, rank_id: 0, loss: 0.017515, lr: 0.0000214090, speed: 0.9193 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:24:04,574] [    INFO]\u001B[0m - global step 90800/156300, epoch: 29, batch: 145, rank_id: 0, loss: 0.021342, lr: 0.0000213763, speed: 0.9158 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:25:59,619] [    INFO]\u001B[0m - global step 90900/156300, epoch: 29, batch: 245, rank_id: 0, loss: 0.019241, lr: 0.0000213437, speed: 0.8693 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:27:53,358] [    INFO]\u001B[0m - global step 91000/156300, epoch: 29, batch: 345, rank_id: 0, loss: 0.016256, lr: 0.0000213111, speed: 0.8793 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:29:42,078] [    INFO]\u001B[0m - global step 91100/156300, epoch: 29, batch: 445, rank_id: 0, loss: 0.032173, lr: 0.0000212784, speed: 0.9199 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:31:29,651] [    INFO]\u001B[0m - global step 91200/156300, epoch: 29, batch: 545, rank_id: 0, loss: 0.005593, lr: 0.0000212458, speed: 0.9297 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:33:21,601] [    INFO]\u001B[0m - global step 91300/156300, epoch: 29, batch: 645, rank_id: 0, loss: 0.021393, lr: 0.0000212131, speed: 0.8934 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:35:12,112] [    INFO]\u001B[0m - global step 91400/156300, epoch: 29, batch: 745, rank_id: 0, loss: 0.021662, lr: 0.0000211805, speed: 0.9050 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:37:03,742] [    INFO]\u001B[0m - global step 91500/156300, epoch: 29, batch: 845, rank_id: 0, loss: 0.027110, lr: 0.0000211478, speed: 0.8959 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:38:53,437] [    INFO]\u001B[0m - global step 91600/156300, epoch: 29, batch: 945, rank_id: 0, loss: 0.015013, lr: 0.0000211152, speed: 0.9117 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:40:44,840] [    INFO]\u001B[0m - global step 91700/156300, epoch: 29, batch: 1045, rank_id: 0, loss: 0.004600, lr: 0.0000210826, speed: 0.8978 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:42:36,084] [    INFO]\u001B[0m - global step 91800/156300, epoch: 29, batch: 1145, rank_id: 0, loss: 0.008444, lr: 0.0000210499, speed: 0.8991 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:44:30,245] [    INFO]\u001B[0m - global step 91900/156300, epoch: 29, batch: 1245, rank_id: 0, loss: 0.006501, lr: 0.0000210173, speed: 0.8761 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:46:21,601] [    INFO]\u001B[0m - global step 92000/156300, epoch: 29, batch: 1345, rank_id: 0, loss: 0.024760, lr: 0.0000209846, speed: 0.8982 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:48:10,774] [    INFO]\u001B[0m - global step 92100/156300, epoch: 29, batch: 1445, rank_id: 0, loss: 0.007287, lr: 0.0000209520, speed: 0.9161 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:49:58,888] [    INFO]\u001B[0m - global step 92200/156300, epoch: 29, batch: 1545, rank_id: 0, loss: 0.011718, lr: 0.0000209193, speed: 0.9251 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:51:50,390] [    INFO]\u001B[0m - global step 92300/156300, epoch: 29, batch: 1645, rank_id: 0, loss: 0.026174, lr: 0.0000208867, speed: 0.8970 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:53:43,057] [    INFO]\u001B[0m - global step 92400/156300, epoch: 29, batch: 1745, rank_id: 0, loss: 0.022653, lr: 0.0000208541, speed: 0.8877 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:55:31,504] [    INFO]\u001B[0m - global step 92500/156300, epoch: 29, batch: 1845, rank_id: 0, loss: 0.008013, lr: 0.0000208214, speed: 0.9222 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:57:22,152] [    INFO]\u001B[0m - global step 92600/156300, epoch: 29, batch: 1945, rank_id: 0, loss: 0.023752, lr: 0.0000207888, speed: 0.9039 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 02:59:10,690] [    INFO]\u001B[0m - global step 92700/156300, epoch: 29, batch: 2045, rank_id: 0, loss: 0.015962, lr: 0.0000207561, speed: 0.9215 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 03:00:58,728] [    INFO]\u001B[0m - global step 92800/156300, epoch: 29, batch: 2145, rank_id: 0, loss: 0.010982, lr: 0.0000207235, speed: 0.9257 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:02:51,574] [    INFO]\u001B[0m - global step 92900/156300, epoch: 29, batch: 2245, rank_id: 0, loss: 0.016776, lr: 0.0000206908, speed: 0.8863 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:04:39,601] [    INFO]\u001B[0m - global step 93000/156300, epoch: 29, batch: 2345, rank_id: 0, loss: 0.027785, lr: 0.0000206582, speed: 0.9258 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:06:30,230] [    INFO]\u001B[0m - global step 93100/156300, epoch: 29, batch: 2445, rank_id: 0, loss: 0.005213, lr: 0.0000206256, speed: 0.9041 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:08:26,447] [    INFO]\u001B[0m - global step 93200/156300, epoch: 29, batch: 2545, rank_id: 0, loss: 0.006108, lr: 0.0000205929, speed: 0.8606 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:10:22,396] [    INFO]\u001B[0m - global step 93300/156300, epoch: 29, batch: 2645, rank_id: 0, loss: 0.019217, lr: 0.0000205603, speed: 0.8626 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:12:10,683] [    INFO]\u001B[0m - global step 93400/156300, epoch: 29, batch: 2745, rank_id: 0, loss: 0.022938, lr: 0.0000205276, speed: 0.9236 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:14:03,424] [    INFO]\u001B[0m - global step 93500/156300, epoch: 29, batch: 2845, rank_id: 0, loss: 0.011651, lr: 0.0000204950, speed: 0.8871 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:15:52,647] [    INFO]\u001B[0m - global step 93600/156300, epoch: 29, batch: 2945, rank_id: 0, loss: 0.011144, lr: 0.0000204624, speed: 0.9157 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:17:42,952] [    INFO]\u001B[0m - global step 93700/156300, epoch: 29, batch: 3045, rank_id: 0, loss: 0.011695, lr: 0.0000204297, speed: 0.9067 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:19:32,203] [    INFO]\u001B[0m - global step 93800/156300, epoch: 30, batch: 19, rank_id: 0, loss: 0.006605, lr: 0.0000203971, speed: 0.9155 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:21:22,250] [    INFO]\u001B[0m - global step 93900/156300, epoch: 30, batch: 119, rank_id: 0, loss: 0.021118, lr: 0.0000203644, speed: 0.9088 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:23:14,160] [    INFO]\u001B[0m - global step 94000/156300, epoch: 30, batch: 219, rank_id: 0, loss: 0.021612, lr: 0.0000203318, speed: 0.8937 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:25:07,972] [    INFO]\u001B[0m - global step 94100/156300, epoch: 30, batch: 319, rank_id: 0, loss: 0.010872, lr: 0.0000202991, speed: 0.8788 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:26:57,777] [    INFO]\u001B[0m - global step 94200/156300, epoch: 30, batch: 419, rank_id: 0, loss: 0.012177, lr: 0.0000202665, speed: 0.9108 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:28:45,409] [    INFO]\u001B[0m - global step 94300/156300, epoch: 30, batch: 519, rank_id: 0, loss: 0.019130, lr: 0.0000202339, speed: 0.9292 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:30:37,166] [    INFO]\u001B[0m - global step 94400/156300, epoch: 30, batch: 619, rank_id: 0, loss: 0.015580, lr: 0.0000202012, speed: 0.8949 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:32:27,352] [    INFO]\u001B[0m - global step 94500/156300, epoch: 30, batch: 719, rank_id: 0, loss: 0.019695, lr: 0.0000201686, speed: 0.9077 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:34:17,909] [    INFO]\u001B[0m - global step 94600/156300, epoch: 30, batch: 819, rank_id: 0, loss: 0.011761, lr: 0.0000201359, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:36:10,322] [    INFO]\u001B[0m - global step 94700/156300, epoch: 30, batch: 919, rank_id: 0, loss: 0.014525, lr: 0.0000201033, speed: 0.8897 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:38:01,137] [    INFO]\u001B[0m - global step 94800/156300, epoch: 30, batch: 1019, rank_id: 0, loss: 0.023551, lr: 0.0000200706, speed: 0.9025 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:39:51,915] [    INFO]\u001B[0m - global step 94900/156300, epoch: 30, batch: 1119, rank_id: 0, loss: 0.015090, lr: 0.0000200380, speed: 0.9028 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:41:44,774] [    INFO]\u001B[0m - global step 95000/156300, epoch: 30, batch: 1219, rank_id: 0, loss: 0.012379, lr: 0.0000200054, speed: 0.8862 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:43:39,603] [    INFO]\u001B[0m - global step 95100/156300, epoch: 30, batch: 1319, rank_id: 0, loss: 0.035258, lr: 0.0000199727, speed: 0.8710 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:45:25,264] [    INFO]\u001B[0m - global step 95200/156300, epoch: 30, batch: 1419, rank_id: 0, loss: 0.016455, lr: 0.0000199401, speed: 0.9466 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:47:17,217] [    INFO]\u001B[0m - global step 95300/156300, epoch: 30, batch: 1519, rank_id: 0, loss: 0.003660, lr: 0.0000199074, speed: 0.8934 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:49:04,255] [    INFO]\u001B[0m - global step 95400/156300, epoch: 30, batch: 1619, rank_id: 0, loss: 0.004094, lr: 0.0000198748, speed: 0.9344 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:50:57,608] [    INFO]\u001B[0m - global step 95500/156300, epoch: 30, batch: 1719, rank_id: 0, loss: 0.005802, lr: 0.0000198421, speed: 0.8823 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:52:48,702] [    INFO]\u001B[0m - global step 95600/156300, epoch: 30, batch: 1819, rank_id: 0, loss: 0.017747, lr: 0.0000198095, speed: 0.9003 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:54:40,038] [    INFO]\u001B[0m - global step 95700/156300, epoch: 30, batch: 1919, rank_id: 0, loss: 0.025904, lr: 0.0000197769, speed: 0.8983 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:56:26,989] [    INFO]\u001B[0m - global step 95800/156300, epoch: 30, batch: 2019, rank_id: 0, loss: 0.016357, lr: 0.0000197442, speed: 0.9351 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 03:58:18,161] [    INFO]\u001B[0m - global step 95900/156300, epoch: 30, batch: 2119, rank_id: 0, loss: 0.011302, lr: 0.0000197116, speed: 0.8996 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:00:06,440] [    INFO]\u001B[0m - global step 96000/156300, epoch: 30, batch: 2219, rank_id: 0, loss: 0.020294, lr: 0.0000196789, speed: 0.9237 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:01:55,507] [    INFO]\u001B[0m - global step 96100/156300, epoch: 30, batch: 2319, rank_id: 0, loss: 0.032277, lr: 0.0000196463, speed: 0.9170 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:03:46,039] [    INFO]\u001B[0m - global step 96200/156300, epoch: 30, batch: 2419, rank_id: 0, loss: 0.012328, lr: 0.0000196136, speed: 0.9048 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:05:39,388] [    INFO]\u001B[0m - global step 96300/156300, epoch: 30, batch: 2519, rank_id: 0, loss: 0.022204, lr: 0.0000195810, speed: 0.8824 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:07:37,155] [    INFO]\u001B[0m - global step 96400/156300, epoch: 30, batch: 2619, rank_id: 0, loss: 0.027672, lr: 0.0000195484, speed: 0.8493 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:09:25,775] [    INFO]\u001B[0m - global step 96500/156300, epoch: 30, batch: 2719, rank_id: 0, loss: 0.005938, lr: 0.0000195157, speed: 0.9208 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:11:19,872] [    INFO]\u001B[0m - global step 96600/156300, epoch: 30, batch: 2819, rank_id: 0, loss: 0.019597, lr: 0.0000194831, speed: 0.8766 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:13:08,864] [    INFO]\u001B[0m - global step 96700/156300, epoch: 30, batch: 2919, rank_id: 0, loss: 0.020661, lr: 0.0000194504, speed: 0.9176 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:15:00,531] [    INFO]\u001B[0m - global step 96800/156300, epoch: 30, batch: 3019, rank_id: 0, loss: 0.012499, lr: 0.0000194178, speed: 0.8956 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:16:49,271] [    INFO]\u001B[0m - global step 96900/156300, epoch: 30, batch: 3119, rank_id: 0, loss: 0.015620, lr: 0.0000193851, speed: 0.9198 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:18:38,313] [    INFO]\u001B[0m - global step 97000/156300, epoch: 31, batch: 93, rank_id: 0, loss: 0.007429, lr: 0.0000193525, speed: 0.9172 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:20:29,524] [    INFO]\u001B[0m - global step 97100/156300, epoch: 31, batch: 193, rank_id: 0, loss: 0.006890, lr: 0.0000193199, speed: 0.8993 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:22:24,147] [    INFO]\u001B[0m - global step 97200/156300, epoch: 31, batch: 293, rank_id: 0, loss: 0.012741, lr: 0.0000192872, speed: 0.8725 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:24:14,732] [    INFO]\u001B[0m - global step 97300/156300, epoch: 31, batch: 393, rank_id: 0, loss: 0.017536, lr: 0.0000192546, speed: 0.9044 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:26:02,784] [    INFO]\u001B[0m - global step 97400/156300, epoch: 31, batch: 493, rank_id: 0, loss: 0.016286, lr: 0.0000192219, speed: 0.9256 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:27:53,398] [    INFO]\u001B[0m - global step 97500/156300, epoch: 31, batch: 593, rank_id: 0, loss: 0.015246, lr: 0.0000191893, speed: 0.9042 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:29:43,561] [    INFO]\u001B[0m - global step 97600/156300, epoch: 31, batch: 693, rank_id: 0, loss: 0.039329, lr: 0.0000191566, speed: 0.9079 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 04:31:32,991] [    INFO]\u001B[0m - global step 97700/156300, epoch: 31, batch: 793, rank_id: 0, loss: 0.017108, lr: 0.0000191240, speed: 0.9140 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:33:24,863] [    INFO]\u001B[0m - global step 97800/156300, epoch: 31, batch: 893, rank_id: 0, loss: 0.008381, lr: 0.0000190914, speed: 0.8940 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:35:15,120] [    INFO]\u001B[0m - global step 97900/156300, epoch: 31, batch: 993, rank_id: 0, loss: 0.022333, lr: 0.0000190587, speed: 0.9071 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:37:06,790] [    INFO]\u001B[0m - global step 98000/156300, epoch: 31, batch: 1093, rank_id: 0, loss: 0.033630, lr: 0.0000190261, speed: 0.8956 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:39:00,331] [    INFO]\u001B[0m - global step 98100/156300, epoch: 31, batch: 1193, rank_id: 0, loss: 0.026512, lr: 0.0000189934, speed: 0.8809 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:40:54,390] [    INFO]\u001B[0m - global step 98200/156300, epoch: 31, batch: 1293, rank_id: 0, loss: 0.022911, lr: 0.0000189608, speed: 0.8769 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:42:42,344] [    INFO]\u001B[0m - global step 98300/156300, epoch: 31, batch: 1393, rank_id: 0, loss: 0.016727, lr: 0.0000189281, speed: 0.9265 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:44:31,461] [    INFO]\u001B[0m - global step 98400/156300, epoch: 31, batch: 1493, rank_id: 0, loss: 0.003658, lr: 0.0000188955, speed: 0.9166 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:46:19,171] [    INFO]\u001B[0m - global step 98500/156300, epoch: 31, batch: 1593, rank_id: 0, loss: 0.014210, lr: 0.0000188629, speed: 0.9286 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:48:08,180] [    INFO]\u001B[0m - global step 98600/156300, epoch: 31, batch: 1693, rank_id: 0, loss: 0.009051, lr: 0.0000188302, speed: 0.9175 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:50:03,061] [    INFO]\u001B[0m - global step 98700/156300, epoch: 31, batch: 1793, rank_id: 0, loss: 0.011016, lr: 0.0000187976, speed: 0.8706 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:51:54,715] [    INFO]\u001B[0m - global step 98800/156300, epoch: 31, batch: 1893, rank_id: 0, loss: 0.011320, lr: 0.0000187649, speed: 0.8958 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:53:42,486] [    INFO]\u001B[0m - global step 98900/156300, epoch: 31, batch: 1993, rank_id: 0, loss: 0.010395, lr: 0.0000187323, speed: 0.9280 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:55:32,182] [    INFO]\u001B[0m - global step 99000/156300, epoch: 31, batch: 2093, rank_id: 0, loss: 0.006648, lr: 0.0000186996, speed: 0.9117 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:57:20,051] [    INFO]\u001B[0m - global step 99100/156300, epoch: 31, batch: 2193, rank_id: 0, loss: 0.014991, lr: 0.0000186670, speed: 0.9272 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 04:59:09,368] [    INFO]\u001B[0m - global step 99200/156300, epoch: 31, batch: 2293, rank_id: 0, loss: 0.045675, lr: 0.0000186344, speed: 0.9149 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:01:00,060] [    INFO]\u001B[0m - global step 99300/156300, epoch: 31, batch: 2393, rank_id: 0, loss: 0.005479, lr: 0.0000186017, speed: 0.9035 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:02:52,488] [    INFO]\u001B[0m - global step 99400/156300, epoch: 31, batch: 2493, rank_id: 0, loss: 0.014123, lr: 0.0000185691, speed: 0.8896 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:04:48,752] [    INFO]\u001B[0m - global step 99500/156300, epoch: 31, batch: 2593, rank_id: 0, loss: 0.013666, lr: 0.0000185364, speed: 0.8602 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:06:42,297] [    INFO]\u001B[0m - global step 99600/156300, epoch: 31, batch: 2693, rank_id: 0, loss: 0.008355, lr: 0.0000185038, speed: 0.8808 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:08:31,760] [    INFO]\u001B[0m - global step 99700/156300, epoch: 31, batch: 2793, rank_id: 0, loss: 0.018118, lr: 0.0000184712, speed: 0.9137 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:10:23,694] [    INFO]\u001B[0m - global step 99800/156300, epoch: 31, batch: 2893, rank_id: 0, loss: 0.025904, lr: 0.0000184385, speed: 0.8935 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:12:14,500] [    INFO]\u001B[0m - global step 99900/156300, epoch: 31, batch: 2993, rank_id: 0, loss: 0.012217, lr: 0.0000184059, speed: 0.9026 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:14:03,849] [    INFO]\u001B[0m - global step 100000/156300, epoch: 31, batch: 3093, rank_id: 0, loss: 0.026507, lr: 0.0000183732, speed: 0.9146 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:14:14,787] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:14:14,789] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:16:03,067] [    INFO]\u001B[0m - global step 100100/156300, epoch: 32, batch: 67, rank_id: 0, loss: 0.015955, lr: 0.0000183406, speed: 0.8389 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:17:55,046] [    INFO]\u001B[0m - global step 100200/156300, epoch: 32, batch: 167, rank_id: 0, loss: 0.023138, lr: 0.0000183079, speed: 0.8932 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:19:47,823] [    INFO]\u001B[0m - global step 100300/156300, epoch: 32, batch: 267, rank_id: 0, loss: 0.022718, lr: 0.0000182753, speed: 0.8869 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:21:40,822] [    INFO]\u001B[0m - global step 100400/156300, epoch: 32, batch: 367, rank_id: 0, loss: 0.012642, lr: 0.0000182427, speed: 0.8851 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:23:30,100] [    INFO]\u001B[0m - global step 100500/156300, epoch: 32, batch: 467, rank_id: 0, loss: 0.006772, lr: 0.0000182100, speed: 0.9153 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:25:18,890] [    INFO]\u001B[0m - global step 100600/156300, epoch: 32, batch: 567, rank_id: 0, loss: 0.012670, lr: 0.0000181774, speed: 0.9194 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:27:06,964] [    INFO]\u001B[0m - global step 100700/156300, epoch: 32, batch: 667, rank_id: 0, loss: 0.014013, lr: 0.0000181447, speed: 0.9255 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:28:59,170] [    INFO]\u001B[0m - global step 100800/156300, epoch: 32, batch: 767, rank_id: 0, loss: 0.016332, lr: 0.0000181121, speed: 0.8914 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:30:52,267] [    INFO]\u001B[0m - global step 100900/156300, epoch: 32, batch: 867, rank_id: 0, loss: 0.012879, lr: 0.0000180794, speed: 0.8844 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:32:41,682] [    INFO]\u001B[0m - global step 101000/156300, epoch: 32, batch: 967, rank_id: 0, loss: 0.009823, lr: 0.0000180468, speed: 0.9141 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:34:31,513] [    INFO]\u001B[0m - global step 101100/156300, epoch: 32, batch: 1067, rank_id: 0, loss: 0.011014, lr: 0.0000180142, speed: 0.9107 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:36:25,643] [    INFO]\u001B[0m - global step 101200/156300, epoch: 32, batch: 1167, rank_id: 0, loss: 0.017470, lr: 0.0000179815, speed: 0.8763 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:38:18,571] [    INFO]\u001B[0m - global step 101300/156300, epoch: 32, batch: 1267, rank_id: 0, loss: 0.021949, lr: 0.0000179489, speed: 0.8857 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:40:07,966] [    INFO]\u001B[0m - global step 101400/156300, epoch: 32, batch: 1367, rank_id: 0, loss: 0.029781, lr: 0.0000179162, speed: 0.9143 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:41:57,395] [    INFO]\u001B[0m - global step 101500/156300, epoch: 32, batch: 1467, rank_id: 0, loss: 0.006017, lr: 0.0000178836, speed: 0.9140 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:43:46,304] [    INFO]\u001B[0m - global step 101600/156300, epoch: 32, batch: 1567, rank_id: 0, loss: 0.005367, lr: 0.0000178509, speed: 0.9184 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:45:35,773] [    INFO]\u001B[0m - global step 101700/156300, epoch: 32, batch: 1667, rank_id: 0, loss: 0.011573, lr: 0.0000178183, speed: 0.9137 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:47:28,775] [    INFO]\u001B[0m - global step 101800/156300, epoch: 32, batch: 1767, rank_id: 0, loss: 0.004666, lr: 0.0000177857, speed: 0.8851 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:49:18,184] [    INFO]\u001B[0m - global step 101900/156300, epoch: 32, batch: 1867, rank_id: 0, loss: 0.015545, lr: 0.0000177530, speed: 0.9142 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:51:09,740] [    INFO]\u001B[0m - global step 102000/156300, epoch: 32, batch: 1967, rank_id: 0, loss: 0.021033, lr: 0.0000177204, speed: 0.8966 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:52:58,712] [    INFO]\u001B[0m - global step 102100/156300, epoch: 32, batch: 2067, rank_id: 0, loss: 0.023500, lr: 0.0000176877, speed: 0.9178 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:54:45,345] [    INFO]\u001B[0m - global step 102200/156300, epoch: 32, batch: 2167, rank_id: 0, loss: 0.004587, lr: 0.0000176551, speed: 0.9380 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:56:37,385] [    INFO]\u001B[0m - global step 102300/156300, epoch: 32, batch: 2267, rank_id: 0, loss: 0.022420, lr: 0.0000176224, speed: 0.8927 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 05:58:27,897] [    INFO]\u001B[0m - global step 102400/156300, epoch: 32, batch: 2367, rank_id: 0, loss: 0.027186, lr: 0.0000175898, speed: 0.9050 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 06:00:18,464] [    INFO]\u001B[0m - global step 102500/156300, epoch: 32, batch: 2467, rank_id: 0, loss: 0.010819, lr: 0.0000175572, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:02:12,107] [    INFO]\u001B[0m - global step 102600/156300, epoch: 32, batch: 2567, rank_id: 0, loss: 0.005819, lr: 0.0000175245, speed: 0.8801 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:04:10,011] [    INFO]\u001B[0m - global step 102700/156300, epoch: 32, batch: 2667, rank_id: 0, loss: 0.012177, lr: 0.0000174919, speed: 0.8483 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:05:57,297] [    INFO]\u001B[0m - global step 102800/156300, epoch: 32, batch: 2767, rank_id: 0, loss: 0.003342, lr: 0.0000174592, speed: 0.9323 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:07:49,224] [    INFO]\u001B[0m - global step 102900/156300, epoch: 32, batch: 2867, rank_id: 0, loss: 0.030192, lr: 0.0000174266, speed: 0.8936 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:09:39,946] [    INFO]\u001B[0m - global step 103000/156300, epoch: 32, batch: 2967, rank_id: 0, loss: 0.007391, lr: 0.0000173939, speed: 0.9033 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:11:29,909] [    INFO]\u001B[0m - global step 103100/156300, epoch: 32, batch: 3067, rank_id: 0, loss: 0.007217, lr: 0.0000173613, speed: 0.9096 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:13:18,973] [    INFO]\u001B[0m - global step 103200/156300, epoch: 33, batch: 41, rank_id: 0, loss: 0.005707, lr: 0.0000173287, speed: 0.9171 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:15:07,645] [    INFO]\u001B[0m - global step 103300/156300, epoch: 33, batch: 141, rank_id: 0, loss: 0.004403, lr: 0.0000172960, speed: 0.9204 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:17:02,651] [    INFO]\u001B[0m - global step 103400/156300, epoch: 33, batch: 241, rank_id: 0, loss: 0.008427, lr: 0.0000172634, speed: 0.8697 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:18:56,696] [    INFO]\u001B[0m - global step 103500/156300, epoch: 33, batch: 341, rank_id: 0, loss: 0.012402, lr: 0.0000172307, speed: 0.8770 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:20:45,461] [    INFO]\u001B[0m - global step 103600/156300, epoch: 33, batch: 441, rank_id: 0, loss: 0.031671, lr: 0.0000171981, speed: 0.9196 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:22:33,939] [    INFO]\u001B[0m - global step 103700/156300, epoch: 33, batch: 541, rank_id: 0, loss: 0.005338, lr: 0.0000171654, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:24:25,221] [    INFO]\u001B[0m - global step 103800/156300, epoch: 33, batch: 641, rank_id: 0, loss: 0.021816, lr: 0.0000171328, speed: 0.8988 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:26:15,208] [    INFO]\u001B[0m - global step 103900/156300, epoch: 33, batch: 741, rank_id: 0, loss: 0.014927, lr: 0.0000171002, speed: 0.9094 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:28:06,608] [    INFO]\u001B[0m - global step 104000/156300, epoch: 33, batch: 841, rank_id: 0, loss: 0.018806, lr: 0.0000170675, speed: 0.8978 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:29:57,397] [    INFO]\u001B[0m - global step 104100/156300, epoch: 33, batch: 941, rank_id: 0, loss: 0.018760, lr: 0.0000170349, speed: 0.9028 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:31:47,801] [    INFO]\u001B[0m - global step 104200/156300, epoch: 33, batch: 1041, rank_id: 0, loss: 0.007460, lr: 0.0000170022, speed: 0.9059 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:33:39,476] [    INFO]\u001B[0m - global step 104300/156300, epoch: 33, batch: 1141, rank_id: 0, loss: 0.007072, lr: 0.0000169696, speed: 0.8956 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:35:33,746] [    INFO]\u001B[0m - global step 104400/156300, epoch: 33, batch: 1241, rank_id: 0, loss: 0.014437, lr: 0.0000169369, speed: 0.8753 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:37:26,378] [    INFO]\u001B[0m - global step 104500/156300, epoch: 33, batch: 1341, rank_id: 0, loss: 0.007917, lr: 0.0000169043, speed: 0.8880 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:39:14,469] [    INFO]\u001B[0m - global step 104600/156300, epoch: 33, batch: 1441, rank_id: 0, loss: 0.010796, lr: 0.0000168717, speed: 0.9253 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:41:02,888] [    INFO]\u001B[0m - global step 104700/156300, epoch: 33, batch: 1541, rank_id: 0, loss: 0.016103, lr: 0.0000168390, speed: 0.9225 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:42:54,772] [    INFO]\u001B[0m - global step 104800/156300, epoch: 33, batch: 1641, rank_id: 0, loss: 0.007204, lr: 0.0000168064, speed: 0.8939 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:44:46,377] [    INFO]\u001B[0m - global step 104900/156300, epoch: 33, batch: 1741, rank_id: 0, loss: 0.009968, lr: 0.0000167737, speed: 0.8962 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:46:35,351] [    INFO]\u001B[0m - global step 105000/156300, epoch: 33, batch: 1841, rank_id: 0, loss: 0.018546, lr: 0.0000167411, speed: 0.9178 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:48:26,395] [    INFO]\u001B[0m - global step 105100/156300, epoch: 33, batch: 1941, rank_id: 0, loss: 0.010340, lr: 0.0000167084, speed: 0.9007 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:50:14,772] [    INFO]\u001B[0m - global step 105200/156300, epoch: 33, batch: 2041, rank_id: 0, loss: 0.013925, lr: 0.0000166758, speed: 0.9229 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:52:03,654] [    INFO]\u001B[0m - global step 105300/156300, epoch: 33, batch: 2141, rank_id: 0, loss: 0.006513, lr: 0.0000166432, speed: 0.9186 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:53:55,997] [    INFO]\u001B[0m - global step 105400/156300, epoch: 33, batch: 2241, rank_id: 0, loss: 0.009552, lr: 0.0000166105, speed: 0.8903 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:55:43,385] [    INFO]\u001B[0m - global step 105500/156300, epoch: 33, batch: 2341, rank_id: 0, loss: 0.011212, lr: 0.0000165779, speed: 0.9314 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:57:34,195] [    INFO]\u001B[0m - global step 105600/156300, epoch: 33, batch: 2441, rank_id: 0, loss: 0.016301, lr: 0.0000165452, speed: 0.9026 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 06:59:30,027] [    INFO]\u001B[0m - global step 105700/156300, epoch: 33, batch: 2541, rank_id: 0, loss: 0.019124, lr: 0.0000165126, speed: 0.8635 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:01:26,143] [    INFO]\u001B[0m - global step 105800/156300, epoch: 33, batch: 2641, rank_id: 0, loss: 0.025078, lr: 0.0000164800, speed: 0.8614 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:03:15,054] [    INFO]\u001B[0m - global step 105900/156300, epoch: 33, batch: 2741, rank_id: 0, loss: 0.013302, lr: 0.0000164473, speed: 0.9183 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:05:07,702] [    INFO]\u001B[0m - global step 106000/156300, epoch: 33, batch: 2841, rank_id: 0, loss: 0.015599, lr: 0.0000164147, speed: 0.8879 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:06:57,407] [    INFO]\u001B[0m - global step 106100/156300, epoch: 33, batch: 2941, rank_id: 0, loss: 0.011361, lr: 0.0000163820, speed: 0.9117 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:08:47,449] [    INFO]\u001B[0m - global step 106200/156300, epoch: 33, batch: 3041, rank_id: 0, loss: 0.004877, lr: 0.0000163494, speed: 0.9089 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:10:37,323] [    INFO]\u001B[0m - global step 106300/156300, epoch: 34, batch: 15, rank_id: 0, loss: 0.012346, lr: 0.0000163167, speed: 0.9103 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:12:26,898] [    INFO]\u001B[0m - global step 106400/156300, epoch: 34, batch: 115, rank_id: 0, loss: 0.012145, lr: 0.0000162841, speed: 0.9128 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:14:18,103] [    INFO]\u001B[0m - global step 106500/156300, epoch: 34, batch: 215, rank_id: 0, loss: 0.021218, lr: 0.0000162515, speed: 0.8994 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:16:12,948] [    INFO]\u001B[0m - global step 106600/156300, epoch: 34, batch: 315, rank_id: 0, loss: 0.018084, lr: 0.0000162188, speed: 0.8709 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:18:02,658] [    INFO]\u001B[0m - global step 106700/156300, epoch: 34, batch: 415, rank_id: 0, loss: 0.010204, lr: 0.0000161862, speed: 0.9116 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:19:50,463] [    INFO]\u001B[0m - global step 106800/156300, epoch: 34, batch: 515, rank_id: 0, loss: 0.008830, lr: 0.0000161535, speed: 0.9277 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:21:41,737] [    INFO]\u001B[0m - global step 106900/156300, epoch: 34, batch: 615, rank_id: 0, loss: 0.008802, lr: 0.0000161209, speed: 0.8988 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:23:32,336] [    INFO]\u001B[0m - global step 107000/156300, epoch: 34, batch: 715, rank_id: 0, loss: 0.011759, lr: 0.0000160882, speed: 0.9043 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:25:22,822] [    INFO]\u001B[0m - global step 107100/156300, epoch: 34, batch: 815, rank_id: 0, loss: 0.021289, lr: 0.0000160556, speed: 0.9052 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:27:16,072] [    INFO]\u001B[0m - global step 107200/156300, epoch: 34, batch: 915, rank_id: 0, loss: 0.014763, lr: 0.0000160230, speed: 0.8831 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:29:06,470] [    INFO]\u001B[0m - global step 107300/156300, epoch: 34, batch: 1015, rank_id: 0, loss: 0.007606, lr: 0.0000159903, speed: 0.9059 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 07:30:57,476] [    INFO]\u001B[0m - global step 107400/156300, epoch: 34, batch: 1115, rank_id: 0, loss: 0.009496, lr: 0.0000159577, speed: 0.9010 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:32:50,121] [    INFO]\u001B[0m - global step 107500/156300, epoch: 34, batch: 1215, rank_id: 0, loss: 0.012169, lr: 0.0000159250, speed: 0.8879 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:34:44,677] [    INFO]\u001B[0m - global step 107600/156300, epoch: 34, batch: 1315, rank_id: 0, loss: 0.014613, lr: 0.0000158924, speed: 0.8731 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:36:30,833] [    INFO]\u001B[0m - global step 107700/156300, epoch: 34, batch: 1415, rank_id: 0, loss: 0.012973, lr: 0.0000158597, speed: 0.9421 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:38:22,442] [    INFO]\u001B[0m - global step 107800/156300, epoch: 34, batch: 1515, rank_id: 0, loss: 0.022737, lr: 0.0000158271, speed: 0.8961 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:40:09,433] [    INFO]\u001B[0m - global step 107900/156300, epoch: 34, batch: 1615, rank_id: 0, loss: 0.006715, lr: 0.0000157945, speed: 0.9348 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:42:02,706] [    INFO]\u001B[0m - global step 108000/156300, epoch: 34, batch: 1715, rank_id: 0, loss: 0.008248, lr: 0.0000157618, speed: 0.8829 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:43:53,385] [    INFO]\u001B[0m - global step 108100/156300, epoch: 34, batch: 1815, rank_id: 0, loss: 0.005853, lr: 0.0000157292, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:45:45,004] [    INFO]\u001B[0m - global step 108200/156300, epoch: 34, batch: 1915, rank_id: 0, loss: 0.006602, lr: 0.0000156965, speed: 0.8960 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:47:33,033] [    INFO]\u001B[0m - global step 108300/156300, epoch: 34, batch: 2015, rank_id: 0, loss: 0.023454, lr: 0.0000156639, speed: 0.9258 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:49:22,739] [    INFO]\u001B[0m - global step 108400/156300, epoch: 34, batch: 2115, rank_id: 0, loss: 0.004308, lr: 0.0000156312, speed: 0.9117 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:51:11,205] [    INFO]\u001B[0m - global step 108500/156300, epoch: 34, batch: 2215, rank_id: 0, loss: 0.007720, lr: 0.0000155986, speed: 0.9221 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:53:00,457] [    INFO]\u001B[0m - global step 108600/156300, epoch: 34, batch: 2315, rank_id: 0, loss: 0.013814, lr: 0.0000155660, speed: 0.9154 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:54:51,912] [    INFO]\u001B[0m - global step 108700/156300, epoch: 34, batch: 2415, rank_id: 0, loss: 0.021198, lr: 0.0000155333, speed: 0.8973 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:56:44,235] [    INFO]\u001B[0m - global step 108800/156300, epoch: 34, batch: 2515, rank_id: 0, loss: 0.024013, lr: 0.0000155007, speed: 0.8904 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 07:58:41,971] [    INFO]\u001B[0m - global step 108900/156300, epoch: 34, batch: 2615, rank_id: 0, loss: 0.004270, lr: 0.0000154680, speed: 0.8495 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:00:30,784] [    INFO]\u001B[0m - global step 109000/156300, epoch: 34, batch: 2715, rank_id: 0, loss: 0.006709, lr: 0.0000154354, speed: 0.9191 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:02:24,010] [    INFO]\u001B[0m - global step 109100/156300, epoch: 34, batch: 2815, rank_id: 0, loss: 0.003853, lr: 0.0000154027, speed: 0.8833 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:04:13,683] [    INFO]\u001B[0m - global step 109200/156300, epoch: 34, batch: 2915, rank_id: 0, loss: 0.006642, lr: 0.0000153701, speed: 0.9119 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:06:05,278] [    INFO]\u001B[0m - global step 109300/156300, epoch: 34, batch: 3015, rank_id: 0, loss: 0.010160, lr: 0.0000153375, speed: 0.8962 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:07:53,484] [    INFO]\u001B[0m - global step 109400/156300, epoch: 34, batch: 3115, rank_id: 0, loss: 0.010606, lr: 0.0000153048, speed: 0.9243 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:09:43,503] [    INFO]\u001B[0m - global step 109500/156300, epoch: 35, batch: 89, rank_id: 0, loss: 0.008355, lr: 0.0000152722, speed: 0.9091 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:11:34,969] [    INFO]\u001B[0m - global step 109600/156300, epoch: 35, batch: 189, rank_id: 0, loss: 0.010433, lr: 0.0000152395, speed: 0.8973 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:13:28,991] [    INFO]\u001B[0m - global step 109700/156300, epoch: 35, batch: 289, rank_id: 0, loss: 0.009933, lr: 0.0000152069, speed: 0.8771 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:15:20,043] [    INFO]\u001B[0m - global step 109800/156300, epoch: 35, batch: 389, rank_id: 0, loss: 0.005793, lr: 0.0000151742, speed: 0.9006 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:17:08,110] [    INFO]\u001B[0m - global step 109900/156300, epoch: 35, batch: 489, rank_id: 0, loss: 0.009429, lr: 0.0000151416, speed: 0.9255 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:18:58,923] [    INFO]\u001B[0m - global step 110000/156300, epoch: 35, batch: 589, rank_id: 0, loss: 0.005258, lr: 0.0000151090, speed: 0.9026 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:20:48,408] [    INFO]\u001B[0m - global step 110100/156300, epoch: 35, batch: 689, rank_id: 0, loss: 0.016481, lr: 0.0000150763, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:22:38,269] [    INFO]\u001B[0m - global step 110200/156300, epoch: 35, batch: 789, rank_id: 0, loss: 0.009471, lr: 0.0000150437, speed: 0.9104 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:24:30,870] [    INFO]\u001B[0m - global step 110300/156300, epoch: 35, batch: 889, rank_id: 0, loss: 0.009226, lr: 0.0000150110, speed: 0.8882 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:26:20,623] [    INFO]\u001B[0m - global step 110400/156300, epoch: 35, batch: 989, rank_id: 0, loss: 0.007579, lr: 0.0000149784, speed: 0.9113 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:28:11,392] [    INFO]\u001B[0m - global step 110500/156300, epoch: 35, batch: 1089, rank_id: 0, loss: 0.008789, lr: 0.0000149457, speed: 0.9029 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:30:05,070] [    INFO]\u001B[0m - global step 110600/156300, epoch: 35, batch: 1189, rank_id: 0, loss: 0.018404, lr: 0.0000149131, speed: 0.8798 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:31:59,046] [    INFO]\u001B[0m - global step 110700/156300, epoch: 35, batch: 1289, rank_id: 0, loss: 0.028299, lr: 0.0000148805, speed: 0.8775 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:33:47,786] [    INFO]\u001B[0m - global step 110800/156300, epoch: 35, batch: 1389, rank_id: 0, loss: 0.023420, lr: 0.0000148478, speed: 0.9198 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:35:36,621] [    INFO]\u001B[0m - global step 110900/156300, epoch: 35, batch: 1489, rank_id: 0, loss: 0.005351, lr: 0.0000148152, speed: 0.9190 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:37:24,098] [    INFO]\u001B[0m - global step 111000/156300, epoch: 35, batch: 1589, rank_id: 0, loss: 0.007330, lr: 0.0000147825, speed: 0.9306 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:39:13,787] [    INFO]\u001B[0m - global step 111100/156300, epoch: 35, batch: 1689, rank_id: 0, loss: 0.010910, lr: 0.0000147499, speed: 0.9118 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:41:08,285] [    INFO]\u001B[0m - global step 111200/156300, epoch: 35, batch: 1789, rank_id: 0, loss: 0.002034, lr: 0.0000147172, speed: 0.8735 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:42:59,866] [    INFO]\u001B[0m - global step 111300/156300, epoch: 35, batch: 1889, rank_id: 0, loss: 0.007846, lr: 0.0000146846, speed: 0.8963 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:44:48,779] [    INFO]\u001B[0m - global step 111400/156300, epoch: 35, batch: 1989, rank_id: 0, loss: 0.020851, lr: 0.0000146520, speed: 0.9183 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:46:37,851] [    INFO]\u001B[0m - global step 111500/156300, epoch: 35, batch: 2089, rank_id: 0, loss: 0.004969, lr: 0.0000146193, speed: 0.9170 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:48:25,894] [    INFO]\u001B[0m - global step 111600/156300, epoch: 35, batch: 2189, rank_id: 0, loss: 0.008465, lr: 0.0000145867, speed: 0.9257 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:50:16,327] [    INFO]\u001B[0m - global step 111700/156300, epoch: 35, batch: 2289, rank_id: 0, loss: 0.007248, lr: 0.0000145540, speed: 0.9057 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:52:06,540] [    INFO]\u001B[0m - global step 111800/156300, epoch: 35, batch: 2389, rank_id: 0, loss: 0.007135, lr: 0.0000145214, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:53:58,286] [    INFO]\u001B[0m - global step 111900/156300, epoch: 35, batch: 2489, rank_id: 0, loss: 0.005654, lr: 0.0000144888, speed: 0.8950 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:55:53,889] [    INFO]\u001B[0m - global step 112000/156300, epoch: 35, batch: 2589, rank_id: 0, loss: 0.012587, lr: 0.0000144561, speed: 0.8652 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:57:48,860] [    INFO]\u001B[0m - global step 112100/156300, epoch: 35, batch: 2689, rank_id: 0, loss: 0.013332, lr: 0.0000144235, speed: 0.8699 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 08:59:38,101] [    INFO]\u001B[0m - global step 112200/156300, epoch: 35, batch: 2789, rank_id: 0, loss: 0.005094, lr: 0.0000143908, speed: 0.9155 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 09:01:28,754] [    INFO]\u001B[0m - global step 112300/156300, epoch: 35, batch: 2889, rank_id: 0, loss: 0.007022, lr: 0.0000143582, speed: 0.9039 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:03:20,580] [    INFO]\u001B[0m - global step 112400/156300, epoch: 35, batch: 2989, rank_id: 0, loss: 0.008550, lr: 0.0000143255, speed: 0.8944 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:05:09,355] [    INFO]\u001B[0m - global step 112500/156300, epoch: 35, batch: 3089, rank_id: 0, loss: 0.003078, lr: 0.0000142929, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:06:58,118] [    INFO]\u001B[0m - global step 112600/156300, epoch: 36, batch: 63, rank_id: 0, loss: 0.006590, lr: 0.0000142603, speed: 0.9196 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:08:50,317] [    INFO]\u001B[0m - global step 112700/156300, epoch: 36, batch: 163, rank_id: 0, loss: 0.007702, lr: 0.0000142276, speed: 0.8914 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:10:42,738] [    INFO]\u001B[0m - global step 112800/156300, epoch: 36, batch: 263, rank_id: 0, loss: 0.012748, lr: 0.0000141950, speed: 0.8896 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:12:36,524] [    INFO]\u001B[0m - global step 112900/156300, epoch: 36, batch: 363, rank_id: 0, loss: 0.016587, lr: 0.0000141623, speed: 0.8790 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:14:25,917] [    INFO]\u001B[0m - global step 113000/156300, epoch: 36, batch: 463, rank_id: 0, loss: 0.006718, lr: 0.0000141297, speed: 0.9143 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:16:13,737] [    INFO]\u001B[0m - global step 113100/156300, epoch: 36, batch: 563, rank_id: 0, loss: 0.010625, lr: 0.0000140970, speed: 0.9276 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:18:02,599] [    INFO]\u001B[0m - global step 113200/156300, epoch: 36, batch: 663, rank_id: 0, loss: 0.008365, lr: 0.0000140644, speed: 0.9187 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:19:54,286] [    INFO]\u001B[0m - global step 113300/156300, epoch: 36, batch: 763, rank_id: 0, loss: 0.004907, lr: 0.0000140318, speed: 0.8955 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:21:46,892] [    INFO]\u001B[0m - global step 113400/156300, epoch: 36, batch: 863, rank_id: 0, loss: 0.011845, lr: 0.0000139991, speed: 0.8882 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:23:37,071] [    INFO]\u001B[0m - global step 113500/156300, epoch: 36, batch: 963, rank_id: 0, loss: 0.008255, lr: 0.0000139665, speed: 0.9077 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:25:27,549] [    INFO]\u001B[0m - global step 113600/156300, epoch: 36, batch: 1063, rank_id: 0, loss: 0.012713, lr: 0.0000139338, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:27:20,915] [    INFO]\u001B[0m - global step 113700/156300, epoch: 36, batch: 1163, rank_id: 0, loss: 0.014894, lr: 0.0000139012, speed: 0.8822 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:29:14,387] [    INFO]\u001B[0m - global step 113800/156300, epoch: 36, batch: 1263, rank_id: 0, loss: 0.012237, lr: 0.0000138685, speed: 0.8814 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:31:04,424] [    INFO]\u001B[0m - global step 113900/156300, epoch: 36, batch: 1363, rank_id: 0, loss: 0.008922, lr: 0.0000138359, speed: 0.9089 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:32:53,484] [    INFO]\u001B[0m - global step 114000/156300, epoch: 36, batch: 1463, rank_id: 0, loss: 0.015086, lr: 0.0000138033, speed: 0.9171 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:34:41,871] [    INFO]\u001B[0m - global step 114100/156300, epoch: 36, batch: 1563, rank_id: 0, loss: 0.005699, lr: 0.0000137706, speed: 0.9228 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:36:32,079] [    INFO]\u001B[0m - global step 114200/156300, epoch: 36, batch: 1663, rank_id: 0, loss: 0.007851, lr: 0.0000137380, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:38:24,636] [    INFO]\u001B[0m - global step 114300/156300, epoch: 36, batch: 1763, rank_id: 0, loss: 0.014219, lr: 0.0000137053, speed: 0.8886 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:40:14,350] [    INFO]\u001B[0m - global step 114400/156300, epoch: 36, batch: 1863, rank_id: 0, loss: 0.007926, lr: 0.0000136727, speed: 0.9116 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:42:05,290] [    INFO]\u001B[0m - global step 114500/156300, epoch: 36, batch: 1963, rank_id: 0, loss: 0.009825, lr: 0.0000136400, speed: 0.9015 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:43:54,311] [    INFO]\u001B[0m - global step 114600/156300, epoch: 36, batch: 2063, rank_id: 0, loss: 0.011477, lr: 0.0000136074, speed: 0.9174 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:45:41,801] [    INFO]\u001B[0m - global step 114700/156300, epoch: 36, batch: 2163, rank_id: 0, loss: 0.004423, lr: 0.0000135748, speed: 0.9305 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:47:32,976] [    INFO]\u001B[0m - global step 114800/156300, epoch: 36, batch: 2263, rank_id: 0, loss: 0.014815, lr: 0.0000135421, speed: 0.8996 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:49:23,272] [    INFO]\u001B[0m - global step 114900/156300, epoch: 36, batch: 2363, rank_id: 0, loss: 0.012571, lr: 0.0000135095, speed: 0.9068 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:51:15,319] [    INFO]\u001B[0m - global step 115000/156300, epoch: 36, batch: 2463, rank_id: 0, loss: 0.009638, lr: 0.0000134768, speed: 0.8926 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:53:08,350] [    INFO]\u001B[0m - global step 115100/156300, epoch: 36, batch: 2563, rank_id: 0, loss: 0.005797, lr: 0.0000134442, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:55:06,388] [    INFO]\u001B[0m - global step 115200/156300, epoch: 36, batch: 2663, rank_id: 0, loss: 0.005350, lr: 0.0000134115, speed: 0.8473 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:56:53,341] [    INFO]\u001B[0m - global step 115300/156300, epoch: 36, batch: 2763, rank_id: 0, loss: 0.009454, lr: 0.0000133789, speed: 0.9351 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 09:58:45,391] [    INFO]\u001B[0m - global step 115400/156300, epoch: 36, batch: 2863, rank_id: 0, loss: 0.012023, lr: 0.0000133463, speed: 0.8926 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:00:36,890] [    INFO]\u001B[0m - global step 115500/156300, epoch: 36, batch: 2963, rank_id: 0, loss: 0.006583, lr: 0.0000133136, speed: 0.8970 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:02:24,767] [    INFO]\u001B[0m - global step 115600/156300, epoch: 36, batch: 3063, rank_id: 0, loss: 0.008624, lr: 0.0000132810, speed: 0.9271 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:04:14,736] [    INFO]\u001B[0m - global step 115700/156300, epoch: 37, batch: 37, rank_id: 0, loss: 0.008839, lr: 0.0000132483, speed: 0.9095 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:06:04,103] [    INFO]\u001B[0m - global step 115800/156300, epoch: 37, batch: 137, rank_id: 0, loss: 0.007211, lr: 0.0000132157, speed: 0.9145 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:07:57,294] [    INFO]\u001B[0m - global step 115900/156300, epoch: 37, batch: 237, rank_id: 0, loss: 0.010827, lr: 0.0000131830, speed: 0.8836 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:09:51,970] [    INFO]\u001B[0m - global step 116000/156300, epoch: 37, batch: 337, rank_id: 0, loss: 0.018873, lr: 0.0000131504, speed: 0.8721 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:11:40,217] [    INFO]\u001B[0m - global step 116100/156300, epoch: 37, batch: 437, rank_id: 0, loss: 0.005468, lr: 0.0000131178, speed: 0.9239 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:13:29,003] [    INFO]\u001B[0m - global step 116200/156300, epoch: 37, batch: 537, rank_id: 0, loss: 0.004631, lr: 0.0000130851, speed: 0.9194 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:15:19,640] [    INFO]\u001B[0m - global step 116300/156300, epoch: 37, batch: 637, rank_id: 0, loss: 0.017787, lr: 0.0000130525, speed: 0.9040 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:17:10,742] [    INFO]\u001B[0m - global step 116400/156300, epoch: 37, batch: 737, rank_id: 0, loss: 0.005872, lr: 0.0000130198, speed: 0.9002 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:19:00,674] [    INFO]\u001B[0m - global step 116500/156300, epoch: 37, batch: 837, rank_id: 0, loss: 0.010958, lr: 0.0000129872, speed: 0.9098 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:20:52,811] [    INFO]\u001B[0m - global step 116600/156300, epoch: 37, batch: 937, rank_id: 0, loss: 0.002333, lr: 0.0000129545, speed: 0.8919 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:22:42,812] [    INFO]\u001B[0m - global step 116700/156300, epoch: 37, batch: 1037, rank_id: 0, loss: 0.015309, lr: 0.0000129219, speed: 0.9092 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:24:34,297] [    INFO]\u001B[0m - global step 116800/156300, epoch: 37, batch: 1137, rank_id: 0, loss: 0.017470, lr: 0.0000128893, speed: 0.8971 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:26:28,297] [    INFO]\u001B[0m - global step 116900/156300, epoch: 37, batch: 1237, rank_id: 0, loss: 0.006220, lr: 0.0000128566, speed: 0.8773 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:28:21,257] [    INFO]\u001B[0m - global step 117000/156300, epoch: 37, batch: 1337, rank_id: 0, loss: 0.006657, lr: 0.0000128240, speed: 0.8854 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:30:08,623] [    INFO]\u001B[0m - global step 117100/156300, epoch: 37, batch: 1437, rank_id: 0, loss: 0.006662, lr: 0.0000127913, speed: 0.9315 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 10:31:58,824] [    INFO]\u001B[0m - global step 117200/156300, epoch: 37, batch: 1537, rank_id: 0, loss: 0.010151, lr: 0.0000127587, speed: 0.9076 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:33:49,121] [    INFO]\u001B[0m - global step 117300/156300, epoch: 37, batch: 1637, rank_id: 0, loss: 0.003976, lr: 0.0000127261, speed: 0.9068 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:35:40,895] [    INFO]\u001B[0m - global step 117400/156300, epoch: 37, batch: 1737, rank_id: 0, loss: 0.009079, lr: 0.0000126934, speed: 0.8948 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:37:30,455] [    INFO]\u001B[0m - global step 117500/156300, epoch: 37, batch: 1837, rank_id: 0, loss: 0.007959, lr: 0.0000126608, speed: 0.9129 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:39:21,423] [    INFO]\u001B[0m - global step 117600/156300, epoch: 37, batch: 1937, rank_id: 0, loss: 0.010683, lr: 0.0000126281, speed: 0.9013 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:41:08,849] [    INFO]\u001B[0m - global step 117700/156300, epoch: 37, batch: 2037, rank_id: 0, loss: 0.004533, lr: 0.0000125955, speed: 0.9310 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:42:58,770] [    INFO]\u001B[0m - global step 117800/156300, epoch: 37, batch: 2137, rank_id: 0, loss: 0.006010, lr: 0.0000125628, speed: 0.9099 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:44:49,690] [    INFO]\u001B[0m - global step 117900/156300, epoch: 37, batch: 2237, rank_id: 0, loss: 0.024458, lr: 0.0000125302, speed: 0.9017 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:46:37,762] [    INFO]\u001B[0m - global step 118000/156300, epoch: 37, batch: 2337, rank_id: 0, loss: 0.004861, lr: 0.0000124976, speed: 0.9254 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:48:27,824] [    INFO]\u001B[0m - global step 118100/156300, epoch: 37, batch: 2437, rank_id: 0, loss: 0.007085, lr: 0.0000124649, speed: 0.9087 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:50:25,497] [    INFO]\u001B[0m - global step 118200/156300, epoch: 37, batch: 2537, rank_id: 0, loss: 0.002149, lr: 0.0000124323, speed: 0.8499 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:52:20,637] [    INFO]\u001B[0m - global step 118300/156300, epoch: 37, batch: 2637, rank_id: 0, loss: 0.012318, lr: 0.0000123996, speed: 0.8686 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:54:09,385] [    INFO]\u001B[0m - global step 118400/156300, epoch: 37, batch: 2737, rank_id: 0, loss: 0.003671, lr: 0.0000123670, speed: 0.9197 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:56:03,057] [    INFO]\u001B[0m - global step 118500/156300, epoch: 37, batch: 2837, rank_id: 0, loss: 0.017239, lr: 0.0000123343, speed: 0.8798 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:57:51,541] [    INFO]\u001B[0m - global step 118600/156300, epoch: 37, batch: 2937, rank_id: 0, loss: 0.007936, lr: 0.0000123017, speed: 0.9219 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 10:59:41,495] [    INFO]\u001B[0m - global step 118700/156300, epoch: 37, batch: 3037, rank_id: 0, loss: 0.005163, lr: 0.0000122691, speed: 0.9096 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:01:31,988] [    INFO]\u001B[0m - global step 118800/156300, epoch: 38, batch: 11, rank_id: 0, loss: 0.012716, lr: 0.0000122364, speed: 0.9052 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:03:20,805] [    INFO]\u001B[0m - global step 118900/156300, epoch: 38, batch: 111, rank_id: 0, loss: 0.005284, lr: 0.0000122038, speed: 0.9191 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:05:13,003] [    INFO]\u001B[0m - global step 119000/156300, epoch: 38, batch: 211, rank_id: 0, loss: 0.005195, lr: 0.0000121711, speed: 0.8914 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:07:07,432] [    INFO]\u001B[0m - global step 119100/156300, epoch: 38, batch: 311, rank_id: 0, loss: 0.007413, lr: 0.0000121385, speed: 0.8740 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:08:57,501] [    INFO]\u001B[0m - global step 119200/156300, epoch: 38, batch: 411, rank_id: 0, loss: 0.002213, lr: 0.0000121058, speed: 0.9087 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:10:45,975] [    INFO]\u001B[0m - global step 119300/156300, epoch: 38, batch: 511, rank_id: 0, loss: 0.012798, lr: 0.0000120732, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:12:36,266] [    INFO]\u001B[0m - global step 119400/156300, epoch: 38, batch: 611, rank_id: 0, loss: 0.013303, lr: 0.0000120406, speed: 0.9068 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:14:26,258] [    INFO]\u001B[0m - global step 119500/156300, epoch: 38, batch: 711, rank_id: 0, loss: 0.004069, lr: 0.0000120079, speed: 0.9093 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:16:16,950] [    INFO]\u001B[0m - global step 119600/156300, epoch: 38, batch: 811, rank_id: 0, loss: 0.011851, lr: 0.0000119753, speed: 0.9035 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:18:10,491] [    INFO]\u001B[0m - global step 119700/156300, epoch: 38, batch: 911, rank_id: 0, loss: 0.006091, lr: 0.0000119426, speed: 0.8809 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:20:01,117] [    INFO]\u001B[0m - global step 119800/156300, epoch: 38, batch: 1011, rank_id: 0, loss: 0.005195, lr: 0.0000119100, speed: 0.9041 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:21:51,815] [    INFO]\u001B[0m - global step 119900/156300, epoch: 38, batch: 1111, rank_id: 0, loss: 0.008250, lr: 0.0000118773, speed: 0.9035 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:23:44,674] [    INFO]\u001B[0m - global step 120000/156300, epoch: 38, batch: 1211, rank_id: 0, loss: 0.005689, lr: 0.0000118447, speed: 0.8862 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:23:55,363] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:23:55,365] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:25:49,578] [    INFO]\u001B[0m - global step 120100/156300, epoch: 38, batch: 1311, rank_id: 0, loss: 0.007264, lr: 0.0000118121, speed: 0.8007 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:27:35,277] [    INFO]\u001B[0m - global step 120200/156300, epoch: 38, batch: 1411, rank_id: 0, loss: 0.002515, lr: 0.0000117794, speed: 0.9462 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:29:26,504] [    INFO]\u001B[0m - global step 120300/156300, epoch: 38, batch: 1511, rank_id: 0, loss: 0.004794, lr: 0.0000117468, speed: 0.8992 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:31:14,225] [    INFO]\u001B[0m - global step 120400/156300, epoch: 38, batch: 1611, rank_id: 0, loss: 0.006276, lr: 0.0000117141, speed: 0.9285 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:33:07,285] [    INFO]\u001B[0m - global step 120500/156300, epoch: 38, batch: 1711, rank_id: 0, loss: 0.003093, lr: 0.0000116815, speed: 0.8846 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:34:57,757] [    INFO]\u001B[0m - global step 120600/156300, epoch: 38, batch: 1811, rank_id: 0, loss: 0.004263, lr: 0.0000116488, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:36:50,642] [    INFO]\u001B[0m - global step 120700/156300, epoch: 38, batch: 1911, rank_id: 0, loss: 0.005221, lr: 0.0000116162, speed: 0.8860 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:38:37,693] [    INFO]\u001B[0m - global step 120800/156300, epoch: 38, batch: 2011, rank_id: 0, loss: 0.010197, lr: 0.0000115836, speed: 0.9343 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:40:27,441] [    INFO]\u001B[0m - global step 120900/156300, epoch: 38, batch: 2111, rank_id: 0, loss: 0.004804, lr: 0.0000115509, speed: 0.9113 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:42:16,636] [    INFO]\u001B[0m - global step 121000/156300, epoch: 38, batch: 2211, rank_id: 0, loss: 0.005079, lr: 0.0000115183, speed: 0.9159 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:44:04,209] [    INFO]\u001B[0m - global step 121100/156300, epoch: 38, batch: 2311, rank_id: 0, loss: 0.006990, lr: 0.0000114856, speed: 0.9297 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:45:55,971] [    INFO]\u001B[0m - global step 121200/156300, epoch: 38, batch: 2411, rank_id: 0, loss: 0.002650, lr: 0.0000114530, speed: 0.8949 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:47:49,013] [    INFO]\u001B[0m - global step 121300/156300, epoch: 38, batch: 2511, rank_id: 0, loss: 0.005897, lr: 0.0000114203, speed: 0.8848 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:49:46,528] [    INFO]\u001B[0m - global step 121400/156300, epoch: 38, batch: 2611, rank_id: 0, loss: 0.002839, lr: 0.0000113877, speed: 0.8511 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:51:36,091] [    INFO]\u001B[0m - global step 121500/156300, epoch: 38, batch: 2711, rank_id: 0, loss: 0.008829, lr: 0.0000113551, speed: 0.9129 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:53:28,763] [    INFO]\u001B[0m - global step 121600/156300, epoch: 38, batch: 2811, rank_id: 0, loss: 0.004952, lr: 0.0000113224, speed: 0.8877 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:55:18,176] [    INFO]\u001B[0m - global step 121700/156300, epoch: 38, batch: 2911, rank_id: 0, loss: 0.013885, lr: 0.0000112898, speed: 0.9141 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 11:57:10,349] [    INFO]\u001B[0m - global step 121800/156300, epoch: 38, batch: 3011, rank_id: 0, loss: 0.003788, lr: 0.0000112571, speed: 0.8916 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 11:58:58,843] [    INFO]\u001B[0m - global step 121900/156300, epoch: 38, batch: 3111, rank_id: 0, loss: 0.014688, lr: 0.0000112245, speed: 0.9218 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:00:49,183] [    INFO]\u001B[0m - global step 122000/156300, epoch: 39, batch: 85, rank_id: 0, loss: 0.001539, lr: 0.0000111918, speed: 0.9064 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:02:40,097] [    INFO]\u001B[0m - global step 122100/156300, epoch: 39, batch: 185, rank_id: 0, loss: 0.007541, lr: 0.0000111592, speed: 0.9017 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:04:34,896] [    INFO]\u001B[0m - global step 122200/156300, epoch: 39, batch: 285, rank_id: 0, loss: 0.008714, lr: 0.0000111266, speed: 0.8712 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:06:26,221] [    INFO]\u001B[0m - global step 122300/156300, epoch: 39, batch: 385, rank_id: 0, loss: 0.004104, lr: 0.0000110939, speed: 0.8984 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:08:13,648] [    INFO]\u001B[0m - global step 122400/156300, epoch: 39, batch: 485, rank_id: 0, loss: 0.013214, lr: 0.0000110613, speed: 0.9310 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:10:04,329] [    INFO]\u001B[0m - global step 122500/156300, epoch: 39, batch: 585, rank_id: 0, loss: 0.012084, lr: 0.0000110286, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:11:53,131] [    INFO]\u001B[0m - global step 122600/156300, epoch: 39, batch: 685, rank_id: 0, loss: 0.004972, lr: 0.0000109960, speed: 0.9192 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:13:43,763] [    INFO]\u001B[0m - global step 122700/156300, epoch: 39, batch: 785, rank_id: 0, loss: 0.005377, lr: 0.0000109633, speed: 0.9040 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:15:36,397] [    INFO]\u001B[0m - global step 122800/156300, epoch: 39, batch: 885, rank_id: 0, loss: 0.004573, lr: 0.0000109307, speed: 0.8880 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:17:26,079] [    INFO]\u001B[0m - global step 122900/156300, epoch: 39, batch: 985, rank_id: 0, loss: 0.005431, lr: 0.0000108981, speed: 0.9119 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:19:15,991] [    INFO]\u001B[0m - global step 123000/156300, epoch: 39, batch: 1085, rank_id: 0, loss: 0.009410, lr: 0.0000108654, speed: 0.9099 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:21:10,318] [    INFO]\u001B[0m - global step 123100/156300, epoch: 39, batch: 1185, rank_id: 0, loss: 0.015355, lr: 0.0000108328, speed: 0.8748 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:23:04,527] [    INFO]\u001B[0m - global step 123200/156300, epoch: 39, batch: 1285, rank_id: 0, loss: 0.006943, lr: 0.0000108001, speed: 0.8757 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:24:52,781] [    INFO]\u001B[0m - global step 123300/156300, epoch: 39, batch: 1385, rank_id: 0, loss: 0.002344, lr: 0.0000107675, speed: 0.9239 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:26:42,211] [    INFO]\u001B[0m - global step 123400/156300, epoch: 39, batch: 1485, rank_id: 0, loss: 0.002553, lr: 0.0000107349, speed: 0.9140 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:28:30,394] [    INFO]\u001B[0m - global step 123500/156300, epoch: 39, batch: 1585, rank_id: 0, loss: 0.004825, lr: 0.0000107022, speed: 0.9245 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:30:19,575] [    INFO]\u001B[0m - global step 123600/156300, epoch: 39, batch: 1685, rank_id: 0, loss: 0.002728, lr: 0.0000106696, speed: 0.9160 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:32:13,603] [    INFO]\u001B[0m - global step 123700/156300, epoch: 39, batch: 1785, rank_id: 0, loss: 0.005528, lr: 0.0000106369, speed: 0.8771 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:34:04,931] [    INFO]\u001B[0m - global step 123800/156300, epoch: 39, batch: 1885, rank_id: 0, loss: 0.003498, lr: 0.0000106043, speed: 0.8984 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:35:54,823] [    INFO]\u001B[0m - global step 123900/156300, epoch: 39, batch: 1985, rank_id: 0, loss: 0.003889, lr: 0.0000105716, speed: 0.9101 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:37:44,005] [    INFO]\u001B[0m - global step 124000/156300, epoch: 39, batch: 2085, rank_id: 0, loss: 0.010129, lr: 0.0000105390, speed: 0.9161 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:39:32,358] [    INFO]\u001B[0m - global step 124100/156300, epoch: 39, batch: 2185, rank_id: 0, loss: 0.002826, lr: 0.0000105064, speed: 0.9231 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:41:22,945] [    INFO]\u001B[0m - global step 124200/156300, epoch: 39, batch: 2285, rank_id: 0, loss: 0.006717, lr: 0.0000104737, speed: 0.9044 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:43:12,582] [    INFO]\u001B[0m - global step 124300/156300, epoch: 39, batch: 2385, rank_id: 0, loss: 0.009163, lr: 0.0000104411, speed: 0.9123 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:45:03,895] [    INFO]\u001B[0m - global step 124400/156300, epoch: 39, batch: 2485, rank_id: 0, loss: 0.002478, lr: 0.0000104084, speed: 0.8985 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:46:59,004] [    INFO]\u001B[0m - global step 124500/156300, epoch: 39, batch: 2585, rank_id: 0, loss: 0.007824, lr: 0.0000103758, speed: 0.8689 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:48:55,029] [    INFO]\u001B[0m - global step 124600/156300, epoch: 39, batch: 2685, rank_id: 0, loss: 0.006556, lr: 0.0000103431, speed: 0.8620 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:50:43,995] [    INFO]\u001B[0m - global step 124700/156300, epoch: 39, batch: 2785, rank_id: 0, loss: 0.002294, lr: 0.0000103105, speed: 0.9179 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:52:34,241] [    INFO]\u001B[0m - global step 124800/156300, epoch: 39, batch: 2885, rank_id: 0, loss: 0.008541, lr: 0.0000102779, speed: 0.9072 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:54:25,675] [    INFO]\u001B[0m - global step 124900/156300, epoch: 39, batch: 2985, rank_id: 0, loss: 0.009669, lr: 0.0000102452, speed: 0.8976 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:56:16,074] [    INFO]\u001B[0m - global step 125000/156300, epoch: 39, batch: 3085, rank_id: 0, loss: 0.002534, lr: 0.0000102126, speed: 0.9060 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:58:03,274] [    INFO]\u001B[0m - global step 125100/156300, epoch: 40, batch: 59, rank_id: 0, loss: 0.004123, lr: 0.0000101799, speed: 0.9330 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 12:59:54,991] [    INFO]\u001B[0m - global step 125200/156300, epoch: 40, batch: 159, rank_id: 0, loss: 0.007401, lr: 0.0000101473, speed: 0.8952 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:01:47,757] [    INFO]\u001B[0m - global step 125300/156300, epoch: 40, batch: 259, rank_id: 0, loss: 0.003635, lr: 0.0000101146, speed: 0.8869 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:03:42,300] [    INFO]\u001B[0m - global step 125400/156300, epoch: 40, batch: 359, rank_id: 0, loss: 0.001891, lr: 0.0000100820, speed: 0.8732 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:05:31,612] [    INFO]\u001B[0m - global step 125500/156300, epoch: 40, batch: 459, rank_id: 0, loss: 0.007713, lr: 0.0000100494, speed: 0.9149 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:07:19,306] [    INFO]\u001B[0m - global step 125600/156300, epoch: 40, batch: 559, rank_id: 0, loss: 0.009684, lr: 0.0000100167, speed: 0.9287 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:09:08,991] [    INFO]\u001B[0m - global step 125700/156300, epoch: 40, batch: 659, rank_id: 0, loss: 0.004942, lr: 0.0000099841, speed: 0.9118 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:10:59,922] [    INFO]\u001B[0m - global step 125800/156300, epoch: 40, batch: 759, rank_id: 0, loss: 0.000939, lr: 0.0000099514, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:12:52,549] [    INFO]\u001B[0m - global step 125900/156300, epoch: 40, batch: 859, rank_id: 0, loss: 0.010400, lr: 0.0000099188, speed: 0.8880 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:14:43,820] [    INFO]\u001B[0m - global step 126000/156300, epoch: 40, batch: 959, rank_id: 0, loss: 0.007873, lr: 0.0000098861, speed: 0.8988 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:16:34,346] [    INFO]\u001B[0m - global step 126100/156300, epoch: 40, batch: 1059, rank_id: 0, loss: 0.008245, lr: 0.0000098535, speed: 0.9049 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:18:26,238] [    INFO]\u001B[0m - global step 126200/156300, epoch: 40, batch: 1159, rank_id: 0, loss: 0.008674, lr: 0.0000098209, speed: 0.8938 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:20:19,654] [    INFO]\u001B[0m - global step 126300/156300, epoch: 40, batch: 1259, rank_id: 0, loss: 0.006055, lr: 0.0000097882, speed: 0.8818 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:22:10,039] [    INFO]\u001B[0m - global step 126400/156300, epoch: 40, batch: 1359, rank_id: 0, loss: 0.003129, lr: 0.0000097556, speed: 0.9061 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:23:58,374] [    INFO]\u001B[0m - global step 126500/156300, epoch: 40, batch: 1459, rank_id: 0, loss: 0.003491, lr: 0.0000097229, speed: 0.9232 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:25:47,492] [    INFO]\u001B[0m - global step 126600/156300, epoch: 40, batch: 1559, rank_id: 0, loss: 0.016133, lr: 0.0000096903, speed: 0.9166 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:27:37,602] [    INFO]\u001B[0m - global step 126700/156300, epoch: 40, batch: 1659, rank_id: 0, loss: 0.005653, lr: 0.0000096576, speed: 0.9083 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 13:29:30,195] [    INFO]\u001B[0m - global step 126800/156300, epoch: 40, batch: 1759, rank_id: 0, loss: 0.006392, lr: 0.0000096250, speed: 0.8883 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:31:19,283] [    INFO]\u001B[0m - global step 126900/156300, epoch: 40, batch: 1859, rank_id: 0, loss: 0.003965, lr: 0.0000095924, speed: 0.9168 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:33:11,002] [    INFO]\u001B[0m - global step 127000/156300, epoch: 40, batch: 1959, rank_id: 0, loss: 0.008735, lr: 0.0000095597, speed: 0.8952 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:35:00,018] [    INFO]\u001B[0m - global step 127100/156300, epoch: 40, batch: 2059, rank_id: 0, loss: 0.004989, lr: 0.0000095271, speed: 0.9174 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:36:47,400] [    INFO]\u001B[0m - global step 127200/156300, epoch: 40, batch: 2159, rank_id: 0, loss: 0.006714, lr: 0.0000094944, speed: 0.9314 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:38:38,198] [    INFO]\u001B[0m - global step 127300/156300, epoch: 40, batch: 2259, rank_id: 0, loss: 0.001795, lr: 0.0000094618, speed: 0.9027 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:40:28,858] [    INFO]\u001B[0m - global step 127400/156300, epoch: 40, batch: 2359, rank_id: 0, loss: 0.002690, lr: 0.0000094291, speed: 0.9038 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:42:20,719] [    INFO]\u001B[0m - global step 127500/156300, epoch: 40, batch: 2459, rank_id: 0, loss: 0.002489, lr: 0.0000093965, speed: 0.8941 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:44:14,394] [    INFO]\u001B[0m - global step 127600/156300, epoch: 40, batch: 2559, rank_id: 0, loss: 0.003637, lr: 0.0000093639, speed: 0.8798 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:46:11,996] [    INFO]\u001B[0m - global step 127700/156300, epoch: 40, batch: 2659, rank_id: 0, loss: 0.013245, lr: 0.0000093312, speed: 0.8504 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:47:59,540] [    INFO]\u001B[0m - global step 127800/156300, epoch: 40, batch: 2759, rank_id: 0, loss: 0.003601, lr: 0.0000092986, speed: 0.9300 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:49:51,498] [    INFO]\u001B[0m - global step 127900/156300, epoch: 40, batch: 2859, rank_id: 0, loss: 0.001902, lr: 0.0000092659, speed: 0.8933 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:51:42,001] [    INFO]\u001B[0m - global step 128000/156300, epoch: 40, batch: 2959, rank_id: 0, loss: 0.003187, lr: 0.0000092333, speed: 0.9051 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:53:30,402] [    INFO]\u001B[0m - global step 128100/156300, epoch: 40, batch: 3059, rank_id: 0, loss: 0.001900, lr: 0.0000092006, speed: 0.9226 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:55:20,930] [    INFO]\u001B[0m - global step 128200/156300, epoch: 41, batch: 33, rank_id: 0, loss: 0.006435, lr: 0.0000091680, speed: 0.9049 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:57:09,861] [    INFO]\u001B[0m - global step 128300/156300, epoch: 41, batch: 133, rank_id: 0, loss: 0.002191, lr: 0.0000091354, speed: 0.9181 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 13:59:03,245] [    INFO]\u001B[0m - global step 128400/156300, epoch: 41, batch: 233, rank_id: 0, loss: 0.001842, lr: 0.0000091027, speed: 0.8821 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:00:57,133] [    INFO]\u001B[0m - global step 128500/156300, epoch: 41, batch: 333, rank_id: 0, loss: 0.001897, lr: 0.0000090701, speed: 0.8782 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:02:47,336] [    INFO]\u001B[0m - global step 128600/156300, epoch: 41, batch: 433, rank_id: 0, loss: 0.004760, lr: 0.0000090374, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:04:35,016] [    INFO]\u001B[0m - global step 128700/156300, epoch: 41, batch: 533, rank_id: 0, loss: 0.003833, lr: 0.0000090048, speed: 0.9288 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:06:25,505] [    INFO]\u001B[0m - global step 128800/156300, epoch: 41, batch: 633, rank_id: 0, loss: 0.004962, lr: 0.0000089721, speed: 0.9052 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:08:16,192] [    INFO]\u001B[0m - global step 128900/156300, epoch: 41, batch: 733, rank_id: 0, loss: 0.005912, lr: 0.0000089395, speed: 0.9036 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:10:06,298] [    INFO]\u001B[0m - global step 129000/156300, epoch: 41, batch: 833, rank_id: 0, loss: 0.008769, lr: 0.0000089069, speed: 0.9083 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:11:59,170] [    INFO]\u001B[0m - global step 129100/156300, epoch: 41, batch: 933, rank_id: 0, loss: 0.002621, lr: 0.0000088742, speed: 0.8861 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:13:48,617] [    INFO]\u001B[0m - global step 129200/156300, epoch: 41, batch: 1033, rank_id: 0, loss: 0.008465, lr: 0.0000088416, speed: 0.9138 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:15:39,850] [    INFO]\u001B[0m - global step 129300/156300, epoch: 41, batch: 1133, rank_id: 0, loss: 0.003473, lr: 0.0000088089, speed: 0.8991 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:17:34,847] [    INFO]\u001B[0m - global step 129400/156300, epoch: 41, batch: 1233, rank_id: 0, loss: 0.002527, lr: 0.0000087763, speed: 0.8697 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:19:27,950] [    INFO]\u001B[0m - global step 129500/156300, epoch: 41, batch: 1333, rank_id: 0, loss: 0.024039, lr: 0.0000087437, speed: 0.8843 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:21:15,018] [    INFO]\u001B[0m - global step 129600/156300, epoch: 41, batch: 1433, rank_id: 0, loss: 0.008785, lr: 0.0000087110, speed: 0.9341 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:23:05,139] [    INFO]\u001B[0m - global step 129700/156300, epoch: 41, batch: 1533, rank_id: 0, loss: 0.001265, lr: 0.0000086784, speed: 0.9082 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:24:54,408] [    INFO]\u001B[0m - global step 129800/156300, epoch: 41, batch: 1633, rank_id: 0, loss: 0.001255, lr: 0.0000086457, speed: 0.9153 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:26:46,222] [    INFO]\u001B[0m - global step 129900/156300, epoch: 41, batch: 1733, rank_id: 0, loss: 0.006105, lr: 0.0000086131, speed: 0.8945 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:28:36,984] [    INFO]\u001B[0m - global step 130000/156300, epoch: 41, batch: 1833, rank_id: 0, loss: 0.004257, lr: 0.0000085804, speed: 0.9030 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:30:27,265] [    INFO]\u001B[0m - global step 130100/156300, epoch: 41, batch: 1933, rank_id: 0, loss: 0.003568, lr: 0.0000085478, speed: 0.9069 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:32:15,225] [    INFO]\u001B[0m - global step 130200/156300, epoch: 41, batch: 2033, rank_id: 0, loss: 0.003488, lr: 0.0000085152, speed: 0.9264 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:34:04,797] [    INFO]\u001B[0m - global step 130300/156300, epoch: 41, batch: 2133, rank_id: 0, loss: 0.001767, lr: 0.0000084825, speed: 0.9128 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:35:55,200] [    INFO]\u001B[0m - global step 130400/156300, epoch: 41, batch: 2233, rank_id: 0, loss: 0.008370, lr: 0.0000084499, speed: 0.9059 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:37:43,726] [    INFO]\u001B[0m - global step 130500/156300, epoch: 41, batch: 2333, rank_id: 0, loss: 0.006867, lr: 0.0000084172, speed: 0.9216 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:39:34,142] [    INFO]\u001B[0m - global step 130600/156300, epoch: 41, batch: 2433, rank_id: 0, loss: 0.003414, lr: 0.0000083846, speed: 0.9058 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:41:30,139] [    INFO]\u001B[0m - global step 130700/156300, epoch: 41, batch: 2533, rank_id: 0, loss: 0.003971, lr: 0.0000083519, speed: 0.8622 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:43:26,722] [    INFO]\u001B[0m - global step 130800/156300, epoch: 41, batch: 2633, rank_id: 0, loss: 0.006121, lr: 0.0000083193, speed: 0.8579 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:45:14,655] [    INFO]\u001B[0m - global step 130900/156300, epoch: 41, batch: 2733, rank_id: 0, loss: 0.002964, lr: 0.0000082867, speed: 0.9266 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:47:08,104] [    INFO]\u001B[0m - global step 131000/156300, epoch: 41, batch: 2833, rank_id: 0, loss: 0.007151, lr: 0.0000082540, speed: 0.8816 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:48:56,911] [    INFO]\u001B[0m - global step 131100/156300, epoch: 41, batch: 2933, rank_id: 0, loss: 0.005888, lr: 0.0000082214, speed: 0.9192 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:50:47,115] [    INFO]\u001B[0m - global step 131200/156300, epoch: 41, batch: 3033, rank_id: 0, loss: 0.003097, lr: 0.0000081887, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:52:37,539] [    INFO]\u001B[0m - global step 131300/156300, epoch: 42, batch: 7, rank_id: 0, loss: 0.001923, lr: 0.0000081561, speed: 0.9057 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:54:26,654] [    INFO]\u001B[0m - global step 131400/156300, epoch: 42, batch: 107, rank_id: 0, loss: 0.003327, lr: 0.0000081234, speed: 0.9166 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:56:18,602] [    INFO]\u001B[0m - global step 131500/156300, epoch: 42, batch: 207, rank_id: 0, loss: 0.002450, lr: 0.0000080908, speed: 0.8934 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 14:58:12,256] [    INFO]\u001B[0m - global step 131600/156300, epoch: 42, batch: 307, rank_id: 0, loss: 0.001047, lr: 0.0000080582, speed: 0.8800 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 15:00:03,843] [    INFO]\u001B[0m - global step 131700/156300, epoch: 42, batch: 407, rank_id: 0, loss: 0.009012, lr: 0.0000080255, speed: 0.8963 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:01:51,289] [    INFO]\u001B[0m - global step 131800/156300, epoch: 42, batch: 507, rank_id: 0, loss: 0.003283, lr: 0.0000079929, speed: 0.9308 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:03:41,818] [    INFO]\u001B[0m - global step 131900/156300, epoch: 42, batch: 607, rank_id: 0, loss: 0.003554, lr: 0.0000079602, speed: 0.9049 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:05:32,645] [    INFO]\u001B[0m - global step 132000/156300, epoch: 42, batch: 707, rank_id: 0, loss: 0.006293, lr: 0.0000079276, speed: 0.9024 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:07:22,551] [    INFO]\u001B[0m - global step 132100/156300, epoch: 42, batch: 807, rank_id: 0, loss: 0.008421, lr: 0.0000078949, speed: 0.9100 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:09:15,204] [    INFO]\u001B[0m - global step 132200/156300, epoch: 42, batch: 907, rank_id: 0, loss: 0.005318, lr: 0.0000078623, speed: 0.8878 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:11:06,176] [    INFO]\u001B[0m - global step 132300/156300, epoch: 42, batch: 1007, rank_id: 0, loss: 0.004978, lr: 0.0000078297, speed: 0.9013 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:12:57,265] [    INFO]\u001B[0m - global step 132400/156300, epoch: 42, batch: 1107, rank_id: 0, loss: 0.003031, lr: 0.0000077970, speed: 0.9003 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:14:50,780] [    INFO]\u001B[0m - global step 132500/156300, epoch: 42, batch: 1207, rank_id: 0, loss: 0.015455, lr: 0.0000077644, speed: 0.8811 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:16:44,846] [    INFO]\u001B[0m - global step 132600/156300, epoch: 42, batch: 1307, rank_id: 0, loss: 0.004052, lr: 0.0000077317, speed: 0.8768 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:18:30,777] [    INFO]\u001B[0m - global step 132700/156300, epoch: 42, batch: 1407, rank_id: 0, loss: 0.000952, lr: 0.0000076991, speed: 0.9441 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:20:21,925] [    INFO]\u001B[0m - global step 132800/156300, epoch: 42, batch: 1507, rank_id: 0, loss: 0.005300, lr: 0.0000076664, speed: 0.8998 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:22:09,613] [    INFO]\u001B[0m - global step 132900/156300, epoch: 42, batch: 1607, rank_id: 0, loss: 0.002621, lr: 0.0000076338, speed: 0.9287 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:24:01,331] [    INFO]\u001B[0m - global step 133000/156300, epoch: 42, batch: 1707, rank_id: 0, loss: 0.005093, lr: 0.0000076012, speed: 0.8952 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:25:53,511] [    INFO]\u001B[0m - global step 133100/156300, epoch: 42, batch: 1807, rank_id: 0, loss: 0.004881, lr: 0.0000075685, speed: 0.8915 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:27:46,396] [    INFO]\u001B[0m - global step 133200/156300, epoch: 42, batch: 1907, rank_id: 0, loss: 0.003171, lr: 0.0000075359, speed: 0.8860 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:29:32,432] [    INFO]\u001B[0m - global step 133300/156300, epoch: 42, batch: 2007, rank_id: 0, loss: 0.002747, lr: 0.0000075032, speed: 0.9432 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:31:22,876] [    INFO]\u001B[0m - global step 133400/156300, epoch: 42, batch: 2107, rank_id: 0, loss: 0.003256, lr: 0.0000074706, speed: 0.9056 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:33:11,065] [    INFO]\u001B[0m - global step 133500/156300, epoch: 42, batch: 2207, rank_id: 0, loss: 0.002815, lr: 0.0000074379, speed: 0.9244 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:34:59,539] [    INFO]\u001B[0m - global step 133600/156300, epoch: 42, batch: 2307, rank_id: 0, loss: 0.003709, lr: 0.0000074053, speed: 0.9220 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:36:50,284] [    INFO]\u001B[0m - global step 133700/156300, epoch: 42, batch: 2407, rank_id: 0, loss: 0.004167, lr: 0.0000073727, speed: 0.9031 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:38:43,725] [    INFO]\u001B[0m - global step 133800/156300, epoch: 42, batch: 2507, rank_id: 0, loss: 0.002195, lr: 0.0000073400, speed: 0.8816 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:40:40,883] [    INFO]\u001B[0m - global step 133900/156300, epoch: 42, batch: 2607, rank_id: 0, loss: 0.001642, lr: 0.0000073074, speed: 0.8537 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:42:31,479] [    INFO]\u001B[0m - global step 134000/156300, epoch: 42, batch: 2707, rank_id: 0, loss: 0.002059, lr: 0.0000072747, speed: 0.9043 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:44:22,587] [    INFO]\u001B[0m - global step 134100/156300, epoch: 42, batch: 2807, rank_id: 0, loss: 0.008893, lr: 0.0000072421, speed: 0.9002 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:46:13,288] [    INFO]\u001B[0m - global step 134200/156300, epoch: 42, batch: 2907, rank_id: 0, loss: 0.001715, lr: 0.0000072094, speed: 0.9035 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:48:04,901] [    INFO]\u001B[0m - global step 134300/156300, epoch: 42, batch: 3007, rank_id: 0, loss: 0.005807, lr: 0.0000071768, speed: 0.8961 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:49:53,819] [    INFO]\u001B[0m - global step 134400/156300, epoch: 42, batch: 3107, rank_id: 0, loss: 0.004385, lr: 0.0000071442, speed: 0.9183 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:51:43,243] [    INFO]\u001B[0m - global step 134500/156300, epoch: 43, batch: 81, rank_id: 0, loss: 0.011568, lr: 0.0000071115, speed: 0.9140 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:53:35,086] [    INFO]\u001B[0m - global step 134600/156300, epoch: 43, batch: 181, rank_id: 0, loss: 0.014236, lr: 0.0000070789, speed: 0.8942 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:55:29,026] [    INFO]\u001B[0m - global step 134700/156300, epoch: 43, batch: 281, rank_id: 0, loss: 0.011546, lr: 0.0000070462, speed: 0.8778 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:57:21,598] [    INFO]\u001B[0m - global step 134800/156300, epoch: 43, batch: 381, rank_id: 0, loss: 0.007956, lr: 0.0000070136, speed: 0.8884 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 15:59:08,153] [    INFO]\u001B[0m - global step 134900/156300, epoch: 43, batch: 481, rank_id: 0, loss: 0.001707, lr: 0.0000069809, speed: 0.9386 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:00:58,873] [    INFO]\u001B[0m - global step 135000/156300, epoch: 43, batch: 581, rank_id: 0, loss: 0.005358, lr: 0.0000069483, speed: 0.9033 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:02:48,125] [    INFO]\u001B[0m - global step 135100/156300, epoch: 43, batch: 681, rank_id: 0, loss: 0.002416, lr: 0.0000069157, speed: 0.9154 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:04:38,500] [    INFO]\u001B[0m - global step 135200/156300, epoch: 43, batch: 781, rank_id: 0, loss: 0.001925, lr: 0.0000068830, speed: 0.9061 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:06:31,291] [    INFO]\u001B[0m - global step 135300/156300, epoch: 43, batch: 881, rank_id: 0, loss: 0.002314, lr: 0.0000068504, speed: 0.8867 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:08:20,044] [    INFO]\u001B[0m - global step 135400/156300, epoch: 43, batch: 981, rank_id: 0, loss: 0.012638, lr: 0.0000068177, speed: 0.9196 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:10:10,606] [    INFO]\u001B[0m - global step 135500/156300, epoch: 43, batch: 1081, rank_id: 0, loss: 0.006832, lr: 0.0000067851, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:12:04,442] [    INFO]\u001B[0m - global step 135600/156300, epoch: 43, batch: 1181, rank_id: 0, loss: 0.004618, lr: 0.0000067525, speed: 0.8786 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:13:58,700] [    INFO]\u001B[0m - global step 135700/156300, epoch: 43, batch: 1281, rank_id: 0, loss: 0.011487, lr: 0.0000067198, speed: 0.8753 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:15:46,863] [    INFO]\u001B[0m - global step 135800/156300, epoch: 43, batch: 1381, rank_id: 0, loss: 0.002754, lr: 0.0000066872, speed: 0.9247 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:17:37,051] [    INFO]\u001B[0m - global step 135900/156300, epoch: 43, batch: 1481, rank_id: 0, loss: 0.006765, lr: 0.0000066545, speed: 0.9077 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:19:24,654] [    INFO]\u001B[0m - global step 136000/156300, epoch: 43, batch: 1581, rank_id: 0, loss: 0.002670, lr: 0.0000066219, speed: 0.9295 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:21:14,264] [    INFO]\u001B[0m - global step 136100/156300, epoch: 43, batch: 1681, rank_id: 0, loss: 0.006937, lr: 0.0000065892, speed: 0.9125 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:23:07,328] [    INFO]\u001B[0m - global step 136200/156300, epoch: 43, batch: 1781, rank_id: 0, loss: 0.005980, lr: 0.0000065566, speed: 0.8846 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:24:57,931] [    INFO]\u001B[0m - global step 136300/156300, epoch: 43, batch: 1881, rank_id: 0, loss: 0.004585, lr: 0.0000065240, speed: 0.9043 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:26:48,636] [    INFO]\u001B[0m - global step 136400/156300, epoch: 43, batch: 1981, rank_id: 0, loss: 0.002081, lr: 0.0000064913, speed: 0.9034 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:28:37,523] [    INFO]\u001B[0m - global step 136500/156300, epoch: 43, batch: 2081, rank_id: 0, loss: 0.000954, lr: 0.0000064587, speed: 0.9185 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 16:30:25,184] [    INFO]\u001B[0m - global step 136600/156300, epoch: 43, batch: 2181, rank_id: 0, loss: 0.004327, lr: 0.0000064260, speed: 0.9290 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:32:16,148] [    INFO]\u001B[0m - global step 136700/156300, epoch: 43, batch: 2281, rank_id: 0, loss: 0.005938, lr: 0.0000063934, speed: 0.9013 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:34:05,582] [    INFO]\u001B[0m - global step 136800/156300, epoch: 43, batch: 2381, rank_id: 0, loss: 0.014332, lr: 0.0000063607, speed: 0.9139 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:35:56,243] [    INFO]\u001B[0m - global step 136900/156300, epoch: 43, batch: 2481, rank_id: 0, loss: 0.002355, lr: 0.0000063281, speed: 0.9038 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:37:51,840] [    INFO]\u001B[0m - global step 137000/156300, epoch: 43, batch: 2581, rank_id: 0, loss: 0.001638, lr: 0.0000062955, speed: 0.8652 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:39:47,851] [    INFO]\u001B[0m - global step 137100/156300, epoch: 43, batch: 2681, rank_id: 0, loss: 0.005080, lr: 0.0000062628, speed: 0.8621 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:41:36,572] [    INFO]\u001B[0m - global step 137200/156300, epoch: 43, batch: 2781, rank_id: 0, loss: 0.002103, lr: 0.0000062302, speed: 0.9199 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:43:27,265] [    INFO]\u001B[0m - global step 137300/156300, epoch: 43, batch: 2881, rank_id: 0, loss: 0.002132, lr: 0.0000061975, speed: 0.9035 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:45:18,287] [    INFO]\u001B[0m - global step 137400/156300, epoch: 43, batch: 2981, rank_id: 0, loss: 0.004405, lr: 0.0000061649, speed: 0.9008 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:47:08,768] [    INFO]\u001B[0m - global step 137500/156300, epoch: 43, batch: 3081, rank_id: 0, loss: 0.002615, lr: 0.0000061322, speed: 0.9053 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:48:56,790] [    INFO]\u001B[0m - global step 137600/156300, epoch: 44, batch: 55, rank_id: 0, loss: 0.004603, lr: 0.0000060996, speed: 0.9259 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:50:46,637] [    INFO]\u001B[0m - global step 137700/156300, epoch: 44, batch: 155, rank_id: 0, loss: 0.002369, lr: 0.0000060670, speed: 0.9105 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:52:40,606] [    INFO]\u001B[0m - global step 137800/156300, epoch: 44, batch: 255, rank_id: 0, loss: 0.001955, lr: 0.0000060343, speed: 0.8776 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:54:34,229] [    INFO]\u001B[0m - global step 137900/156300, epoch: 44, batch: 355, rank_id: 0, loss: 0.004311, lr: 0.0000060017, speed: 0.8802 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:56:23,846] [    INFO]\u001B[0m - global step 138000/156300, epoch: 44, batch: 455, rank_id: 0, loss: 0.005611, lr: 0.0000059690, speed: 0.9124 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 16:58:11,793] [    INFO]\u001B[0m - global step 138100/156300, epoch: 44, batch: 555, rank_id: 0, loss: 0.002355, lr: 0.0000059364, speed: 0.9265 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:00:01,700] [    INFO]\u001B[0m - global step 138200/156300, epoch: 44, batch: 655, rank_id: 0, loss: 0.012266, lr: 0.0000059037, speed: 0.9100 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:01:52,168] [    INFO]\u001B[0m - global step 138300/156300, epoch: 44, batch: 755, rank_id: 0, loss: 0.001296, lr: 0.0000058711, speed: 0.9054 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:03:44,227] [    INFO]\u001B[0m - global step 138400/156300, epoch: 44, batch: 855, rank_id: 0, loss: 0.002307, lr: 0.0000058385, speed: 0.8925 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:05:35,094] [    INFO]\u001B[0m - global step 138500/156300, epoch: 44, batch: 955, rank_id: 0, loss: 0.003114, lr: 0.0000058058, speed: 0.9021 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:07:26,362] [    INFO]\u001B[0m - global step 138600/156300, epoch: 44, batch: 1055, rank_id: 0, loss: 0.002576, lr: 0.0000057732, speed: 0.8989 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:09:17,553] [    INFO]\u001B[0m - global step 138700/156300, epoch: 44, batch: 1155, rank_id: 0, loss: 0.011996, lr: 0.0000057405, speed: 0.8995 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:11:12,052] [    INFO]\u001B[0m - global step 138800/156300, epoch: 44, batch: 1255, rank_id: 0, loss: 0.006753, lr: 0.0000057079, speed: 0.8735 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:13:01,722] [    INFO]\u001B[0m - global step 138900/156300, epoch: 44, batch: 1355, rank_id: 0, loss: 0.004969, lr: 0.0000056752, speed: 0.9120 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:14:49,760] [    INFO]\u001B[0m - global step 139000/156300, epoch: 44, batch: 1455, rank_id: 0, loss: 0.003348, lr: 0.0000056426, speed: 0.9257 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:16:38,854] [    INFO]\u001B[0m - global step 139100/156300, epoch: 44, batch: 1555, rank_id: 0, loss: 0.002269, lr: 0.0000056100, speed: 0.9168 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:18:29,058] [    INFO]\u001B[0m - global step 139200/156300, epoch: 44, batch: 1655, rank_id: 0, loss: 0.002093, lr: 0.0000055773, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:20:22,016] [    INFO]\u001B[0m - global step 139300/156300, epoch: 44, batch: 1755, rank_id: 0, loss: 0.004653, lr: 0.0000055447, speed: 0.8854 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:22:11,358] [    INFO]\u001B[0m - global step 139400/156300, epoch: 44, batch: 1855, rank_id: 0, loss: 0.005703, lr: 0.0000055120, speed: 0.9147 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:24:02,224] [    INFO]\u001B[0m - global step 139500/156300, epoch: 44, batch: 1955, rank_id: 0, loss: 0.004706, lr: 0.0000054794, speed: 0.9021 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:25:50,504] [    INFO]\u001B[0m - global step 139600/156300, epoch: 44, batch: 2055, rank_id: 0, loss: 0.013366, lr: 0.0000054467, speed: 0.9237 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:27:38,462] [    INFO]\u001B[0m - global step 139700/156300, epoch: 44, batch: 2155, rank_id: 0, loss: 0.003796, lr: 0.0000054141, speed: 0.9264 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:29:29,527] [    INFO]\u001B[0m - global step 139800/156300, epoch: 44, batch: 2255, rank_id: 0, loss: 0.002948, lr: 0.0000053815, speed: 0.9005 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:31:18,824] [    INFO]\u001B[0m - global step 139900/156300, epoch: 44, batch: 2355, rank_id: 0, loss: 0.003284, lr: 0.0000053488, speed: 0.9151 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:33:10,384] [    INFO]\u001B[0m - global step 140000/156300, epoch: 44, batch: 2455, rank_id: 0, loss: 0.008589, lr: 0.0000053162, speed: 0.8965 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:33:20,948] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:33:20,950] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:35:15,886] [    INFO]\u001B[0m - global step 140100/156300, epoch: 44, batch: 2555, rank_id: 0, loss: 0.002292, lr: 0.0000052835, speed: 0.7969 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:37:13,324] [    INFO]\u001B[0m - global step 140200/156300, epoch: 44, batch: 2655, rank_id: 0, loss: 0.001976, lr: 0.0000052509, speed: 0.8516 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:39:00,145] [    INFO]\u001B[0m - global step 140300/156300, epoch: 44, batch: 2755, rank_id: 0, loss: 0.005397, lr: 0.0000052182, speed: 0.9363 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:40:52,315] [    INFO]\u001B[0m - global step 140400/156300, epoch: 44, batch: 2855, rank_id: 0, loss: 0.002340, lr: 0.0000051856, speed: 0.8916 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:42:41,953] [    INFO]\u001B[0m - global step 140500/156300, epoch: 44, batch: 2955, rank_id: 0, loss: 0.001561, lr: 0.0000051530, speed: 0.9122 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:44:31,407] [    INFO]\u001B[0m - global step 140600/156300, epoch: 44, batch: 3055, rank_id: 0, loss: 0.021895, lr: 0.0000051203, speed: 0.9138 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:46:21,336] [    INFO]\u001B[0m - global step 140700/156300, epoch: 45, batch: 29, rank_id: 0, loss: 0.002292, lr: 0.0000050877, speed: 0.9098 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:48:10,865] [    INFO]\u001B[0m - global step 140800/156300, epoch: 45, batch: 129, rank_id: 0, loss: 0.005363, lr: 0.0000050550, speed: 0.9131 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:50:02,526] [    INFO]\u001B[0m - global step 140900/156300, epoch: 45, batch: 229, rank_id: 0, loss: 0.002930, lr: 0.0000050224, speed: 0.8957 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:51:57,630] [    INFO]\u001B[0m - global step 141000/156300, epoch: 45, batch: 329, rank_id: 0, loss: 0.001856, lr: 0.0000049898, speed: 0.8689 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:53:46,971] [    INFO]\u001B[0m - global step 141100/156300, epoch: 45, batch: 429, rank_id: 0, loss: 0.002261, lr: 0.0000049571, speed: 0.9147 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:55:34,897] [    INFO]\u001B[0m - global step 141200/156300, epoch: 45, batch: 529, rank_id: 0, loss: 0.001980, lr: 0.0000049245, speed: 0.9267 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 17:57:25,409] [    INFO]\u001B[0m - global step 141300/156300, epoch: 45, batch: 629, rank_id: 0, loss: 0.001587, lr: 0.0000048918, speed: 0.9050 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 17:59:15,968] [    INFO]\u001B[0m - global step 141400/156300, epoch: 45, batch: 729, rank_id: 0, loss: 0.004543, lr: 0.0000048592, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:01:05,335] [    INFO]\u001B[0m - global step 141500/156300, epoch: 45, batch: 829, rank_id: 0, loss: 0.001415, lr: 0.0000048265, speed: 0.9145 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:02:58,254] [    INFO]\u001B[0m - global step 141600/156300, epoch: 45, batch: 929, rank_id: 0, loss: 0.002481, lr: 0.0000047939, speed: 0.8857 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:04:48,997] [    INFO]\u001B[0m - global step 141700/156300, epoch: 45, batch: 1029, rank_id: 0, loss: 0.005140, lr: 0.0000047613, speed: 0.9031 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:06:39,166] [    INFO]\u001B[0m - global step 141800/156300, epoch: 45, batch: 1129, rank_id: 0, loss: 0.003225, lr: 0.0000047286, speed: 0.9078 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:08:33,459] [    INFO]\u001B[0m - global step 141900/156300, epoch: 45, batch: 1229, rank_id: 0, loss: 0.002982, lr: 0.0000046960, speed: 0.8751 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:10:27,366] [    INFO]\u001B[0m - global step 142000/156300, epoch: 45, batch: 1329, rank_id: 0, loss: 0.001831, lr: 0.0000046633, speed: 0.8780 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:12:13,974] [    INFO]\u001B[0m - global step 142100/156300, epoch: 45, batch: 1429, rank_id: 0, loss: 0.003640, lr: 0.0000046307, speed: 0.9382 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:14:04,249] [    INFO]\u001B[0m - global step 142200/156300, epoch: 45, batch: 1529, rank_id: 0, loss: 0.006614, lr: 0.0000045980, speed: 0.9070 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:15:52,986] [    INFO]\u001B[0m - global step 142300/156300, epoch: 45, batch: 1629, rank_id: 0, loss: 0.003409, lr: 0.0000045654, speed: 0.9198 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:17:45,262] [    INFO]\u001B[0m - global step 142400/156300, epoch: 45, batch: 1729, rank_id: 0, loss: 0.001492, lr: 0.0000045328, speed: 0.8908 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:19:36,407] [    INFO]\u001B[0m - global step 142500/156300, epoch: 45, batch: 1829, rank_id: 0, loss: 0.001295, lr: 0.0000045001, speed: 0.8999 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:21:25,892] [    INFO]\u001B[0m - global step 142600/156300, epoch: 45, batch: 1929, rank_id: 0, loss: 0.003368, lr: 0.0000044675, speed: 0.9135 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:23:14,618] [    INFO]\u001B[0m - global step 142700/156300, epoch: 45, batch: 2029, rank_id: 0, loss: 0.002103, lr: 0.0000044348, speed: 0.9199 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:25:03,900] [    INFO]\u001B[0m - global step 142800/156300, epoch: 45, batch: 2129, rank_id: 0, loss: 0.002839, lr: 0.0000044022, speed: 0.9152 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:26:54,043] [    INFO]\u001B[0m - global step 142900/156300, epoch: 45, batch: 2229, rank_id: 0, loss: 0.010264, lr: 0.0000043695, speed: 0.9081 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:28:42,751] [    INFO]\u001B[0m - global step 143000/156300, epoch: 45, batch: 2329, rank_id: 0, loss: 0.006419, lr: 0.0000043369, speed: 0.9201 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:30:32,403] [    INFO]\u001B[0m - global step 143100/156300, epoch: 45, batch: 2429, rank_id: 0, loss: 0.004335, lr: 0.0000043043, speed: 0.9121 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:32:28,276] [    INFO]\u001B[0m - global step 143200/156300, epoch: 45, batch: 2529, rank_id: 0, loss: 0.003477, lr: 0.0000042716, speed: 0.8632 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:34:25,185] [    INFO]\u001B[0m - global step 143300/156300, epoch: 45, batch: 2629, rank_id: 0, loss: 0.001757, lr: 0.0000042390, speed: 0.8555 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:36:13,330] [    INFO]\u001B[0m - global step 143400/156300, epoch: 45, batch: 2729, rank_id: 0, loss: 0.001911, lr: 0.0000042063, speed: 0.9249 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:38:06,408] [    INFO]\u001B[0m - global step 143500/156300, epoch: 45, batch: 2829, rank_id: 0, loss: 0.004999, lr: 0.0000041737, speed: 0.8845 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:39:55,181] [    INFO]\u001B[0m - global step 143600/156300, epoch: 45, batch: 2929, rank_id: 0, loss: 0.003982, lr: 0.0000041410, speed: 0.9195 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:41:46,174] [    INFO]\u001B[0m - global step 143700/156300, epoch: 45, batch: 3029, rank_id: 0, loss: 0.008646, lr: 0.0000041084, speed: 0.9011 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:43:35,822] [    INFO]\u001B[0m - global step 143800/156300, epoch: 46, batch: 3, rank_id: 0, loss: 0.002247, lr: 0.0000040758, speed: 0.9122 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:45:24,471] [    INFO]\u001B[0m - global step 143900/156300, epoch: 46, batch: 103, rank_id: 0, loss: 0.001682, lr: 0.0000040431, speed: 0.9205 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:47:17,579] [    INFO]\u001B[0m - global step 144000/156300, epoch: 46, batch: 203, rank_id: 0, loss: 0.001346, lr: 0.0000040105, speed: 0.8842 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:49:10,805] [    INFO]\u001B[0m - global step 144100/156300, epoch: 46, batch: 303, rank_id: 0, loss: 0.006376, lr: 0.0000039778, speed: 0.8833 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:51:02,017] [    INFO]\u001B[0m - global step 144200/156300, epoch: 46, batch: 403, rank_id: 0, loss: 0.012751, lr: 0.0000039452, speed: 0.8993 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:52:49,501] [    INFO]\u001B[0m - global step 144300/156300, epoch: 46, batch: 503, rank_id: 0, loss: 0.003848, lr: 0.0000039125, speed: 0.9305 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:54:40,156] [    INFO]\u001B[0m - global step 144400/156300, epoch: 46, batch: 603, rank_id: 0, loss: 0.005066, lr: 0.0000038799, speed: 0.9038 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:56:29,867] [    INFO]\u001B[0m - global step 144500/156300, epoch: 46, batch: 703, rank_id: 0, loss: 0.001125, lr: 0.0000038473, speed: 0.9116 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 18:58:19,982] [    INFO]\u001B[0m - global step 144600/156300, epoch: 46, batch: 803, rank_id: 0, loss: 0.003288, lr: 0.0000038146, speed: 0.9083 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:00:12,625] [    INFO]\u001B[0m - global step 144700/156300, epoch: 46, batch: 903, rank_id: 0, loss: 0.002140, lr: 0.0000037820, speed: 0.8879 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:02:03,925] [    INFO]\u001B[0m - global step 144800/156300, epoch: 46, batch: 1003, rank_id: 0, loss: 0.002730, lr: 0.0000037493, speed: 0.8986 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:03:54,374] [    INFO]\u001B[0m - global step 144900/156300, epoch: 46, batch: 1103, rank_id: 0, loss: 0.001034, lr: 0.0000037167, speed: 0.9055 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:05:48,884] [    INFO]\u001B[0m - global step 145000/156300, epoch: 46, batch: 1203, rank_id: 0, loss: 0.002751, lr: 0.0000036840, speed: 0.8734 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:07:42,325] [    INFO]\u001B[0m - global step 145100/156300, epoch: 46, batch: 1303, rank_id: 0, loss: 0.007357, lr: 0.0000036514, speed: 0.8816 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:09:28,111] [    INFO]\u001B[0m - global step 145200/156300, epoch: 46, batch: 1403, rank_id: 0, loss: 0.016708, lr: 0.0000036188, speed: 0.9454 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:11:18,840] [    INFO]\u001B[0m - global step 145300/156300, epoch: 46, batch: 1503, rank_id: 0, loss: 0.001596, lr: 0.0000035861, speed: 0.9032 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:13:06,991] [    INFO]\u001B[0m - global step 145400/156300, epoch: 46, batch: 1603, rank_id: 0, loss: 0.002739, lr: 0.0000035535, speed: 0.9248 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:14:57,509] [    INFO]\u001B[0m - global step 145500/156300, epoch: 46, batch: 1703, rank_id: 0, loss: 0.004879, lr: 0.0000035208, speed: 0.9050 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:16:51,016] [    INFO]\u001B[0m - global step 145600/156300, epoch: 46, batch: 1803, rank_id: 0, loss: 0.003925, lr: 0.0000034882, speed: 0.8811 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:18:43,541] [    INFO]\u001B[0m - global step 145700/156300, epoch: 46, batch: 1903, rank_id: 0, loss: 0.002112, lr: 0.0000034555, speed: 0.8888 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:20:29,855] [    INFO]\u001B[0m - global step 145800/156300, epoch: 46, batch: 2003, rank_id: 0, loss: 0.004140, lr: 0.0000034229, speed: 0.9408 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:22:20,280] [    INFO]\u001B[0m - global step 145900/156300, epoch: 46, batch: 2103, rank_id: 0, loss: 0.001034, lr: 0.0000033903, speed: 0.9057 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:24:06,940] [    INFO]\u001B[0m - global step 146000/156300, epoch: 46, batch: 2203, rank_id: 0, loss: 0.003563, lr: 0.0000033576, speed: 0.9377 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:25:56,298] [    INFO]\u001B[0m - global step 146100/156300, epoch: 46, batch: 2303, rank_id: 0, loss: 0.001877, lr: 0.0000033250, speed: 0.9146 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 19:27:47,160] [    INFO]\u001B[0m - global step 146200/156300, epoch: 46, batch: 2403, rank_id: 0, loss: 0.004024, lr: 0.0000032923, speed: 0.9022 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:29:40,313] [    INFO]\u001B[0m - global step 146300/156300, epoch: 46, batch: 2503, rank_id: 0, loss: 0.001606, lr: 0.0000032597, speed: 0.8839 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:31:36,419] [    INFO]\u001B[0m - global step 146400/156300, epoch: 46, batch: 2603, rank_id: 0, loss: 0.003898, lr: 0.0000032270, speed: 0.8614 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:33:28,158] [    INFO]\u001B[0m - global step 146500/156300, epoch: 46, batch: 2703, rank_id: 0, loss: 0.004210, lr: 0.0000031944, speed: 0.8951 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:35:19,049] [    INFO]\u001B[0m - global step 146600/156300, epoch: 46, batch: 2803, rank_id: 0, loss: 0.006353, lr: 0.0000031618, speed: 0.9019 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:37:10,088] [    INFO]\u001B[0m - global step 146700/156300, epoch: 46, batch: 2903, rank_id: 0, loss: 0.002829, lr: 0.0000031291, speed: 0.9007 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:39:01,059] [    INFO]\u001B[0m - global step 146800/156300, epoch: 46, batch: 3003, rank_id: 0, loss: 0.002727, lr: 0.0000030965, speed: 0.9013 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:40:50,357] [    INFO]\u001B[0m - global step 146900/156300, epoch: 46, batch: 3103, rank_id: 0, loss: 0.005003, lr: 0.0000030638, speed: 0.9151 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:42:38,846] [    INFO]\u001B[0m - global step 147000/156300, epoch: 47, batch: 77, rank_id: 0, loss: 0.001697, lr: 0.0000030312, speed: 0.9219 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:44:30,579] [    INFO]\u001B[0m - global step 147100/156300, epoch: 47, batch: 177, rank_id: 0, loss: 0.002704, lr: 0.0000029986, speed: 0.8951 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:46:24,484] [    INFO]\u001B[0m - global step 147200/156300, epoch: 47, batch: 277, rank_id: 0, loss: 0.004318, lr: 0.0000029659, speed: 0.8781 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:48:16,385] [    INFO]\u001B[0m - global step 147300/156300, epoch: 47, batch: 377, rank_id: 0, loss: 0.003693, lr: 0.0000029333, speed: 0.8938 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:50:04,940] [    INFO]\u001B[0m - global step 147400/156300, epoch: 47, batch: 477, rank_id: 0, loss: 0.001382, lr: 0.0000029006, speed: 0.9213 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:51:53,802] [    INFO]\u001B[0m - global step 147500/156300, epoch: 47, batch: 577, rank_id: 0, loss: 0.000848, lr: 0.0000028680, speed: 0.9187 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:53:43,347] [    INFO]\u001B[0m - global step 147600/156300, epoch: 47, batch: 677, rank_id: 0, loss: 0.004708, lr: 0.0000028353, speed: 0.9130 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:55:35,141] [    INFO]\u001B[0m - global step 147700/156300, epoch: 47, batch: 777, rank_id: 0, loss: 0.002692, lr: 0.0000028027, speed: 0.8946 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:57:28,155] [    INFO]\u001B[0m - global step 147800/156300, epoch: 47, batch: 877, rank_id: 0, loss: 0.007483, lr: 0.0000027701, speed: 0.8850 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 19:59:16,602] [    INFO]\u001B[0m - global step 147900/156300, epoch: 47, batch: 977, rank_id: 0, loss: 0.004477, lr: 0.0000027374, speed: 0.9222 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:01:07,168] [    INFO]\u001B[0m - global step 148000/156300, epoch: 47, batch: 1077, rank_id: 0, loss: 0.006381, lr: 0.0000027048, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:03:00,829] [    INFO]\u001B[0m - global step 148100/156300, epoch: 47, batch: 1177, rank_id: 0, loss: 0.008350, lr: 0.0000026721, speed: 0.8799 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:04:54,877] [    INFO]\u001B[0m - global step 148200/156300, epoch: 47, batch: 1277, rank_id: 0, loss: 0.001859, lr: 0.0000026395, speed: 0.8769 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:06:42,775] [    INFO]\u001B[0m - global step 148300/156300, epoch: 47, batch: 1377, rank_id: 0, loss: 0.004150, lr: 0.0000026068, speed: 0.9269 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:08:32,580] [    INFO]\u001B[0m - global step 148400/156300, epoch: 47, batch: 1477, rank_id: 0, loss: 0.003566, lr: 0.0000025742, speed: 0.9108 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:10:21,688] [    INFO]\u001B[0m - global step 148500/156300, epoch: 47, batch: 1577, rank_id: 0, loss: 0.002443, lr: 0.0000025416, speed: 0.9167 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:12:10,226] [    INFO]\u001B[0m - global step 148600/156300, epoch: 47, batch: 1677, rank_id: 0, loss: 0.003057, lr: 0.0000025089, speed: 0.9215 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:14:03,273] [    INFO]\u001B[0m - global step 148700/156300, epoch: 47, batch: 1777, rank_id: 0, loss: 0.001231, lr: 0.0000024763, speed: 0.8847 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:15:53,835] [    INFO]\u001B[0m - global step 148800/156300, epoch: 47, batch: 1877, rank_id: 0, loss: 0.001256, lr: 0.0000024436, speed: 0.9046 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:17:45,540] [    INFO]\u001B[0m - global step 148900/156300, epoch: 47, batch: 1977, rank_id: 0, loss: 0.001556, lr: 0.0000024110, speed: 0.8953 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:19:35,331] [    INFO]\u001B[0m - global step 149000/156300, epoch: 47, batch: 2077, rank_id: 0, loss: 0.000954, lr: 0.0000023783, speed: 0.9110 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:21:21,663] [    INFO]\u001B[0m - global step 149100/156300, epoch: 47, batch: 2177, rank_id: 0, loss: 0.001830, lr: 0.0000023457, speed: 0.9406 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:23:12,324] [    INFO]\u001B[0m - global step 149200/156300, epoch: 47, batch: 2277, rank_id: 0, loss: 0.003177, lr: 0.0000023131, speed: 0.9038 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:25:03,508] [    INFO]\u001B[0m - global step 149300/156300, epoch: 47, batch: 2377, rank_id: 0, loss: 0.001033, lr: 0.0000022804, speed: 0.8995 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:26:54,044] [    INFO]\u001B[0m - global step 149400/156300, epoch: 47, batch: 2477, rank_id: 0, loss: 0.003566, lr: 0.0000022478, speed: 0.9048 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:28:48,634] [    INFO]\u001B[0m - global step 149500/156300, epoch: 47, batch: 2577, rank_id: 0, loss: 0.004149, lr: 0.0000022151, speed: 0.8728 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:30:45,217] [    INFO]\u001B[0m - global step 149600/156300, epoch: 47, batch: 2677, rank_id: 0, loss: 0.003213, lr: 0.0000021825, speed: 0.8579 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:32:33,924] [    INFO]\u001B[0m - global step 149700/156300, epoch: 47, batch: 2777, rank_id: 0, loss: 0.001023, lr: 0.0000021498, speed: 0.9200 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:34:24,567] [    INFO]\u001B[0m - global step 149800/156300, epoch: 47, batch: 2877, rank_id: 0, loss: 0.002135, lr: 0.0000021172, speed: 0.9039 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:36:14,959] [    INFO]\u001B[0m - global step 149900/156300, epoch: 47, batch: 2977, rank_id: 0, loss: 0.002191, lr: 0.0000020846, speed: 0.9060 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:38:05,884] [    INFO]\u001B[0m - global step 150000/156300, epoch: 47, batch: 3077, rank_id: 0, loss: 0.001208, lr: 0.0000020519, speed: 0.9016 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:38:16,694] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:38:16,695] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:40:05,669] [    INFO]\u001B[0m - global step 150100/156300, epoch: 48, batch: 51, rank_id: 0, loss: 0.001293, lr: 0.0000020193, speed: 0.8349 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:41:55,564] [    INFO]\u001B[0m - global step 150200/156300, epoch: 48, batch: 151, rank_id: 0, loss: 0.002579, lr: 0.0000019866, speed: 0.9101 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:43:49,727] [    INFO]\u001B[0m - global step 150300/156300, epoch: 48, batch: 251, rank_id: 0, loss: 0.004210, lr: 0.0000019540, speed: 0.8761 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:45:43,826] [    INFO]\u001B[0m - global step 150400/156300, epoch: 48, batch: 351, rank_id: 0, loss: 0.003383, lr: 0.0000019213, speed: 0.8765 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:47:33,127] [    INFO]\u001B[0m - global step 150500/156300, epoch: 48, batch: 451, rank_id: 0, loss: 0.001850, lr: 0.0000018887, speed: 0.9150 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:49:20,797] [    INFO]\u001B[0m - global step 150600/156300, epoch: 48, batch: 551, rank_id: 0, loss: 0.007061, lr: 0.0000018561, speed: 0.9289 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:51:11,779] [    INFO]\u001B[0m - global step 150700/156300, epoch: 48, batch: 651, rank_id: 0, loss: 0.006862, lr: 0.0000018234, speed: 0.9012 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:53:02,260] [    INFO]\u001B[0m - global step 150800/156300, epoch: 48, batch: 751, rank_id: 0, loss: 0.001670, lr: 0.0000017908, speed: 0.9053 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 20:54:54,465] [    INFO]\u001B[0m - global step 150900/156300, epoch: 48, batch: 851, rank_id: 0, loss: 0.001876, lr: 0.0000017581, speed: 0.8914 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:56:44,618] [    INFO]\u001B[0m - global step 151000/156300, epoch: 48, batch: 951, rank_id: 0, loss: 0.007644, lr: 0.0000017255, speed: 0.9080 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 20:58:36,792] [    INFO]\u001B[0m - global step 151100/156300, epoch: 48, batch: 1051, rank_id: 0, loss: 0.005407, lr: 0.0000016928, speed: 0.8916 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:00:28,134] [    INFO]\u001B[0m - global step 151200/156300, epoch: 48, batch: 1151, rank_id: 0, loss: 0.011273, lr: 0.0000016602, speed: 0.8983 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:02:22,348] [    INFO]\u001B[0m - global step 151300/156300, epoch: 48, batch: 1251, rank_id: 0, loss: 0.001919, lr: 0.0000016276, speed: 0.8757 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:04:12,508] [    INFO]\u001B[0m - global step 151400/156300, epoch: 48, batch: 1351, rank_id: 0, loss: 0.002378, lr: 0.0000015949, speed: 0.9079 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:06:00,817] [    INFO]\u001B[0m - global step 151500/156300, epoch: 48, batch: 1451, rank_id: 0, loss: 0.001477, lr: 0.0000015623, speed: 0.9234 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:07:50,103] [    INFO]\u001B[0m - global step 151600/156300, epoch: 48, batch: 1551, rank_id: 0, loss: 0.007910, lr: 0.0000015296, speed: 0.9152 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:09:40,099] [    INFO]\u001B[0m - global step 151700/156300, epoch: 48, batch: 1651, rank_id: 0, loss: 0.001685, lr: 0.0000014970, speed: 0.9093 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:11:33,343] [    INFO]\u001B[0m - global step 151800/156300, epoch: 48, batch: 1751, rank_id: 0, loss: 0.003894, lr: 0.0000014643, speed: 0.8832 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:13:22,268] [    INFO]\u001B[0m - global step 151900/156300, epoch: 48, batch: 1851, rank_id: 0, loss: 0.001963, lr: 0.0000014317, speed: 0.9182 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:15:13,831] [    INFO]\u001B[0m - global step 152000/156300, epoch: 48, batch: 1951, rank_id: 0, loss: 0.003261, lr: 0.0000013991, speed: 0.8965 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:17:01,803] [    INFO]\u001B[0m - global step 152100/156300, epoch: 48, batch: 2051, rank_id: 0, loss: 0.002170, lr: 0.0000013664, speed: 0.9263 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:18:49,270] [    INFO]\u001B[0m - global step 152200/156300, epoch: 48, batch: 2151, rank_id: 0, loss: 0.001673, lr: 0.0000013338, speed: 0.9307 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:20:41,303] [    INFO]\u001B[0m - global step 152300/156300, epoch: 48, batch: 2251, rank_id: 0, loss: 0.004500, lr: 0.0000013011, speed: 0.8927 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:22:30,612] [    INFO]\u001B[0m - global step 152400/156300, epoch: 48, batch: 2351, rank_id: 0, loss: 0.004822, lr: 0.0000012685, speed: 0.9150 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:24:21,626] [    INFO]\u001B[0m - global step 152500/156300, epoch: 48, batch: 2451, rank_id: 0, loss: 0.000897, lr: 0.0000012358, speed: 0.9009 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:26:17,366] [    INFO]\u001B[0m - global step 152600/156300, epoch: 48, batch: 2551, rank_id: 0, loss: 0.006847, lr: 0.0000012032, speed: 0.8641 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:28:14,004] [    INFO]\u001B[0m - global step 152700/156300, epoch: 48, batch: 2651, rank_id: 0, loss: 0.001574, lr: 0.0000011706, speed: 0.8575 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:30:00,920] [    INFO]\u001B[0m - global step 152800/156300, epoch: 48, batch: 2751, rank_id: 0, loss: 0.001360, lr: 0.0000011379, speed: 0.9355 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:31:53,778] [    INFO]\u001B[0m - global step 152900/156300, epoch: 48, batch: 2851, rank_id: 0, loss: 0.006133, lr: 0.0000011053, speed: 0.8862 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:33:43,084] [    INFO]\u001B[0m - global step 153000/156300, epoch: 48, batch: 2951, rank_id: 0, loss: 0.000701, lr: 0.0000010726, speed: 0.9150 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:35:33,016] [    INFO]\u001B[0m - global step 153100/156300, epoch: 48, batch: 3051, rank_id: 0, loss: 0.004803, lr: 0.0000010400, speed: 0.9098 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:37:22,465] [    INFO]\u001B[0m - global step 153200/156300, epoch: 49, batch: 25, rank_id: 0, loss: 0.002603, lr: 0.0000010074, speed: 0.9138 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:39:12,324] [    INFO]\u001B[0m - global step 153300/156300, epoch: 49, batch: 125, rank_id: 0, loss: 0.003242, lr: 0.0000009747, speed: 0.9104 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:41:03,802] [    INFO]\u001B[0m - global step 153400/156300, epoch: 49, batch: 225, rank_id: 0, loss: 0.001157, lr: 0.0000009421, speed: 0.8972 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:42:58,719] [    INFO]\u001B[0m - global step 153500/156300, epoch: 49, batch: 325, rank_id: 0, loss: 0.001587, lr: 0.0000009094, speed: 0.8703 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:44:48,955] [    INFO]\u001B[0m - global step 153600/156300, epoch: 49, batch: 425, rank_id: 0, loss: 0.004316, lr: 0.0000008768, speed: 0.9073 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:46:36,024] [    INFO]\u001B[0m - global step 153700/156300, epoch: 49, batch: 525, rank_id: 0, loss: 0.001632, lr: 0.0000008441, speed: 0.9341 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:48:27,544] [    INFO]\u001B[0m - global step 153800/156300, epoch: 49, batch: 625, rank_id: 0, loss: 0.002408, lr: 0.0000008115, speed: 0.8968 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:50:17,447] [    INFO]\u001B[0m - global step 153900/156300, epoch: 49, batch: 725, rank_id: 0, loss: 0.001727, lr: 0.0000007789, speed: 0.9100 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:52:08,221] [    INFO]\u001B[0m - global step 154000/156300, epoch: 49, batch: 825, rank_id: 0, loss: 0.001915, lr: 0.0000007462, speed: 0.9029 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:54:00,410] [    INFO]\u001B[0m - global step 154100/156300, epoch: 49, batch: 925, rank_id: 0, loss: 0.004521, lr: 0.0000007136, speed: 0.8915 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:55:51,162] [    INFO]\u001B[0m - global step 154200/156300, epoch: 49, batch: 1025, rank_id: 0, loss: 0.002916, lr: 0.0000006809, speed: 0.9030 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:57:41,320] [    INFO]\u001B[0m - global step 154300/156300, epoch: 49, batch: 1125, rank_id: 0, loss: 0.003554, lr: 0.0000006483, speed: 0.9079 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 21:59:34,682] [    INFO]\u001B[0m - global step 154400/156300, epoch: 49, batch: 1225, rank_id: 0, loss: 0.001884, lr: 0.0000006156, speed: 0.8823 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:01:29,315] [    INFO]\u001B[0m - global step 154500/156300, epoch: 49, batch: 1325, rank_id: 0, loss: 0.001573, lr: 0.0000005830, speed: 0.8725 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:03:15,522] [    INFO]\u001B[0m - global step 154600/156300, epoch: 49, batch: 1425, rank_id: 0, loss: 0.001627, lr: 0.0000005504, speed: 0.9417 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:05:06,031] [    INFO]\u001B[0m - global step 154700/156300, epoch: 49, batch: 1525, rank_id: 0, loss: 0.001261, lr: 0.0000005177, speed: 0.9050 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:06:54,912] [    INFO]\u001B[0m - global step 154800/156300, epoch: 49, batch: 1625, rank_id: 0, loss: 0.002199, lr: 0.0000004851, speed: 0.9186 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:08:47,285] [    INFO]\u001B[0m - global step 154900/156300, epoch: 49, batch: 1725, rank_id: 0, loss: 0.002518, lr: 0.0000004524, speed: 0.8900 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:10:37,380] [    INFO]\u001B[0m - global step 155000/156300, epoch: 49, batch: 1825, rank_id: 0, loss: 0.000690, lr: 0.0000004198, speed: 0.9084 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:12:27,585] [    INFO]\u001B[0m - global step 155100/156300, epoch: 49, batch: 1925, rank_id: 0, loss: 0.000823, lr: 0.0000003871, speed: 0.9075 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:14:16,672] [    INFO]\u001B[0m - global step 155200/156300, epoch: 49, batch: 2025, rank_id: 0, loss: 0.003326, lr: 0.0000003545, speed: 0.9168 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:16:06,337] [    INFO]\u001B[0m - global step 155300/156300, epoch: 49, batch: 2125, rank_id: 0, loss: 0.008324, lr: 0.0000003219, speed: 0.9120 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:17:55,365] [    INFO]\u001B[0m - global step 155400/156300, epoch: 49, batch: 2225, rank_id: 0, loss: 0.001225, lr: 0.0000002892, speed: 0.9173 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:19:44,121] [    INFO]\u001B[0m - global step 155500/156300, epoch: 49, batch: 2325, rank_id: 0, loss: 0.002304, lr: 0.0000002566, speed: 0.9196 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:21:35,072] [    INFO]\u001B[0m - global step 155600/156300, epoch: 49, batch: 2425, rank_id: 0, loss: 0.002479, lr: 0.0000002239, speed: 0.9014 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:23:28,987] [    INFO]\u001B[0m - global step 155700/156300, epoch: 49, batch: 2525, rank_id: 0, loss: 0.004000, lr: 0.0000001913, speed: 0.8780 step/s\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-07 22:25:26,612] [    INFO]\u001B[0m - global step 155800/156300, epoch: 49, batch: 2625, rank_id: 0, loss: 0.001987, lr: 0.0000001586, speed: 0.8503 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:27:15,174] [    INFO]\u001B[0m - global step 155900/156300, epoch: 49, batch: 2725, rank_id: 0, loss: 0.001197, lr: 0.0000001260, speed: 0.9213 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:29:08,297] [    INFO]\u001B[0m - global step 156000/156300, epoch: 49, batch: 2825, rank_id: 0, loss: 0.002396, lr: 0.0000000934, speed: 0.8841 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:30:56,250] [    INFO]\u001B[0m - global step 156100/156300, epoch: 49, batch: 2925, rank_id: 0, loss: 0.001298, lr: 0.0000000607, speed: 0.9265 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:32:48,262] [    INFO]\u001B[0m - global step 156200/156300, epoch: 49, batch: 3025, rank_id: 0, loss: 0.001472, lr: 0.0000000281, speed: 0.8929 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:34:37,264] [    INFO]\u001B[0m - global step 156300/156300, epoch: 49, batch: 3125, rank_id: 0, loss: 0.000058, lr: 0.0000000000, speed: 0.9175 step/s\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:34:48,029] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-07 22:34:48,031] [    INFO]\u001B[0m - Special tokens file saved in checkpoints/special_tokens_map.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 调用\n",
    "# 模型训练\n",
    "train(model, train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained('checkpoints')\n",
    "model.eval()\n",
    "tokenizer = PegasusChineseTokenizer.from_pretrained('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 4\n",
    "def infer(text, model, tokenizer):\n",
    "    tokenized = tokenizer(text, \n",
    "                          truncation=True, \n",
    "                          max_length=max_source_length, \n",
    "                          return_tensors='pd')\n",
    "    preds, _ = model.generate(input_ids=tokenized['input_ids'],\n",
    "                              max_length=160,\n",
    "                              min_length=min_target_length,\n",
    "                              decode_strategy='beam_search',\n",
    "                              num_beams=num_beams)\n",
    "    return(tokenizer.decode(preds[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001</td>\n",
       "      <td>客:个我刚收到们个话费通知的短信我看说我上个月消费二十一块多吧有五元是我的包月费剩下有16块...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25002</td>\n",
       "      <td>客:个先说个不太好意思今天不是我之前投诉不是个扣费的问题，个今天今天应该给我反馈回来有服务电...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25003</td>\n",
       "      <td>客:个我套餐到期没人通知我原来是138块6的现在它我这刚发现现在是按198坐:帮查来电手机号...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25004</td>\n",
       "      <td>客:我想问我个话费现在欠坐:来电这号码欠费钱是坐:行号码现在欠费2月份的165.75165....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25005</td>\n",
       "      <td>客:你帮我查我有业务是返返钱的业务一放1月份的给我返个九十九十九月好像还能返28你帮我看客:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            content\n",
       "0  25001  客:个我刚收到们个话费通知的短信我看说我上个月消费二十一块多吧有五元是我的包月费剩下有16块...\n",
       "1  25002  客:个先说个不太好意思今天不是我之前投诉不是个扣费的问题，个今天今天应该给我反馈回来有服务电...\n",
       "2  25003  客:个我套餐到期没人通知我原来是138块6的现在它我这刚发现现在是按198坐:帮查来电手机号...\n",
       "3  25004  客:我想问我个话费现在欠坐:来电这号码欠费钱是坐:行号码现在欠费2月份的165.75165....\n",
       "4  25005  客:你帮我查我有业务是返返钱的业务一放1月份的给我返个九十九十九月好像还能返28你帮我看客:..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_file='./process_data_62/test_data.csv'\n",
    "validation_data=pd.read_csv(validation_file,encoding='utf-8',sep='|',header=0)\n",
    "text=validation_data.iat[0,1]\n",
    "validation_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7522.000000\n",
       "mean      421.702340\n",
       "std       120.174324\n",
       "min        15.000000\n",
       "25%       334.000000\n",
       "50%       512.000000\n",
       "75%       512.000000\n",
       "max       513.000000\n",
       "Name: content, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data['content'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'用户来电对01月产生的15.93元的流量费有疑义，我方经系统查询安上网日志向用户解释，用户不认可，我方按快速处理向用户核减费用，用户不认可要求核实原因，请处理，谢谢。'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(filename,num=2):\n",
    "    lines = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        next(f)\n",
    "        if num==3:\n",
    "            for line in f:\n",
    "                lines.append({\"id\":line.split(\"|\")[0].strip(),\"content\":line.split(\"|\")[1].strip(),\"abstract\":line.split(\"|\")[2].strip()})\n",
    "        else:\n",
    "            for line in f:\n",
    "                lines.append({\"id\":line.split(\"|\")[0].strip(),\"content\":line.split(\"|\")[1].strip()})\n",
    "    return lines\n",
    "infer(text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_lines=read_file(validation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '25001',\n",
       " 'content': '客:个我刚收到们个话费通知的短信我看说我上个月消费二十一块多吧有五元是我的包月费剩下有16块多的个的消费我没有进行过何的上网通话的我想查查个什费用坐:我看1月二十一块8上网流量费15块9毛3国内通话费0.15元到达电话打一分钟流量应该是超出一部分用15块9毛3的流量费客:对我肯定没有用流量我是退休在家我家里有WIFI我不出去玩一星之前我刚激活根本连买菜都不用我出去流量是怎出来的钱这肯定有积分问题坐:用五十五十九兆流量扣19块15块9毛7的费用客:59兆流量六块钱坐:电话对流量超出不认可给进行上报反馈后期会有专人给回电处理客:他最后给我回电怎处理，我要求这返返费我肯定没消费说电话电话有过，电话我没打过我家里人没用我电话打过每个人都有手续坐:现在无法给进行核实只能看到使用的超出是没有使用我给记录上报后期会有专人给客:你给我上报余额实际话费反正就这15块几吧我肯定没花点钱我肯定要交的我绝对没用过我就没出过门激活坐:好我给记录上报后期会有专人给回复保持电话畅通客:直接就给我发短信坐:24小时你回复电话坐:感谢来电稍后按两个一谢谢'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据生成进行中，当前进行ID： 25001\n",
      "数据生成进行中，当前进行ID： 25002\n",
      "数据生成进行中，当前进行ID： 25003\n",
      "数据生成进行中，当前进行ID： 25004\n",
      "数据生成进行中，当前进行ID： 25005\n",
      "数据生成进行中，当前进行ID： 25006\n",
      "数据生成进行中，当前进行ID： 25100\n",
      "数据生成进行中，当前进行ID： 25200\n",
      "数据生成进行中，当前进行ID： 25300\n",
      "数据生成进行中，当前进行ID： 25400\n",
      "数据生成进行中，当前进行ID： 25500\n",
      "数据生成进行中，当前进行ID： 25600\n",
      "数据生成进行中，当前进行ID： 25700\n",
      "数据生成进行中，当前进行ID： 25800\n",
      "数据生成进行中，当前进行ID： 25900\n",
      "数据生成进行中，当前进行ID： 26000\n",
      "数据生成进行中，当前进行ID： 26100\n",
      "数据生成进行中，当前进行ID： 26200\n",
      "数据生成进行中，当前进行ID： 26300\n",
      "数据生成进行中，当前进行ID： 26400\n",
      "数据生成进行中，当前进行ID： 26500\n",
      "数据生成进行中，当前进行ID： 26600\n",
      "数据生成进行中，当前进行ID： 26700\n",
      "数据生成进行中，当前进行ID： 26800\n",
      "数据生成进行中，当前进行ID： 26900\n",
      "数据生成进行中，当前进行ID： 27000\n",
      "数据生成进行中，当前进行ID： 27100\n",
      "数据生成进行中，当前进行ID： 27200\n",
      "数据生成进行中，当前进行ID： 27300\n",
      "数据生成进行中，当前进行ID： 27400\n",
      "数据生成进行中，当前进行ID： 27500\n",
      "数据生成进行中，当前进行ID： 27600\n",
      "数据生成进行中，当前进行ID： 27700\n",
      "数据生成进行中，当前进行ID： 27800\n",
      "数据生成进行中，当前进行ID： 27900\n",
      "数据生成进行中，当前进行ID： 28000\n",
      "数据生成进行中，当前进行ID： 28100\n",
      "数据生成进行中，当前进行ID： 28200\n",
      "数据生成进行中，当前进行ID： 28300\n",
      "数据生成进行中，当前进行ID： 28400\n",
      "数据生成进行中，当前进行ID： 28500\n",
      "数据生成进行中，当前进行ID： 28600\n",
      "数据生成进行中，当前进行ID： 28700\n",
      "数据生成进行中，当前进行ID： 28800\n",
      "数据生成进行中，当前进行ID： 28900\n",
      "数据生成进行中，当前进行ID： 29000\n",
      "数据生成进行中，当前进行ID： 29100\n",
      "数据生成进行中，当前进行ID： 29200\n",
      "数据生成进行中，当前进行ID： 29300\n",
      "数据生成进行中，当前进行ID： 29400\n",
      "数据生成进行中，当前进行ID： 29500\n",
      "数据生成进行中，当前进行ID： 29600\n",
      "数据生成进行中，当前进行ID： 29700\n",
      "数据生成进行中，当前进行ID： 29800\n",
      "数据生成进行中，当前进行ID： 29900\n",
      "数据生成进行中，当前进行ID： 30000\n",
      "数据生成进行中，当前进行ID： 30100\n",
      "数据生成进行中，当前进行ID： 30200\n",
      "数据生成进行中，当前进行ID： 30300\n",
      "数据生成进行中，当前进行ID： 30400\n",
      "数据生成进行中，当前进行ID： 30500\n",
      "数据生成进行中，当前进行ID： 30600\n",
      "数据生成进行中，当前进行ID： 30700\n",
      "数据生成进行中，当前进行ID： 30800\n",
      "数据生成进行中，当前进行ID： 30900\n",
      "数据生成进行中，当前进行ID： 31000\n",
      "数据生成进行中，当前进行ID： 31100\n",
      "数据生成进行中，当前进行ID： 31200\n",
      "数据生成进行中，当前进行ID： 31300\n",
      "数据生成进行中，当前进行ID： 31400\n",
      "数据生成进行中，当前进行ID： 31500\n",
      "数据生成进行中，当前进行ID： 31700\n",
      "数据生成进行中，当前进行ID： 31800\n",
      "数据生成进行中，当前进行ID： 31900\n",
      "数据生成进行中，当前进行ID： 32000\n",
      "数据生成进行中，当前进行ID： 32100\n",
      "数据生成进行中，当前进行ID： 32200\n",
      "数据生成进行中，当前进行ID： 32300\n",
      "数据生成进行中，当前进行ID： 32400\n",
      "数据生成进行中，当前进行ID： 32500\n"
     ]
    }
   ],
   "source": [
    "result_data=pd.DataFrame()\n",
    "idx = 0\n",
    "for line in validation_lines:\n",
    "    idx +=1\n",
    "    validation_id=line['id']\n",
    "    content=line['content']\n",
    "    ret=infer(content,model, tokenizer)\n",
    "    result={\"id\":validation_id,\"ret\":ret}\n",
    "    result_data=result_data._append(result,ignore_index=True)\n",
    "    if idx % 100 == 0 or idx in [1,2,3,4,5,6]:\n",
    "        print(\"数据生成进行中，当前进行ID：\",validation_id)\n",
    "result_data.to_csv('result.csv',  index=False,encoding='utf-8',sep ='|',header =['id','ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/\n",
      "checkpoints/model_config.json\n",
      "checkpoints/vocab.txt\n",
      "checkpoints/model_state.pdparams\n",
      "checkpoints/tokenizer_config.json\n",
      "checkpoints/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "!tar -cvf checkpoints64.tar checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
