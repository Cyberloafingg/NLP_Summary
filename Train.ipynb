{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "运行环境：\n",
    "CPU：Intel® Xeon® E5-2680 v4 CPU，主频2.4GHz\n",
    "GPU：NVIDIA® Tesla® P40（12TFLOPS 单精度浮点计算，47INT8 TOPS）\n",
    "内存：DDR4，2666MT/s。\n",
    "操作系统：Linux Ubuntu 18.04 LTS\n",
    "CUDA 11.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\paddle\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from rouge import Rouge\n",
    "from visualdl import LogWriter\n",
    "\n",
    "from paddlenlp.transformers import PegasusForConditionalGeneration, PegasusChineseTokenizer\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import DataCollatorForSeq2Seq\n",
    "from paddlenlp.utils.log import logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    24992.000000\nmean       419.802937\nstd        121.761374\nmin         11.000000\n25%        330.000000\n50%        512.000000\n75%        512.000000\nmax        513.000000\nName: content, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './proceed/train_data_all.csv'\n",
    "data=pd.read_csv(data_path,encoding='utf-8',sep='|')\n",
    "data['content'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 构造训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sklearn.utils.shuffle(data) #随机打乱\n",
    "train_data = df.sample(frac=0.9, random_state=0, axis=0)\n",
    "dev_data = df.drop(train_data.index)\n",
    "# train_data = train_data[0:100]\n",
    "# dev_data = dev_data[0:3]\n",
    "train_data_path = './proceed/train_data.csv'\n",
    "dev_data_path = './proceed/dev_data.csv'\n",
    "# #将训练数据写入到文件中\n",
    "train_data.to_csv(train_data_path,  index=False,encoding='utf-8',sep ='|',header =['id','content','abstract'])\n",
    "# #将测试数据写入文件中\n",
    "dev_data.to_csv(dev_data_path,  index=False,encoding='utf-8',sep ='|',header =['id','content','abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================train===============\n",
      "count    22493.000000\n",
      "mean       419.906282\n",
      "std        121.895025\n",
      "min         11.000000\n",
      "25%        330.000000\n",
      "50%        512.000000\n",
      "75%        512.000000\n",
      "max        513.000000\n",
      "Name: content, dtype: float64\n",
      "=================dev=================\n",
      "count    2499.000000\n",
      "mean      418.872749\n",
      "std       120.571935\n",
      "min        50.000000\n",
      "25%       330.000000\n",
      "50%       512.000000\n",
      "75%       512.000000\n",
      "max       513.000000\n",
      "Name: content, dtype: float64\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "print(\"================train===============\")\n",
    "print(train_data['content'].str.len().describe())\n",
    "print(\"=================dev=================\")\n",
    "print(dev_data['content'].str.len().describe())\n",
    "print(\"====================================\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 参数配置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONTENT_LENGTH = 512\n",
    "MAX_ABSTRACT_LENGTH = 160\n",
    "MIN_CONTENT_LENGTH = 0\n",
    "MIN_ABSTRACT_LENGTH = 0\n",
    "BATCH_SIZE = 8 # 8\n",
    "WARMUP_RATIO = 0.02\n",
    "LR_RATE = 5e-5\n",
    "EPOCHS_NUM =50 # 50\n",
    "LOG_STEP = 2000 # 2000\n",
    "SSTIA_RATIO = 0.5 # 0.5\n",
    "USE_SSTIA = True\n",
    "NUM_BEAM = 4\n",
    "ROUGE_METRIC_NAME = ['rouge-1', 'rouge-2', 'rouge-l']\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "LOG_WRITER = LogWriter('visualdl_log_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 构造dataloader与加载预训练模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22501\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "def read_from_csv(data_path):\n",
    "    data=pd.read_csv(data_path,encoding='utf-8',sep='|')\n",
    "    for index, row in data.iterrows():\n",
    "        content, abstract = row['content'],row['abstract']\n",
    "        yield {'content': content, 'abstract': abstract}\n",
    "def read_from_csv(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            content, abstract = line.strip('\\t').split(\"|\")[1].strip(),line.strip('\\t').split(\"|\")[2].strip()\n",
    "            yield {'content': content, 'abstract': abstract}\n",
    "train_dataset  = load_dataset(read_from_csv, data_path=train_data_path, lazy=False, split=\"train\")\n",
    "dev_dataset  = load_dataset(read_from_csv, data_path=dev_data_path, lazy=False, split=\"dev\")\n",
    "print(len(train_dataset))\n",
    "print(len(dev_dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-11 03:21:39,465] [    INFO]\u001B[0m - Already cached C:\\Users\\cyberloafing\\.paddlenlp\\models\\IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\vocab.txt\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:21:39,466] [    INFO]\u001B[0m - Already cached C:\\Users\\cyberloafing\\.paddlenlp\\models\\IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\added_tokens.json\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:21:39,467] [    INFO]\u001B[0m - Already cached C:\\Users\\cyberloafing\\.paddlenlp\\models\\IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:21:39,468] [    INFO]\u001B[0m - Already cached C:\\Users\\cyberloafing\\.paddlenlp\\models\\IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:21:39,515] [    INFO]\u001B[0m - Already cached C:\\Users\\cyberloafing\\.paddlenlp\\models\\IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:21:39,516] [    INFO]\u001B[0m - Already cached C:\\Users\\cyberloafing\\.paddlenlp\\models\\IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\\model_config.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 加载Toleknizer\n",
    "tokenizer = PegasusChineseTokenizer.from_pretrained('IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese')\n",
    "# 加载预训练模型\n",
    "model = PegasusForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese')\n",
    "# 设置数据收集器\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def tokenize_input(example,\n",
    "                   content_name,\n",
    "                   abstract_name,\n",
    "                   tokenizer,\n",
    "                   max_content_length,\n",
    "                   max_abstract_length):\n",
    "    \"\"\"\n",
    "    将输入的example中的content和abstract转换为id，并构造labels\n",
    "    :arg example: 一个样本，包含content和abstract\n",
    "    :arg content_name: content的key\n",
    "    :arg abstract_name: abstract的key\n",
    "    :arg tokenizer: 分词器\n",
    "    :arg max_content_length: content的最大长度\n",
    "    :arg max_abstract_length: abstract的最大长度\n",
    "    :return: 返token后的input\n",
    "    \"\"\"\n",
    "    inputs,targets = example[content_name],example[abstract_name]\n",
    "    tokened_inputs = tokenizer(inputs,\n",
    "                             max_length=max_content_length,\n",
    "                             padding=False,\n",
    "                             truncation=True,\n",
    "                             return_attention_mask=True)\n",
    "    tokened_labels = tokenizer(targets,\n",
    "                       max_length=max_abstract_length,\n",
    "                       padding=False,\n",
    "                       truncation=True)\n",
    "    # 把token后的【label】换为【input_ids】\n",
    "    tokened_inputs[\"labels\"] = tokened_labels[\"input_ids\"]\n",
    "    return tokened_inputs\n",
    "packed_tokened_fn = partial(tokenize_input,\n",
    "                            content_name='content',\n",
    "                            abstract_name='abstract',\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_content_length=MAX_CONTENT_LENGTH,\n",
    "                            max_abstract_length=MAX_ABSTRACT_LENGTH)\n",
    "# train_dataset和dev_dataset分别转换\n",
    "train_dataset = train_dataset.map(packed_tokened_fn,batched=False,lazy =False)\n",
    "dev_dataset = dev_dataset.map(packed_tokened_fn,batched=False,lazy =False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1117, 131, 15214, 1909, 2274, 11447, 28537, 3399, 4054, 13048, 30521, 5661, 1266, 43766, 1909, 827, 6948, 3399, 30521, 1117, 131, 1266, 5219, 2251, 5230, 200, 30521, 1477, 200, 18820, 2335, 33335, 541, 28527, 10144, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [25416, 21704, 3624, 28967, 2335, 7257, 28537, 12695, 5661, 32425, 18739, 1735, 430, 8214, 8220, 266, 5661, 5034, 8177, 28967, 115, 115, 115, 115, 115, 115, 115, 115, 12695, 266, 5661, 6250, 8214, 35160, 119, 25416, 30255, 32248, 28967, 35108, 501, 3399, 30698, 5661, 4659, 12942, 11712, 14290, 5661, 30952, 179, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader  = paddle.io.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,return_list=True,collate_fn=data_collator)\n",
    "dev_batch_sampler  = BatchSampler(dataset=dev_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
    "dev_data_loader = DataLoader(dataset=dev_dataset,batch_sampler=dev_batch_sampler,collate_fn=data_collator,return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 PEGASUS类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class PEGASUS():\n",
    "    def __init__(self, model, tokenizer,train_data_loader,dev_data_loader):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lr_rate = LR_RATE\n",
    "        self.checkpoint_dir = CHECKPOINT_DIR\n",
    "        self.global_step = 0\n",
    "        self.best_rouge = 0\n",
    "        self.eval_steps = 20000\n",
    "        self.lr_scheduler = LinearDecayWithWarmup(self.lr_rate, self.eval_steps, 0.1)\n",
    "        self.decay_params = [\n",
    "            p.name for n, p in self.model.named_parameters()\n",
    "            if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "        ]\n",
    "        self.optimizer = paddle.optimizer.AdamW(\n",
    "            learning_rate=self.lr_scheduler,\n",
    "            beta1=0.9,\n",
    "            beta2=0.999,\n",
    "            epsilon=1e-6,\n",
    "            parameters=self.model.parameters(),\n",
    "            weight_decay=0.01,\n",
    "            apply_decay_param_fun=lambda x: x in self.decay_params)\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.dev_data_loader = dev_data_loader\n",
    "        self.num_steps = len(self.train_data_loader) * EPOCHS_NUM\n",
    "        self.model.use_SSTIA = USE_SSTIA\n",
    "        self.model.mix_ratio = SSTIA_RATIO\n",
    "        self.train_time = time.time()\n",
    "        self.eval_time = time.time()\n",
    "        self.mode = 'train_and_eval'\n",
    "\n",
    "    def train_and_eval(self):\n",
    "        if self.mode != 'train_and_eval':\n",
    "            self.mode = 'train_and_eval'\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(f\"  Num examples = {len(self.train_data_loader.dataset)}\")\n",
    "        logger.info(f\"  Num Epochs = {EPOCHS_NUM}\")\n",
    "        logger.info(f\"  Instantaneous batch size per GPU = {BATCH_SIZE}\")\n",
    "        logger.info(f\"  Total num training steps = {self.num_steps}\")\n",
    "        for epoch in range(EPOCHS_NUM):\n",
    "            for step, batch in enumerate(self.train_data_loader):\n",
    "                self.global_step += 1\n",
    "                lm_logits, _, loss = self.model(**batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.lr_scheduler.step()\n",
    "                self.optimizer.clear_grad()\n",
    "                if self.global_step % LOG_STEP == 0:\n",
    "                    logger.info(f\"【step {self.global_step}, \"\n",
    "                                f\"epoch: {epoch}, \"\n",
    "                                f\"batch: {step}, \"\n",
    "                                f\"loss: {round(float(loss),5)}, \"\n",
    "                                f\"lr: {self.optimizer.get_lr()}, \"\n",
    "                                f\"speed: {round(LOG_STEP / (time.time() - self.train_time),4)}step/s】\")\n",
    "                    LOG_WRITER.add_scalar(\"train_loss\", loss.numpy(), self.global_step)\n",
    "                    self.train_time = time.time()\n",
    "                # 为了节约时间，间隔一定时间进行验证\n",
    "                if self.global_step % self.eval_steps == 5 or \\\n",
    "                        self.global_step == self.num_steps or \\\n",
    "                        self.global_step in [1000,6000,10000]:\n",
    "                    self.eval()\n",
    "        logger.info(\"***** Finish training *****\")\n",
    "    @paddle.no_grad()\n",
    "    def eval(self):\n",
    "        self.model.eval() # 评估模式\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        self.model = self.model._layers if isinstance(self.model, paddle.DataParallel) else self.model\n",
    "        for batch in tqdm(self.dev_data_loader, total=len(self.dev_data_loader), desc=\"Evaluation:\"):\n",
    "            labels = batch.pop('labels').numpy()\n",
    "            preds = self.model.generate(input_ids=batch['input_ids'],\n",
    "                                   attention_mask=batch['attention_mask'],\n",
    "                                   min_length=MIN_ABSTRACT_LENGTH,\n",
    "                                   max_length=MAX_ABSTRACT_LENGTH,\n",
    "                                   # 验证时采用贪婪搜索，可以节约一些搜索时间\n",
    "                                   decode_strategy='greedy_search',\n",
    "                                   use_cache=True)[0]\n",
    "            # tokenizer还原文本\n",
    "            all_preds.extend(\n",
    "                tokenizer.batch_decode(preds.numpy(),\n",
    "                                       skip_special_tokens=True,\n",
    "                                       clean_up_tokenization_spaces=False\n",
    "                                       )\n",
    "            )\n",
    "            # 将-100替换为pad_token_id\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            all_labels.extend(\n",
    "                tokenizer.batch_decode(labels,\n",
    "                                       skip_special_tokens=True,\n",
    "                                       clean_up_tokenization_spaces=False)\n",
    "            )\n",
    "        rouge1, rouge2, rougel= self.rouge_metrics(all_preds, all_labels)\n",
    "        logger.info(\"eval done total : %s s\" % (time.time() - self.eval_time))\n",
    "        logger.info(f\"Eval use time: {time.time() - self.eval_time} s\")\n",
    "        LOG_WRITER.add_scalar(\"eval_rouge1\", rouge1, self.global_step)\n",
    "        LOG_WRITER.add_scalar(\"eval_rouge2\", rouge2, self.global_step)\n",
    "        LOG_WRITER.add_scalar(\"eval_rougel\", rougel, self.global_step)\n",
    "        # 根据公式计算rouge_score\n",
    "        rouge_score = rouge1 * 0.2 + rouge2 * 0.4 + rougel * 0.4\n",
    "        LOG_WRITER.add_scalar(\"eval_rouge_score\", rouge_score, self.global_step)\n",
    "        # 保存最优模型\n",
    "        if self.best_rouge < rouge_score:\n",
    "            self.best_rouge = rouge_score\n",
    "            if paddle.distributed.get_rank() == 0:\n",
    "                if not os.path.exists(self.checkpoint_dir):\n",
    "                    os.makedirs(self.checkpoint_dir)\n",
    "                model_to_save = self.model._layers if isinstance(self.model, paddle.DataParallel) else self.model\n",
    "                model_to_save.save_pretrained(self.checkpoint_dir)\n",
    "                self.tokenizer.save_pretrained(self.checkpoint_dir)\n",
    "        self.model.train() # 恢复训练模式\n",
    "\n",
    "    def rouge_metrics(self,preds, labels):\n",
    "        rouge = Rouge()\n",
    "        scores = []\n",
    "        for pred, target in zip(preds, labels):\n",
    "            try:\n",
    "                score = rouge.get_scores(' '.join(pred), ' '.join(target))\n",
    "                for name in ROUGE_METRIC_NAME:\n",
    "                    scores.append(score[0][name]['f'])\n",
    "            except ValueError:\n",
    "                scores.append([0, 0, 0])\n",
    "        rouge1 = np.mean([i for i in scores])\n",
    "        rouge2 = np.mean([i for i in scores])\n",
    "        rougel = np.mean([i for i in scores])\n",
    "        print(f\"rouge-1: {rouge1}, rouge-2: {rouge2}, rouge-l: {rougel}\")\n",
    "        return rouge1, rouge2, rougel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEGASUS_=PEGASUS(model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        dev_data_loader=dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-11 03:27:17,985] [    INFO]\u001B[0m - ***** Running training *****\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:17,986] [    INFO]\u001B[0m -   Num examples = 100\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:17,987] [    INFO]\u001B[0m -   Num Epochs = 1\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:17,988] [    INFO]\u001B[0m -   Instantaneous batch size per GPU = 1\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:17,989] [    INFO]\u001B[0m -   Total num training steps = 100\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:18,706] [    INFO]\u001B[0m - 【step 1, epoch: 0, batch: 0, loss: 2.64153, lr: 2.5000000000000002e-08, speed: 0.8683step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:19,441] [    INFO]\u001B[0m - 【step 2, epoch: 0, batch: 1, loss: 2.45194, lr: 5.0000000000000004e-08, speed: 1.362step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:19,694] [    INFO]\u001B[0m - 【step 3, epoch: 0, batch: 2, loss: 2.3776, lr: 7.500000000000001e-08, speed: 3.9643step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:19,913] [    INFO]\u001B[0m - 【step 4, epoch: 0, batch: 3, loss: 1.97816, lr: 1.0000000000000001e-07, speed: 4.5937step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:20,076] [    INFO]\u001B[0m - 【step 5, epoch: 0, batch: 4, loss: 0.08576, lr: 1.2500000000000002e-07, speed: 6.1534step/s】\u001B[0m\n",
      "Evaluation:: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.16s/it]\n",
      "\u001B[32m[2023-06-11 03:27:26,579] [    INFO]\u001B[0m - eval done total : 9.024606227874756 s\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:26,579] [    INFO]\u001B[0m - Eval use time: 9.025106191635132 s\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1: 0.5018591494897813, rouge-2: 0.5018591494897813, rouge-l: 0.5018591494897813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-11 03:27:30,759] [    INFO]\u001B[0m - tokenizer config file saved in checkpoints\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:30,760] [    INFO]\u001B[0m - Special tokens file saved in checkpoints\\special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:31,268] [    INFO]\u001B[0m - 【step 6, epoch: 0, batch: 5, loss: 1.9518, lr: 1.5000000000000002e-07, speed: 0.0894step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:31,436] [    INFO]\u001B[0m - 【step 7, epoch: 0, batch: 6, loss: 3.08358, lr: 1.7500000000000002e-07, speed: 6.0051step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:31,608] [    INFO]\u001B[0m - 【step 8, epoch: 0, batch: 7, loss: 0.16612, lr: 2.0000000000000002e-07, speed: 5.8646step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:31,780] [    INFO]\u001B[0m - 【step 9, epoch: 0, batch: 8, loss: 0.19492, lr: 2.25e-07, speed: 5.8302step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:32,007] [    INFO]\u001B[0m - 【step 10, epoch: 0, batch: 9, loss: 3.5565, lr: 2.5000000000000004e-07, speed: 4.4336step/s】\u001B[0m\n",
      "Evaluation:: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.44s/it]\n",
      "\u001B[32m[2023-06-11 03:27:39,354] [    INFO]\u001B[0m - eval done total : 21.800416231155396 s\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:39,355] [    INFO]\u001B[0m - Eval use time: 21.801417350769043 s\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1: 0.5018591494897813, rouge-2: 0.5018591494897813, rouge-l: 0.5018591494897813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-11 03:27:39,608] [    INFO]\u001B[0m - 【step 11, epoch: 0, batch: 10, loss: 2.56964, lr: 2.75e-07, speed: 0.1316step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:39,824] [    INFO]\u001B[0m - 【step 12, epoch: 0, batch: 11, loss: 2.67115, lr: 3.0000000000000004e-07, speed: 4.6503step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:40,062] [    INFO]\u001B[0m - 【step 13, epoch: 0, batch: 12, loss: 0.35304, lr: 3.25e-07, speed: 4.2457step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:40,293] [    INFO]\u001B[0m - 【step 14, epoch: 0, batch: 13, loss: 1.41838, lr: 3.5000000000000004e-07, speed: 4.3649step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:40,520] [    INFO]\u001B[0m - 【step 15, epoch: 0, batch: 14, loss: 0.17508, lr: 3.75e-07, speed: 4.4234step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:40,735] [    INFO]\u001B[0m - 【step 16, epoch: 0, batch: 15, loss: 1.75358, lr: 4.0000000000000003e-07, speed: 4.6942step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:40,992] [    INFO]\u001B[0m - 【step 17, epoch: 0, batch: 16, loss: 3.46541, lr: 4.2500000000000006e-07, speed: 3.913step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:41,193] [    INFO]\u001B[0m - 【step 18, epoch: 0, batch: 17, loss: 2.27919, lr: 4.5e-07, speed: 4.9992step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:41,421] [    INFO]\u001B[0m - 【step 19, epoch: 0, batch: 18, loss: 2.42244, lr: 4.75e-07, speed: 4.4237step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:41,640] [    INFO]\u001B[0m - 【step 20, epoch: 0, batch: 19, loss: 3.05523, lr: 5.000000000000001e-07, speed: 4.6079step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:41,871] [    INFO]\u001B[0m - 【step 21, epoch: 0, batch: 20, loss: 3.98377, lr: 5.250000000000001e-07, speed: 4.347step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:42,075] [    INFO]\u001B[0m - 【step 22, epoch: 0, batch: 21, loss: 0.13669, lr: 5.5e-07, speed: 4.9373step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:42,291] [    INFO]\u001B[0m - 【step 23, epoch: 0, batch: 22, loss: 2.18, lr: 5.75e-07, speed: 4.6613step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:42,510] [    INFO]\u001B[0m - 【step 24, epoch: 0, batch: 23, loss: 1.83406, lr: 6.000000000000001e-07, speed: 4.607step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:42,717] [    INFO]\u001B[0m - 【step 25, epoch: 0, batch: 24, loss: 1.91529, lr: 6.25e-07, speed: 4.8774step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:42,939] [    INFO]\u001B[0m - 【step 26, epoch: 0, batch: 25, loss: 2.08455, lr: 6.5e-07, speed: 4.5549step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:43,159] [    INFO]\u001B[0m - 【step 27, epoch: 0, batch: 26, loss: 2.69218, lr: 6.75e-07, speed: 4.5761step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:43,401] [    INFO]\u001B[0m - 【step 28, epoch: 0, batch: 27, loss: 2.63857, lr: 7.000000000000001e-07, speed: 4.1659step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:43,622] [    INFO]\u001B[0m - 【step 29, epoch: 0, batch: 28, loss: 2.28638, lr: 7.25e-07, speed: 4.5549step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:43,844] [    INFO]\u001B[0m - 【step 30, epoch: 0, batch: 29, loss: 1.46642, lr: 7.5e-07, speed: 4.5454step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:44,098] [    INFO]\u001B[0m - 【step 31, epoch: 0, batch: 30, loss: 2.11995, lr: 7.75e-07, speed: 3.9515step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:44,344] [    INFO]\u001B[0m - 【step 32, epoch: 0, batch: 31, loss: 1.25614, lr: 8.000000000000001e-07, speed: 4.072step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:44,572] [    INFO]\u001B[0m - 【step 33, epoch: 0, batch: 32, loss: 2.13273, lr: 8.25e-07, speed: 4.4241step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:44,788] [    INFO]\u001B[0m - 【step 34, epoch: 0, batch: 33, loss: 2.63967, lr: 8.500000000000001e-07, speed: 4.6504step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:45,003] [    INFO]\u001B[0m - 【step 35, epoch: 0, batch: 34, loss: 1.69161, lr: 8.750000000000001e-07, speed: 4.672step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:45,222] [    INFO]\u001B[0m - 【step 36, epoch: 0, batch: 35, loss: 2.03839, lr: 9e-07, speed: 4.5963step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:45,434] [    INFO]\u001B[0m - 【step 37, epoch: 0, batch: 36, loss: 1.11458, lr: 9.25e-07, speed: 4.7386step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:45,690] [    INFO]\u001B[0m - 【step 38, epoch: 0, batch: 37, loss: 1.27595, lr: 9.5e-07, speed: 3.9365step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:45,914] [    INFO]\u001B[0m - 【step 39, epoch: 0, batch: 38, loss: 1.77235, lr: 9.75e-07, speed: 4.4935step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:46,129] [    INFO]\u001B[0m - 【step 40, epoch: 0, batch: 39, loss: 2.22977, lr: 1.0000000000000002e-06, speed: 4.6829step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:46,343] [    INFO]\u001B[0m - 【step 41, epoch: 0, batch: 40, loss: 0.58085, lr: 1.0250000000000001e-06, speed: 4.6943step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:46,561] [    INFO]\u001B[0m - 【step 42, epoch: 0, batch: 41, loss: 1.17514, lr: 1.0500000000000001e-06, speed: 4.6399step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:46,816] [    INFO]\u001B[0m - 【step 43, epoch: 0, batch: 42, loss: 1.75026, lr: 1.0749999999999999e-06, speed: 3.9439step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:47,045] [    INFO]\u001B[0m - 【step 44, epoch: 0, batch: 43, loss: 3.27946, lr: 1.1e-06, speed: 4.4145step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:47,264] [    INFO]\u001B[0m - 【step 45, epoch: 0, batch: 44, loss: 2.36532, lr: 1.125e-06, speed: 4.5971step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:47,491] [    INFO]\u001B[0m - 【step 46, epoch: 0, batch: 45, loss: 2.82636, lr: 1.15e-06, speed: 4.4336step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:47,713] [    INFO]\u001B[0m - 【step 47, epoch: 0, batch: 46, loss: 0.06192, lr: 1.175e-06, speed: 4.5239step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:47,931] [    INFO]\u001B[0m - 【step 48, epoch: 0, batch: 47, loss: 0.13093, lr: 1.2000000000000002e-06, speed: 4.6281step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:48,173] [    INFO]\u001B[0m - 【step 49, epoch: 0, batch: 48, loss: 2.15434, lr: 1.2250000000000001e-06, speed: 4.166step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:48,426] [    INFO]\u001B[0m - 【step 50, epoch: 0, batch: 49, loss: 2.55166, lr: 1.25e-06, speed: 3.9831step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:48,654] [    INFO]\u001B[0m - 【step 51, epoch: 0, batch: 50, loss: 3.15688, lr: 1.275e-06, speed: 4.424step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:48,875] [    INFO]\u001B[0m - 【step 52, epoch: 0, batch: 51, loss: 2.01494, lr: 1.3e-06, speed: 4.555step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:49,127] [    INFO]\u001B[0m - 【step 53, epoch: 0, batch: 52, loss: 3.1787, lr: 1.325e-06, speed: 3.9992step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:49,354] [    INFO]\u001B[0m - 【step 54, epoch: 0, batch: 53, loss: 2.59677, lr: 1.35e-06, speed: 4.4335step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:49,581] [    INFO]\u001B[0m - 【step 55, epoch: 0, batch: 54, loss: 2.82953, lr: 1.3750000000000002e-06, speed: 4.4436step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:49,811] [    INFO]\u001B[0m - 【step 56, epoch: 0, batch: 55, loss: 0.12653, lr: 1.4000000000000001e-06, speed: 4.3661step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:50,032] [    INFO]\u001B[0m - 【step 57, epoch: 0, batch: 56, loss: 2.65229, lr: 1.4250000000000001e-06, speed: 4.5546step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:50,255] [    INFO]\u001B[0m - 【step 58, epoch: 0, batch: 57, loss: 0.68144, lr: 1.45e-06, speed: 4.5142step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:50,485] [    INFO]\u001B[0m - 【step 59, epoch: 0, batch: 58, loss: 2.28374, lr: 1.475e-06, speed: 4.3852step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:50,713] [    INFO]\u001B[0m - 【step 60, epoch: 0, batch: 59, loss: 1.12525, lr: 1.5e-06, speed: 4.4144step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:50,970] [    INFO]\u001B[0m - 【step 61, epoch: 0, batch: 60, loss: 0.13642, lr: 1.525e-06, speed: 3.9129step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:51,211] [    INFO]\u001B[0m - 【step 62, epoch: 0, batch: 61, loss: 2.94326, lr: 1.55e-06, speed: 4.1836step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:51,425] [    INFO]\u001B[0m - 【step 63, epoch: 0, batch: 62, loss: 2.92002, lr: 1.5750000000000002e-06, speed: 4.7046step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:51,642] [    INFO]\u001B[0m - 【step 64, epoch: 0, batch: 63, loss: 1.57752, lr: 1.6000000000000001e-06, speed: 4.6398step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:51,841] [    INFO]\u001B[0m - 【step 65, epoch: 0, batch: 64, loss: 2.5634, lr: 1.6250000000000001e-06, speed: 5.0626step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:52,040] [    INFO]\u001B[0m - 【step 66, epoch: 0, batch: 65, loss: 1.84995, lr: 1.65e-06, speed: 5.0493step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:52,246] [    INFO]\u001B[0m - 【step 67, epoch: 0, batch: 66, loss: 2.55246, lr: 1.6750000000000003e-06, speed: 4.901step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:52,424] [    INFO]\u001B[0m - 【step 68, epoch: 0, batch: 67, loss: 1.97549, lr: 1.7000000000000002e-06, speed: 5.6333step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:52,585] [    INFO]\u001B[0m - 【step 69, epoch: 0, batch: 68, loss: 2.60963, lr: 1.7250000000000002e-06, speed: 6.2691step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:52,752] [    INFO]\u001B[0m - 【step 70, epoch: 0, batch: 69, loss: 0.14478, lr: 1.7500000000000002e-06, speed: 6.0227step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:52,932] [    INFO]\u001B[0m - 【step 71, epoch: 0, batch: 70, loss: 3.82841, lr: 1.775e-06, speed: 5.6314step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:53,093] [    INFO]\u001B[0m - 【step 72, epoch: 0, batch: 71, loss: 0.17242, lr: 1.8e-06, speed: 6.23step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:53,257] [    INFO]\u001B[0m - 【step 73, epoch: 0, batch: 72, loss: 3.34493, lr: 1.8249999999999999e-06, speed: 6.1527step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:53,414] [    INFO]\u001B[0m - 【step 74, epoch: 0, batch: 73, loss: 1.11028, lr: 1.85e-06, speed: 6.4102step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:53,571] [    INFO]\u001B[0m - 【step 75, epoch: 0, batch: 74, loss: 2.02026, lr: 1.875e-06, speed: 6.4099step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:53,737] [    INFO]\u001B[0m - 【step 76, epoch: 0, batch: 75, loss: 2.75698, lr: 1.9e-06, speed: 6.0596step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:53,910] [    INFO]\u001B[0m - 【step 77, epoch: 0, batch: 76, loss: 1.67044, lr: 1.925e-06, speed: 5.8129step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:54,118] [    INFO]\u001B[0m - 【step 78, epoch: 0, batch: 77, loss: 3.02877, lr: 1.95e-06, speed: 4.8539step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:54,275] [    INFO]\u001B[0m - 【step 79, epoch: 0, batch: 78, loss: 1.17402, lr: 1.975e-06, speed: 6.4305step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:54,439] [    INFO]\u001B[0m - 【step 80, epoch: 0, batch: 79, loss: 3.67855, lr: 2.0000000000000003e-06, speed: 6.1153step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:54,619] [    INFO]\u001B[0m - 【step 81, epoch: 0, batch: 80, loss: 1.36881, lr: 2.025e-06, speed: 5.6332step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:54,785] [    INFO]\u001B[0m - 【step 82, epoch: 0, batch: 81, loss: 1.13314, lr: 2.0500000000000003e-06, speed: 6.0419step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:54,956] [    INFO]\u001B[0m - 【step 83, epoch: 0, batch: 82, loss: 0.14281, lr: 2.075e-06, speed: 5.9163step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:55,151] [    INFO]\u001B[0m - 【step 84, epoch: 0, batch: 83, loss: 2.70988, lr: 2.1000000000000002e-06, speed: 5.1942step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:55,326] [    INFO]\u001B[0m - 【step 85, epoch: 0, batch: 84, loss: 2.89077, lr: 2.1250000000000004e-06, speed: 5.7795step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:55,502] [    INFO]\u001B[0m - 【step 86, epoch: 0, batch: 85, loss: 0.17451, lr: 2.1499999999999997e-06, speed: 5.7303step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:55,678] [    INFO]\u001B[0m - 【step 87, epoch: 0, batch: 86, loss: 2.18999, lr: 2.175e-06, speed: 5.7462step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:55,836] [    INFO]\u001B[0m - 【step 88, epoch: 0, batch: 87, loss: 1.34434, lr: 2.2e-06, speed: 6.3886step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,009] [    INFO]\u001B[0m - 【step 89, epoch: 0, batch: 88, loss: 1.5007, lr: 2.225e-06, speed: 5.8473step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,181] [    INFO]\u001B[0m - 【step 90, epoch: 0, batch: 89, loss: 1.60656, lr: 2.25e-06, speed: 5.8303step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,344] [    INFO]\u001B[0m - 【step 91, epoch: 0, batch: 90, loss: 0.91154, lr: 2.2750000000000002e-06, speed: 6.2296step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,502] [    INFO]\u001B[0m - 【step 92, epoch: 0, batch: 91, loss: 2.60537, lr: 2.3e-06, speed: 6.3893step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,660] [    INFO]\u001B[0m - 【step 93, epoch: 0, batch: 92, loss: 1.50815, lr: 2.325e-06, speed: 6.3888step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,824] [    INFO]\u001B[0m - 【step 94, epoch: 0, batch: 93, loss: 1.44805, lr: 2.35e-06, speed: 6.1149step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:56,992] [    INFO]\u001B[0m - 【step 95, epoch: 0, batch: 94, loss: 2.24702, lr: 2.375e-06, speed: 6.0239step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:57,159] [    INFO]\u001B[0m - 【step 96, epoch: 0, batch: 95, loss: 0.65902, lr: 2.4000000000000003e-06, speed: 6.0597step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:57,319] [    INFO]\u001B[0m - 【step 97, epoch: 0, batch: 96, loss: 1.67441, lr: 2.425e-06, speed: 6.269step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:57,509] [    INFO]\u001B[0m - 【step 98, epoch: 0, batch: 97, loss: 2.93546, lr: 2.4500000000000003e-06, speed: 5.3049step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:57,696] [    INFO]\u001B[0m - 【step 99, epoch: 0, batch: 98, loss: 2.98206, lr: 2.4750000000000004e-06, speed: 5.3803step/s】\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:27:57,906] [    INFO]\u001B[0m - 【step 100, epoch: 0, batch: 99, loss: 3.35368, lr: 2.5e-06, speed: 4.7841step/s】\u001B[0m\n",
      "Evaluation:: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.01s/it]\n",
      "\u001B[32m[2023-06-11 03:28:03,950] [    INFO]\u001B[0m - eval done total : 46.395751953125 s\u001B[0m\n",
      "\u001B[32m[2023-06-11 03:28:03,950] [    INFO]\u001B[0m - Eval use time: 46.39625334739685 s\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1: 0.3689381825830514, rouge-2: 0.3689381825830514, rouge-l: 0.3689381825830514\n"
     ]
    }
   ],
   "source": [
    "# 输出仅为测试时使用，实际运行参数并非如此\n",
    "PEGASUS.train_and_eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 测试\n",
    "见python文件，GenerateResult.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: : Couldn't visit directory: No such file or directory\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    }
   ],
   "source": [
    "!tar -cvf checkpoints64.tar checkpoints/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
